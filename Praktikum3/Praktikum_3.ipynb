{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1 style=\"color:blue\">Praktikum 3. Morfoloogilise analüüsi erijuhud</h1>\n",
    "<h3 style=\"color:blue\">Korpusepõhine ühestamine, morfoloogiline analüüs kasutajasõnastiku abil ja Giellatekno märgendid</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tänases praktikumis jätkame morfoloogilise analüüsi ja ühestamise teemadega. Kuna keerukamad analüüsitasemed (süntaks, semantika) toetuvad morfoloogilise analüüsi tulemustele, siis on oluline selle taseme analüüsile rohkem tähelepanu pöörata. Eriti oluliseks muutub see siis, kui analüüsida tuleb tekste, mille keelekasutus erineb kirjakeelest, nt netikeelt, slängi vms eesti keele allkeelt. Samuti võib sõnade morfoloogilist analüüsi parandada see, kui arvestame sõnade kasutust laiemas kontekstis: terves tekstis või _korpuses_ ¹.\n",
    "\n",
    "Analüüsi ja ühestamise juures puutume kokku ka EstNLTK Tagger-klassiga. Text-objekti meetodit `tag_layer()` oleme  teksti morfoloogilise analüüsiga märgendamiseks juba kasutanud. Nii saame kätte vaikesätetega analüüsikihi. Aeg-ajalt võib olla vaja aga loodava kihi sätteid (nt nime) täpsustada. Selleks saame importida ja luua vastavate sätetega Tagger-i ning seda tekstil rakendada. See eeldab siis seda, et tekstil on juba vajalikud sõltuvuskihid olemas. Selles praktikumides kasutame kolme taggerit - `VabamorfCorpusTagger` ja `VabamorfTagger`it ja `UserDictTagger`it. Detailsemat informatsiooni Taggerite ja nende kasutamise kohta leiab EstNLTK baasmaterjalidest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * ¹ _korpus_ = loomuliku keele tekstide kogu. Täpsema määratluse korpuste kohta lingvistikas leiab [siit](https://et.wikipedia.org/wiki/Keelekorpus)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morfoloogiline ühestamine\n",
    "\n",
    "Vaikimisi EstNLTK's kasutatav morfoloogiline ühestamine, millega tutvusite eelmises praktikumis, toimetab ühe lause piires **(seetõttu on analüüsiks vaja ka kihti *sentences*)**.  Lühidalt kirjeldades: statistilist / masinõppe lähenemist kasutades leitakse igale sõnale kontekstist lähtuvalt kõige tõenäolisem morfoloogiline analüüs, sealjuures üksikule sõnale analüüsi valimisel lähtutakse 1-2 eelneva sõna analüüsidest. Detailsemalt kirjeldab statistilist morfoloogilist ühestamist [see artikkel](http://www.cl.ut.ee/yllitised/kk_yhest_1998.pdf).\n",
    "\n",
    "Praktikas töötab lausepõhine ühestamine küllaltki hästi, aga selle täpsust on võimalik siiski veelgi suurendada. Ühe lause piires mitmeseks jäävad sõnad võivad mujal tekstis esineda üheselt tõlgendataval kujul (nt tähenduslikud (perekonna)nimed), seega, kui kasutada ühestamisel laiemat konteksti kui üks lause, saame lahendada lausepõhise ühestamise poolt lahendamata jäänud või valesti lahendatud mitmesusi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uurime lause- ja korpusepõhise morfoloogilise ühestamise erinevust järgmise \"näitekorpuse\" varal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_texts = ['Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.',\\\n",
    "          'Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.', \\\n",
    "          'Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Järjendi `corpus_texts` iga elementi tuleks käsitleda \"ühe tekstina\". Selleks muudame laused korpuses `Text`-objektideks ja rakendame meetodi `tag_layer()` kaudu morfoloogilise analüüsi tavalise, lausepõhise ühestamisega.  Sisuliselt teostab see meetod morfoloogilise analüüsi vastavalt sellele, milline `resolver` on kasutusel teksti märgendamisel *tag_layer* meetodiga ehk millised olid *resolver*'i parameetrite `guess`, `disambiguate` ja `propername` väärtused (eelmise praktikumi teema). Kui *resolver* ühtegi nimetatud parameetritest ei määra on vaikimisi kõik sisse lülitatud. \n",
    "\n",
    "Kasutame kõige selle tegemiseks väikest [tsükli-nõksu](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(text='Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.'),\n",
       " Text(text='Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.'),\n",
       " Text(text='Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "corpus = [Text(t).tag_layer(['morph_analysis']) for t in corpus_texts]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pärast teksti ühestamist trükime välja sõnad, mille analüüsid jäid mitmeseks. Kuvame eelnevalt tutvustatud nõksu abil morfoloogilise analüüsi tulemused nii, et oluline info oleks ühel real. Väljastame iga sõna analüüside osast ainult lemma, sõnaliigi ja käände- või pöördeinfo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.\n",
      "kohale =>[('koht', 'S', 'sg all'), ('koha', 'S', 'sg all')]\n",
      "kuigi =>[('kuigi', 'J', ''), ('kuigi', 'D', '')]\n",
      "\n",
      "Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.\n",
      "Teise =>[('teine', 'P', 'sg g'), ('teine', 'O', 'sg g')]\n",
      "koha =>[('koht', 'S', 'sg g'), ('koha', 'S', 'sg g')]\n",
      "mail =>[('mai', 'S', 'sg ad'), ('maa', 'S', 'pl ad')]\n",
      "\n",
      "Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.\n",
      "summaga =>[('summ', 'S', 'sg kom'), ('summa', 'S', 'sg kom')]\n",
      "on =>[('olema', 'V', 'b'), ('olema', 'V', 'vad')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in corpus:\n",
    "    print(text.text)\n",
    "    # Trükime välja mitmeseks jäänud sõnade analüüsid (ainult lemma, sõnaliigi ja vorminimetuse)\n",
    "    for word in text.morph_analysis:\n",
    "        if len(word.annotations) > 1:\n",
    "            print(f'{word.text} =>{[(a.lemma, a.partofspeech, a.form) for a in word.annotations]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korpusepõhine ühestamine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näha, on ühestamise tulemustes parandamisruumi küll. Proovime korpusepõhist ühestamist. Selleks käsitleme korpust Text-objektide kogumina ja impordime EstNLTK-st klassi VabamorfCorpusTagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import VabamorfCorpusTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loome tagger'i ning määrame selle lisatava kihi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_corpus_tagger = VabamorfCorpusTagger(output_layer='morph_analysis_with_cb_disamb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Märgendame teksti uuesti korpusõhise ühestajaga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(text='Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.'),\n",
       " Text(text='Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.'),\n",
       " Text(text='Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm_corpus_tagger.tag(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uurime tulemusi – väljastame uuesti mitmesed analüüsid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.\n",
      "kuigi => [('kuigi', 'J', ''), ('kuigi', 'D', '')]\n",
      "\n",
      "Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.\n",
      "Teise => [('teine', 'P', 'sg g'), ('teine', 'O', 'sg g')]\n",
      "\n",
      "Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.\n",
      "on => [('olema', 'V', 'b'), ('olema', 'V', 'vad')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in corpus:\n",
    "    print(text.text)\n",
    "    # Trükime välja mitmeseks jäänud sõnade analüüsid (ainult lemma, sõnaliigi ja vorminimetuse)\n",
    "    for word in text.morph_analysis_with_cb_disamb:\n",
    "        if len(word.annotations) > 1:\n",
    "            print(f'{word.text} => {[(a.lemma, a.partofspeech, a.form) for a in word.annotations]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näha, on nüüd mitmeseid analüüse vähem kui enne - sõnadele \"kohale\", \"mail\" ja \"summaga\" on seega ühestamise käigus alles jäänud üks ja ainus analüüs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lisaks on korpusepõhisest ühestamisest abi pärisnimeanalüüside korrastamisel. Kui mõni tavaline sõna on korpuse tekstides tõenäoliselt kasutusel pärisnimena (st esineb suure algustähega ka lausete keskel), siis valib korpusepõhine ühestaja pärisnime-analüüsid selle sõna tavapäraste analüüside asemel. Uurime, millised analüüsid valiti näitekorpuse suure tähega algavatele sõnadele nii vaikimisi kui ka korpuspõhisel ühestamisel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tekst: Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.\n",
      "\n",
      "Vaikimisi: Esimesele => [('esimene', 'O', 'sg all')]\n",
      "Korpusepõhine: Esimesele => [('esimene', 'O', 'sg all')]\n",
      "---------------\n",
      "Vaikimisi: Jänes => [('jänes', 'S', 'sg n')]\n",
      "Korpusepõhine: Jänes => [('Jänes', 'H', 'sg n')]\n",
      "---------------\n",
      "\n",
      "Tekst: Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.\n",
      "\n",
      "Vaikimisi: Lõpparvestuses => [('lõpparvestus', 'S', 'sg in')]\n",
      "Korpusepõhine: Lõpparvestuses => [('lõpparvestus', 'S', 'sg in')]\n",
      "---------------\n",
      "Vaikimisi: Konnale => [('konn', 'S', 'sg all')]\n",
      "Korpusepõhine: Konnale => [('Konn', 'H', 'sg all')]\n",
      "---------------\n",
      "Vaikimisi: Teise => [('teine', 'P', 'sg g'), ('teine', 'O', 'sg g')]\n",
      "Korpusepõhine: Teise => [('teine', 'P', 'sg g'), ('teine', 'O', 'sg g')]\n",
      "---------------\n",
      "Vaikimisi: Jänes => [('jänes', 'S', 'sg n')]\n",
      "Korpusepõhine: Jänes => [('Jäne', 'H', 'sg in')]\n",
      "---------------\n",
      "Vaikimisi: Uus => [('uus', 'A', 'sg n')]\n",
      "Korpusepõhine: Uus => [('uus', 'A', 'sg n')]\n",
      "---------------\n",
      "\n",
      "Tekst: Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.\n",
      "\n",
      "Vaikimisi: Konn => [('konn', 'S', 'sg n')]\n",
      "Korpusepõhine: Konn => [('Konn', 'H', 'sg n')]\n",
      "---------------\n",
      "Vaikimisi: Uue => [('uus', 'A', 'sg g')]\n",
      "Korpusepõhine: Uue => [('uus', 'A', 'sg g')]\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in corpus:\n",
    "    print(f'Tekst: {text.text}')\n",
    "    print()\n",
    "    # Trükime välja suure tähega algavate sõnade analüüsid\n",
    "    for word in text.words:\n",
    "        if word.text.istitle():\n",
    "            print(f\"Vaikimisi: {word.text} => {[(a.lemma, a.partofspeech, a.form) for a in word.morph_analysis.annotations]}\")\n",
    "            print(f\"Korpusepõhine: {word.text} => {[(a.lemma, a.partofspeech, a.form) for a in word.morph_analysis_with_cb_disamb.annotations]}\")\n",
    "            print(f'---------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näha, on sõnad _Jänes_ ja _Konn_ saanud korpuspõhisel ühestamisel pärisnime sõnaliigimärgendi (`'H'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tekstipõhine ühestamine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vahel võivad korpuse tekstid olla väga heterogeensed (näiteks erinevatel teemadel artiklid ühes ajakirjanduskorpuses) ja tekib oht, et sama sõna esineb kahes tekstis täiesti erinevates tähendustes. Sel juhul võib aga juhtuda, et liiga lai ühestamiskontekst (kogu korpus) ajab lemmad valeks. \n",
    "\n",
    "Kui kogu korpuse põhjal ühestamine tundubki liiga lai, on võimalik ühestada tekstipõhiselt, kasutades korpusepõhist ühestajat. Selleks impordime VabamorfTaggeri, täpsustame lippudega eel- ja järelühestamise ja anname taggerile korpuses sisalduvaid Text-objekte ühekaupa ette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_corpus_texts = ['Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.',\n",
    "                  'Kalamehed olid varahommikul platsis kohade, haugede, räimede ja teistegi kaladega. Koka praetud kohale jagus restoranikülastajatel vaid kiidusõnu.']\n",
    "\n",
    "tb_corpus = [Text(text).tag_layer('morph_analysis') for text in tb_corpus_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import VabamorfTagger\n",
    "\n",
    "vm_tb_tagger = VabamorfTagger(output_layer='text_based_disamb', predisambiguate=True, postdisambiguate=True)\n",
    "\n",
    "vm_corpus_tagger.tag(tb_corpus)\n",
    "\n",
    "for corpus_text in tb_corpus:\n",
    "    vm_tb_tagger.tag(corpus_text)  # käsitleme iga Text-objekti eraldi korpusena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Võrdleme korpuspõhise ja tekstipõhise ühestamise kaudu saadud märgenduste erinevusi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">koha</span></span></td>\n",
       "      <td>koha</td>\n",
       "      <td>koht</td>\n",
       "      <td>koht</td>\n",
       "      <td>[&#x27;koht&#x27;]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>koha</td>\n",
       "      <td>koha</td>\n",
       "      <td>koha</td>\n",
       "      <td>[&#x27;koha&#x27;]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('koha', [{'normalized_text': 'koha', 'lemma': 'koht', 'root': 'koht', 'root_tokens': ['koht'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}, {'normalized_text': 'koha', 'lemma': 'koha', 'root': 'koha', 'root_tokens': ['koha'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">koha</span></span></td>\n",
       "      <td>koha</td>\n",
       "      <td>koht</td>\n",
       "      <td>koht</td>\n",
       "      <td>[&#x27;koht&#x27;]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('koha', [{'normalized_text': 'koha', 'lemma': 'koht', 'root': 'koht', 'root_tokens': ['koht'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">kohale</span></span></td>\n",
       "      <td>kohale</td>\n",
       "      <td>koht</td>\n",
       "      <td>koht</td>\n",
       "      <td>[&#x27;koht&#x27;]</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kohale</td>\n",
       "      <td>koha</td>\n",
       "      <td>koha</td>\n",
       "      <td>[&#x27;koha&#x27;]</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('kohale', [{'normalized_text': 'kohale', 'lemma': 'koht', 'root': 'koht', 'root_tokens': ['koht'], 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'S'}, {'normalized_text': 'kohale', 'lemma': 'koha', 'root': 'koha', 'root_tokens': ['koha'], 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'S'}])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">kohale</span></span></td>\n",
       "      <td>kohale</td>\n",
       "      <td>koha</td>\n",
       "      <td>koha</td>\n",
       "      <td>[&#x27;koha&#x27;]</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('kohale', [{'normalized_text': 'kohale', 'lemma': 'koha', 'root': 'koha', 'root_tokens': ['koha'], 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'S'}])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Korpuspõhise ja tekstipõhise ühestaja mittekattuvad märgendused\n",
    "for corpus_text in tb_corpus:\n",
    "    for analysis in corpus_text.morph_analysis:\n",
    "        if analysis.text_based_disamb != analysis.morph_analysis_with_cb_disamb:\n",
    "            display(analysis.morph_analysis_with_cb_disamb)\n",
    "            display(analysis.text_based_disamb)\n",
    "            print('*'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kuna sõnad \"koha\" ja \"kohale\" esinesid tekstis eri kontekstides, näeme selle näite puhul tekstipõhise ühestaja paremust. Kui korpusepõhine ühestaja ei suutnud eristada, kas vormid \"koha\" ja \"kohale\" vastavad lemmale \"koha\" või \"koht\", siis tekstipõhine ühestaja andis mõlemal juhul välja ühe ja õige analüüsi.\n",
    "\n",
    "Juhul kui tahame kasutada morfoloogilisel analüüsil tekstipõhist ühestamist ja kihi eristamine tavalisest morfoloogilisest analüüsist pole oluline, võime luua resolveri, mis muudab morfoloogilise analüüsi vaikesätteid nii, et teostataks tekstipõhine eel- ja järelühestamine. \n",
    "Make_resolveriga on võimalik määrata peaagu kõiki analüüsiparameetreid, mida VabamorfTaggerilgi (loe rohkem  [VabamorfTaggeri](https://github.com/estnltk/estnltk/blob/main/tutorials/nlp_pipeline/B_morphology/01_morphological_analysis.ipynb) ja [`make_resolver`'i](https://github.com/estnltk/estnltk/blob/main/tutorials/basics/introduction_to_nlp_pipeline.ipynb) kasutamise kohta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Lõpparvestuses</td>\n",
       "      <td>Lõpparvestuses</td>\n",
       "      <td>lõpparvestus</td>\n",
       "      <td>lõpp_arvestus</td>\n",
       "      <td>['lõpp', 'arvestus']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>läks</td>\n",
       "      <td>läks</td>\n",
       "      <td>minema</td>\n",
       "      <td>mine</td>\n",
       "      <td>['mine']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Konnale</td>\n",
       "      <td>Konnale</td>\n",
       "      <td>Konnale</td>\n",
       "      <td>Konnale</td>\n",
       "      <td>['Konnale']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>esimene</td>\n",
       "      <td>esimene</td>\n",
       "      <td>esimene</td>\n",
       "      <td>esimene</td>\n",
       "      <td>['esimene']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koht</td>\n",
       "      <td>koht</td>\n",
       "      <td>koht</td>\n",
       "      <td>koht</td>\n",
       "      <td>['koht']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Teise</td>\n",
       "      <td>Teise</td>\n",
       "      <td>teine</td>\n",
       "      <td>teine</td>\n",
       "      <td>['teine']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Teise</td>\n",
       "      <td>teine</td>\n",
       "      <td>teine</td>\n",
       "      <td>['teine']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koha</td>\n",
       "      <td>koha</td>\n",
       "      <td>koht</td>\n",
       "      <td>koht</td>\n",
       "      <td>['koht']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sai</td>\n",
       "      <td>sai</td>\n",
       "      <td>saama</td>\n",
       "      <td>saa</td>\n",
       "      <td>['saa']</td>\n",
       "      <td>i</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>seekord</td>\n",
       "      <td>seekord</td>\n",
       "      <td>seekord</td>\n",
       "      <td>see_kord</td>\n",
       "      <td>['see', 'kord']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jänes</td>\n",
       "      <td>Jänes</td>\n",
       "      <td>Jäne</td>\n",
       "      <td>Jäne</td>\n",
       "      <td>['Jäne']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Uus</td>\n",
       "      <td>Uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>['uus']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>võistlus</td>\n",
       "      <td>võistlus</td>\n",
       "      <td>võistlus</td>\n",
       "      <td>võistlus</td>\n",
       "      <td>['võistlus']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>toimub</td>\n",
       "      <td>toimub</td>\n",
       "      <td>toimuma</td>\n",
       "      <td>toimu</td>\n",
       "      <td>['toimu']</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.</td>\n",
       "      <td>2.</td>\n",
       "      <td>2.</td>\n",
       "      <td>2.</td>\n",
       "      <td>['2.']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>?</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mail</td>\n",
       "      <td>mail</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mail</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>['maa']</td>\n",
       "      <td>il</td>\n",
       "      <td></td>\n",
       "      <td>pl ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Lõpparvestuses', [{'normalized_text': 'Lõpparvestuses', 'lemma': 'lõpparvestus', 'root': 'lõpp_arvestus', 'root_tokens': ['lõpp', 'arvestus'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S'}]),\n",
       "Span('läks', [{'normalized_text': 'läks', 'lemma': 'minema', 'root': 'mine', 'root_tokens': ['mine'], 'ending': 's', 'clitic': '', 'form': 's', 'partofspeech': 'V'}]),\n",
       "Span('Konnale', [{'normalized_text': 'Konnale', 'lemma': 'Konnale', 'root': 'Konnale', 'root_tokens': ['Konnale'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'H'}]),\n",
       "Span('esimene', [{'normalized_text': 'esimene', 'lemma': 'esimene', 'root': 'esimene', 'root_tokens': ['esimene'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'O'}]),\n",
       "Span('koht', [{'normalized_text': 'koht', 'lemma': 'koht', 'root': 'koht', 'root_tokens': ['koht'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Teise', [{'normalized_text': 'Teise', 'lemma': 'teine', 'root': 'teine', 'root_tokens': ['teine'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'P'}, {'normalized_text': 'Teise', 'lemma': 'teine', 'root': 'teine', 'root_tokens': ['teine'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'O'}]),\n",
       "Span('koha', [{'normalized_text': 'koha', 'lemma': 'koht', 'root': 'koht', 'root_tokens': ['koht'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span('sai', [{'normalized_text': 'sai', 'lemma': 'saama', 'root': 'saa', 'root_tokens': ['saa'], 'ending': 'i', 'clitic': '', 'form': 's', 'partofspeech': 'V'}]),\n",
       "Span('seekord', [{'normalized_text': 'seekord', 'lemma': 'seekord', 'root': 'see_kord', 'root_tokens': ['see', 'kord'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('Jänes', [{'normalized_text': 'Jänes', 'lemma': 'Jäne', 'root': 'Jäne', 'root_tokens': ['Jäne'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'H'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Uus', [{'normalized_text': 'Uus', 'lemma': 'uus', 'root': 'uus', 'root_tokens': ['uus'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}]),\n",
       "Span('võistlus', [{'normalized_text': 'võistlus', 'lemma': 'võistlus', 'root': 'võistlus', 'root_tokens': ['võistlus'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('toimub', [{'normalized_text': 'toimub', 'lemma': 'toimuma', 'root': 'toimu', 'root_tokens': ['toimu'], 'ending': 'b', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}]),\n",
       "Span('2.', [{'normalized_text': '2.', 'lemma': '2.', 'root': '2.', 'root_tokens': ['2.'], 'ending': '0', 'clitic': '', 'form': '?', 'partofspeech': 'O'}]),\n",
       "Span('mail', [{'normalized_text': 'mail', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}, {'normalized_text': 'mail', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'il', 'clitic': '', 'form': 'pl ad', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Kalamehed</td>\n",
       "      <td>Kalamehed</td>\n",
       "      <td>kalamees</td>\n",
       "      <td>kala_mees</td>\n",
       "      <td>['kala', 'mees']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olid</td>\n",
       "      <td>olid</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>id</td>\n",
       "      <td></td>\n",
       "      <td>sid</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>varahommikul</td>\n",
       "      <td>varahommikul</td>\n",
       "      <td>varahommik</td>\n",
       "      <td>vara_hommik</td>\n",
       "      <td>['vara', 'hommik']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>platsis</td>\n",
       "      <td>platsis</td>\n",
       "      <td>plats</td>\n",
       "      <td>plats</td>\n",
       "      <td>['plats']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kohade</td>\n",
       "      <td>kohade</td>\n",
       "      <td>koha</td>\n",
       "      <td>koha</td>\n",
       "      <td>['koha']</td>\n",
       "      <td>de</td>\n",
       "      <td></td>\n",
       "      <td>pl g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>haugede</td>\n",
       "      <td>haugede</td>\n",
       "      <td>hauge</td>\n",
       "      <td>hauge</td>\n",
       "      <td>['hauge']</td>\n",
       "      <td>de</td>\n",
       "      <td></td>\n",
       "      <td>pl g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>haugede</td>\n",
       "      <td>haugede</td>\n",
       "      <td>haugede</td>\n",
       "      <td>['haugede']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>räimede</td>\n",
       "      <td>räimede</td>\n",
       "      <td>räim</td>\n",
       "      <td>räim</td>\n",
       "      <td>['räim']</td>\n",
       "      <td>de</td>\n",
       "      <td></td>\n",
       "      <td>pl g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>['ja']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teistegi</td>\n",
       "      <td>teistegi</td>\n",
       "      <td>teine</td>\n",
       "      <td>teine</td>\n",
       "      <td>['teine']</td>\n",
       "      <td>te</td>\n",
       "      <td>gi</td>\n",
       "      <td>pl g</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>teistegi</td>\n",
       "      <td>teine</td>\n",
       "      <td>teine</td>\n",
       "      <td>['teine']</td>\n",
       "      <td>te</td>\n",
       "      <td>gi</td>\n",
       "      <td>pl g</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaladega</td>\n",
       "      <td>kaladega</td>\n",
       "      <td>kala</td>\n",
       "      <td>kala</td>\n",
       "      <td>['kala']</td>\n",
       "      <td>dega</td>\n",
       "      <td></td>\n",
       "      <td>pl kom</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Koka</td>\n",
       "      <td>Koka</td>\n",
       "      <td>koka</td>\n",
       "      <td>koka</td>\n",
       "      <td>['koka']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Koka</td>\n",
       "      <td>kokk</td>\n",
       "      <td>kokk</td>\n",
       "      <td>['kokk']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>praetud</td>\n",
       "      <td>praetud</td>\n",
       "      <td>praetud</td>\n",
       "      <td>prae=tud</td>\n",
       "      <td>['praetud']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>praetud</td>\n",
       "      <td>praetud</td>\n",
       "      <td>prae=tud</td>\n",
       "      <td>['praetud']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>praetud</td>\n",
       "      <td>praetud</td>\n",
       "      <td>prae=tud</td>\n",
       "      <td>['praetud']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>praetud</td>\n",
       "      <td>praadima</td>\n",
       "      <td>praadi</td>\n",
       "      <td>['praadi']</td>\n",
       "      <td>tud</td>\n",
       "      <td></td>\n",
       "      <td>tud</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kohale</td>\n",
       "      <td>kohale</td>\n",
       "      <td>koha</td>\n",
       "      <td>koha</td>\n",
       "      <td>['koha']</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jagus</td>\n",
       "      <td>jagus</td>\n",
       "      <td>jaguma</td>\n",
       "      <td>jagu</td>\n",
       "      <td>['jagu']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>restoranikülastajatel</td>\n",
       "      <td>restoranikülastajatel</td>\n",
       "      <td>restoranikülastaja</td>\n",
       "      <td>restorani_külastaja</td>\n",
       "      <td>['restorani', 'külastaja']</td>\n",
       "      <td>tel</td>\n",
       "      <td></td>\n",
       "      <td>pl ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vaid</td>\n",
       "      <td>vaid</td>\n",
       "      <td>vaid</td>\n",
       "      <td>vaid</td>\n",
       "      <td>['vaid']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kiidusõnu</td>\n",
       "      <td>kiidusõnu</td>\n",
       "      <td>kiidusõna</td>\n",
       "      <td>kiidu_sõna</td>\n",
       "      <td>['kiidu', 'sõna']</td>\n",
       "      <td>u</td>\n",
       "      <td></td>\n",
       "      <td>pl p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Kalamehed', [{'normalized_text': 'Kalamehed', 'lemma': 'kalamees', 'root': 'kala_mees', 'root_tokens': ['kala', 'mees'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('olid', [{'normalized_text': 'olid', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': 'id', 'clitic': '', 'form': 'sid', 'partofspeech': 'V'}]),\n",
       "Span('varahommikul', [{'normalized_text': 'varahommikul', 'lemma': 'varahommik', 'root': 'vara_hommik', 'root_tokens': ['vara', 'hommik'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}]),\n",
       "Span('platsis', [{'normalized_text': 'platsis', 'lemma': 'plats', 'root': 'plats', 'root_tokens': ['plats'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S'}]),\n",
       "Span('kohade', [{'normalized_text': 'kohade', 'lemma': 'koha', 'root': 'koha', 'root_tokens': ['koha'], 'ending': 'de', 'clitic': '', 'form': 'pl g', 'partofspeech': 'S'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('haugede', [{'normalized_text': 'haugede', 'lemma': 'hauge', 'root': 'hauge', 'root_tokens': ['hauge'], 'ending': 'de', 'clitic': '', 'form': 'pl g', 'partofspeech': 'S'}, {'normalized_text': 'haugede', 'lemma': 'haugede', 'root': 'haugede', 'root_tokens': ['haugede'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('räimede', [{'normalized_text': 'räimede', 'lemma': 'räim', 'root': 'räim', 'root_tokens': ['räim'], 'ending': 'de', 'clitic': '', 'form': 'pl g', 'partofspeech': 'S'}]),\n",
       "Span('ja', [{'normalized_text': 'ja', 'lemma': 'ja', 'root': 'ja', 'root_tokens': ['ja'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('teistegi', [{'normalized_text': 'teistegi', 'lemma': 'teine', 'root': 'teine', 'root_tokens': ['teine'], 'ending': 'te', 'clitic': 'gi', 'form': 'pl g', 'partofspeech': 'P'}, {'normalized_text': 'teistegi', 'lemma': 'teine', 'root': 'teine', 'root_tokens': ['teine'], 'ending': 'te', 'clitic': 'gi', 'form': 'pl g', 'partofspeech': 'O'}]),\n",
       "Span('kaladega', [{'normalized_text': 'kaladega', 'lemma': 'kala', 'root': 'kala', 'root_tokens': ['kala'], 'ending': 'dega', 'clitic': '', 'form': 'pl kom', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Koka', [{'normalized_text': 'Koka', 'lemma': 'koka', 'root': 'koka', 'root_tokens': ['koka'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}, {'normalized_text': 'Koka', 'lemma': 'kokk', 'root': 'kokk', 'root_tokens': ['kokk'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span('praetud', [{'normalized_text': 'praetud', 'lemma': 'praetud', 'root': 'prae=tud', 'root_tokens': ['praetud'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'A'}, {'normalized_text': 'praetud', 'lemma': 'praetud', 'root': 'prae=tud', 'root_tokens': ['praetud'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}, {'normalized_text': 'praetud', 'lemma': 'praetud', 'root': 'prae=tud', 'root_tokens': ['praetud'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}, {'normalized_text': 'praetud', 'lemma': 'praadima', 'root': 'praadi', 'root_tokens': ['praadi'], 'ending': 'tud', 'clitic': '', 'form': 'tud', 'partofspeech': 'V'}]),\n",
       "Span('kohale', [{'normalized_text': 'kohale', 'lemma': 'koha', 'root': 'koha', 'root_tokens': ['koha'], 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'S'}]),\n",
       "Span('jagus', [{'normalized_text': 'jagus', 'lemma': 'jaguma', 'root': 'jagu', 'root_tokens': ['jagu'], 'ending': 's', 'clitic': '', 'form': 's', 'partofspeech': 'V'}]),\n",
       "Span('restoranikülastajatel', [{'normalized_text': 'restoranikülastajatel', 'lemma': 'restoranikülastaja', 'root': 'restorani_külastaja', 'root_tokens': ['restorani', 'külastaja'], 'ending': 'tel', 'clitic': '', 'form': 'pl ad', 'partofspeech': 'S'}]),\n",
       "Span('vaid', [{'normalized_text': 'vaid', 'lemma': 'vaid', 'root': 'vaid', 'root_tokens': ['vaid'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('kiidusõnu', [{'normalized_text': 'kiidusõnu', 'lemma': 'kiidusõna', 'root': 'kiidu_sõna', 'root_tokens': ['kiidu', 'sõna'], 'ending': 'u', 'clitic': '', 'form': 'pl p', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make new resolver\n",
    "from estnltk.default_resolver import make_resolver\n",
    "text_based_disamb_resolver = make_resolver(predisambiguate=True, \n",
    "                                           postdisambiguate=True)\n",
    "\n",
    "\n",
    "# Add morph_analysis with text-based disambiguation\n",
    "\n",
    "for corpus_text in tb_corpus_texts:\n",
    "    corpus_text=Text(corpus_text)\n",
    "    corpus_text.tag_layer(resolver=text_based_disamb_resolver)['morph_analysis']\n",
    "    display(corpus_text.morph_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Korpusepõhise ühestamise teooriat kirjeldab [see artikkel](https://ebooks.iospress.nl/volumearticle/7488). EstNLTK korpusepõhise ühestaja liidest kirjeldab detailsemalt [see abimaterjal](https://github.com/estnltk/estnltk/blob/main/tutorials/nlp_pipeline/B_morphology/04_morph_analysis_with_corpus-based_disambiguation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Lisaks: \n",
    "EstNLTK võimaldab eksperimenteerida **kahetasemelise korpusepõhise ühestamisega**. Seda tasub katsetada samuti pigem heterogeensetel tekstidel. Kui meil on mingi alus, mille abil tekste võiks väiksemateks ja seotumateks osadeks liigitada, nt ajalehekorpuses artikli kuupäev või rubriik, on kahetasemelisel korpusepõhisel ühestamisel võimalik esmalt ühestada tekstid väiksema üksuse ning seejärel kogu korpuse põhjal. Kuna tegu on eksperimentaalse võimalusega, pole veel teada, kui palju selline lähenemine tulemusi parandab. Rohkem infot kahetasemelise korpusepõhise ühestamise kohta leiab [siit](https://github.com/estnltk/estnltk/blob/main/tutorials/nlp_pipeline/B_morphology/04_morph_analysis_with_corpus-based_disambiguation.ipynb) alamjaotuse _Two-level input corpus [ Experimental ]_ alt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Ülesanne 1: Kui palju vähendab korpusepõhine ühestamine mitmesust? (1,25p)\n",
    "\n",
    "Esimeseks ülesandeks on uurida, kui palju vähendab **korpusepõhine ühestamine** mitmesust. Kataloogis `'aja_sloleht_1999_04_k'` on SL Õhtulehe ajaleheartiklid. \n",
    "Igas failis on üks artikkel. \n",
    "Lugege sealt tekstid sisse ning teostage morfoloogiline ühestamine kahel erineval viisil: 1) tavaline, nn lausepõhine ühestamine, 2) korpusepõhine ühestamine, kus korpuseks on kõik artiklid, st terve kataloogi sisu.\n",
    "Leidke ja väljastage mõlema ühestamisetapi kohta mitmeseks jäänud sõnade arv ja osakaal kõigist sõnadest (%).\n",
    "\n",
    "Lisajuhis:\n",
    "\n",
    " * Failide kõvakettalt sisselugemine on üldiselt ressurssinõudlik operatsioon; seetõttu on soovitav ülesanne lahendada nii, et loete kõigi failide sisud kõigepealt mällu (nt järjendisse) ja lahendate alamülesanded 1) ja 2) mälus olevatel andmetel;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 2: Pärisnimede ühestamise kvaliteedi uurimine (1,75 p)\n",
    "\n",
    "Korpuste kasutajaid huvitab sageli pärisnimede otsimine. \n",
    "Järgnev ülesanne on uurida, kas ja kuidas aitab **tekstipõhine ühestamine** kaasa pärisnimeanalüüside kvaliteedi paranemisele.\n",
    "Looge programm, mis analüüsib korpust kataloogis `'aja_sloleht_1999_04_k'` ning väljastab kõik laused, kus leidub sõnu, mille puhul tavaline ühestamine ei andnud üldse pärisnime analüüsi, aga tekstipõhise ühestamise järel sai sõna ühese pärisnime analüüsi. Programm väljastab lausete tekstid, ühese pärisnimeanalüüsi saanud sõnad ja nende analüüside muutuse. Näide:\n",
    "\n",
    "    >> aja_sloleht_1999_04_15__20.txt\n",
    "    Matkamiksi peakorraldaja Andrus Nõmm tunnistas , et turvafirma Desperada kuuele töötajale ei ole tal midagi ette heita .\n",
    "     Nõmm\n",
    "       [('nõmm', 'S', 'sg n')]\n",
    "       ==>\n",
    "       [('Nõmm', 'H', 'sg n')]\n",
    "\n",
    "    “ Olin ka ise seal , ” rääkis Nõmm .\n",
    "     Nõmm\n",
    "       [('nõmm', 'S', 'sg n')]\n",
    "       ==>\n",
    "       [('Nõmm', 'H', 'sg n')]\n",
    "\n",
    "    Viha noorukite peale Kare ei pea , sest kaupluse alkoholikäive suurened messi ajal mitu korda .\n",
    "     Kare\n",
    "       [('kare', 'A', 'sg n')]\n",
    "       ==>\n",
    "       [('Kare', 'H', 'sg n')]\n",
    "    \n",
    "Kuidas sellele ülesandele võiks läheneda? Esmalt leida igast lausest sõnad, mis said (tekstipõhise) ühestamise tulemusena ühese pärisnime analüüsi (sõnaliik: `'H'`) ning võrrelda seda tavalise ühestamise väljundiga (eelmise ülesande ühestamine 1). Leidke sobiva muutusega sõnad.\n",
    "Väljastage laused, kuhu tekkisid ühese pärisnimeanalüüsiga sõnad, ning vastavad sõnad ja nende analüüside muutused (väljund võiks olla eeltoodud näitega sarnane).\n",
    "\n",
    "Veel näpunäiteid:\n",
    "\n",
    "  * Kui teete tsükli, mis käib üle korpuse kõigi tekstide, arvestage sellega, et korpus on üksjagu mahukas. Alguses on katsetamiseks soovitav teha kõigepealt tsükkel, mis katkestatakse [`break`](https://docs.python.org/3.5/tutorial/controlflow.html#break-and-continue-statements-and-else-clauses-on-loops) käsuga, kui teatud arv esimesi tekste (või lauseid) on juba läbitud. Kui olete jõudnud niikaugele, et programm töötab ilusti väiksel osal korpusest, siis saab ka katkestusest loobuda ja panna tsükli(d) jooksma üle kogu korpuse;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Morfoloogiline analüüs ja ühestamine kasutajasõnastiku abil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morfoloogiline analüsaator töötab kõige paremini tekstidel, mis järgivad kirjakeele norme. Kuigi analüsaator sisaldab ka tundmatute sõnade oletajat, ei saa selle täpsusele lootma jääda, kui analüüsitavad tekstid erinevad kirjakeelest suurel määral. Üks võimalus, kuidas analüüsi täpsemaks teha on morfoloogilise analüüsi lekskioni laiendamine kõnekeelega. Seda saame teha make_resolveriga nagu ühestamist ja oletamistki, määrates parameetri `slang_lex`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from estnltk.default_resolver import make_resolver\n",
    "\n",
    "resolver = make_resolver(slang_lex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sent = \"Mul on veits halb olla t2na, muideks. Tahax ibukat.\"\n",
    "\n",
    "# Loome tavalise morf. analüüsiga teksti\n",
    "sent_regular = Text(sent).tag_layer() \n",
    "\n",
    "# Slängiga laiendatud morf. analüüs\n",
    "sent_slang = Text(sent).tag_layer(resolver=resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mul</td>\n",
       "      <td>Mul</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>['mina']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>['veits']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>['halb']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olla</td>\n",
       "      <td>olla</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>da</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t2na</td>\n",
       "      <td>t2na</td>\n",
       "      <td>t2na</td>\n",
       "      <td>t2na</td>\n",
       "      <td>['t2na']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>?</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>muideks</td>\n",
       "      <td>muideks</td>\n",
       "      <td>mui</td>\n",
       "      <td>mui</td>\n",
       "      <td>['mui']</td>\n",
       "      <td>deks</td>\n",
       "      <td></td>\n",
       "      <td>pl tr</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tahax</td>\n",
       "      <td>Tahax</td>\n",
       "      <td>Tahax</td>\n",
       "      <td>Tahax</td>\n",
       "      <td>['Tahax']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>['ibukat']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Mul', [{'normalized_text': 'Mul', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'P'}]),\n",
       "Span('on', [{'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}, {'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "Span('veits', [{'normalized_text': 'veits', 'lemma': 'veits', 'root': 'veits', 'root_tokens': ['veits'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('halb', [{'normalized_text': 'halb', 'lemma': 'halb', 'root': 'halb', 'root_tokens': ['halb'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}]),\n",
       "Span('olla', [{'normalized_text': 'olla', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': 'a', 'clitic': '', 'form': 'da', 'partofspeech': 'V'}]),\n",
       "Span('t2na', [{'normalized_text': 't2na', 'lemma': 't2na', 'root': 't2na', 'root_tokens': ['t2na'], 'ending': '0', 'clitic': '', 'form': '?', 'partofspeech': 'Y'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('muideks', [{'normalized_text': 'muideks', 'lemma': 'mui', 'root': 'mui', 'root_tokens': ['mui'], 'ending': 'deks', 'clitic': '', 'form': 'pl tr', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Tahax', [{'normalized_text': 'Tahax', 'lemma': 'Tahax', 'root': 'Tahax', 'root_tokens': ['Tahax'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'H'}]),\n",
       "Span('ibukat', [{'normalized_text': 'ibukat', 'lemma': 'ibukat', 'root': 'ibukat', 'root_tokens': ['ibukat'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sent_regular.morph_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Tavalise morfoloogilise analüüsi puhul on saanud osaliselt või täiesti vale märgenduse neli sõna: *veits*, *muideks*, *Tahax*, *ibukat*.\n",
    "\n",
    "Vaatame laiendatud leksikoniga analüüsi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mul</td>\n",
       "      <td>Mul</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>['mina']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>['veits']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>['halb']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olla</td>\n",
       "      <td>olla</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>da</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t2na</td>\n",
       "      <td>t2na</td>\n",
       "      <td>t2na</td>\n",
       "      <td>t2na</td>\n",
       "      <td>['t2na']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>?</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>muideks</td>\n",
       "      <td>muideks</td>\n",
       "      <td>muideks</td>\n",
       "      <td>muideks</td>\n",
       "      <td>['muideks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tahax</td>\n",
       "      <td>Tahax</td>\n",
       "      <td>Tahax</td>\n",
       "      <td>Tahax</td>\n",
       "      <td>['Tahax']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>['ibukat']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Mul', [{'normalized_text': 'Mul', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'P'}]),\n",
       "Span('on', [{'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}, {'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "Span('veits', [{'normalized_text': 'veits', 'lemma': 'veits', 'root': 'veits', 'root_tokens': ['veits'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('halb', [{'normalized_text': 'halb', 'lemma': 'halb', 'root': 'halb', 'root_tokens': ['halb'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}]),\n",
       "Span('olla', [{'normalized_text': 'olla', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': 'a', 'clitic': '', 'form': 'da', 'partofspeech': 'V'}]),\n",
       "Span('t2na', [{'normalized_text': 't2na', 'lemma': 't2na', 'root': 't2na', 'root_tokens': ['t2na'], 'ending': '0', 'clitic': '', 'form': '?', 'partofspeech': 'Y'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('muideks', [{'normalized_text': 'muideks', 'lemma': 'muideks', 'root': 'muideks', 'root_tokens': ['muideks'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Tahax', [{'normalized_text': 'Tahax', 'lemma': 'Tahax', 'root': 'Tahax', 'root_tokens': ['Tahax'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'H'}]),\n",
       "Span('ibukat', [{'normalized_text': 'ibukat', 'lemma': 'ibukat', 'root': 'ibukat', 'root_tokens': ['ibukat'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sent_slang.morph_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Nagu selgub ka, ei piisa alati ainult slang_lexi määramisest, et tulemused oleksid rahuldavad. Seetõttu kasutatakse netikeele vms eesti keele allkeele automaatseks analüüsimiseks nn _kasutajasõnastiku lähenemist_. Selleks on EstNLTKs klass `UserDictTagger`, mis võimaldab kasutajasõnastikku sõnu ja analüüse lisada või need CSV-failist laadida. `UserDictTagger` märgendab üle `morph_analysis` kihi.\n",
    "\n",
    "Vaatame seda protsessi samm-sammult, proovides eelmise lause analüüse veelgi parandada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Esmalt tuleb tekst märgendada vaikimisi seadetega (see on meil tehtud).\n",
    "\n",
    "Impordime kasutajasõnastiku loomiseks meetodi `make_userdict`, et luua `UserDictTagger`'i objekt. Taggerit luues tuleb ette anda ka sõnastik sõnadest, mida tahame parandada, koos nende normaliseeritud vormiga, mille järgi suudab analüsaator juba korrektse analüüsi määrata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mul</td>\n",
       "      <td>Mul</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>['mina']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>['veits']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>['halb']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olla</td>\n",
       "      <td>olla</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>da</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t2na</td>\n",
       "      <td>täna</td>\n",
       "      <td>täna</td>\n",
       "      <td>täna</td>\n",
       "      <td>['täna']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>täna</td>\n",
       "      <td>tänama</td>\n",
       "      <td>täna</td>\n",
       "      <td>['täna']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>muideks</td>\n",
       "      <td>muideks</td>\n",
       "      <td>muideks</td>\n",
       "      <td>muideks</td>\n",
       "      <td>['muideks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tahax</td>\n",
       "      <td>tahaks</td>\n",
       "      <td>tahtma</td>\n",
       "      <td>taht</td>\n",
       "      <td>['taht']</td>\n",
       "      <td>ks</td>\n",
       "      <td></td>\n",
       "      <td>ks</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>['ibukat']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Mul', [{'normalized_text': 'Mul', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'P'}]),\n",
       "Span('on', [{'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}, {'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "Span('veits', [{'normalized_text': 'veits', 'lemma': 'veits', 'root': 'veits', 'root_tokens': ['veits'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('halb', [{'normalized_text': 'halb', 'lemma': 'halb', 'root': 'halb', 'root_tokens': ['halb'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}]),\n",
       "Span('olla', [{'normalized_text': 'olla', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': 'a', 'clitic': '', 'form': 'da', 'partofspeech': 'V'}]),\n",
       "Span('t2na', [{'normalized_text': 'täna', 'lemma': 'täna', 'root': 'täna', 'root_tokens': ['täna'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}, {'normalized_text': 'täna', 'lemma': 'tänama', 'root': 'täna', 'root_tokens': ['täna'], 'ending': '0', 'clitic': '', 'form': 'o', 'partofspeech': 'V'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('muideks', [{'normalized_text': 'muideks', 'lemma': 'muideks', 'root': 'muideks', 'root_tokens': ['muideks'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Tahax', [{'normalized_text': 'tahaks', 'lemma': 'tahtma', 'root': 'taht', 'root_tokens': ['taht'], 'ending': 'ks', 'clitic': '', 'form': 'ks', 'partofspeech': 'V'}]),\n",
       "Span('ibukat', [{'normalized_text': 'ibukat', 'lemma': 'ibukat', 'root': 'ibukat', 'root_tokens': ['ibukat'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import make_userdict\n",
    "\n",
    "userdict = make_userdict({'t2na': 'täna',\n",
    "                         'tahax': 'tahaks'}, ignore_case=True)\n",
    "\n",
    "userdict.retag(sent_slang)\n",
    "\n",
    "sent_slang.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näha jäi lausesse veel sõna *ibukat*, mida laiendatud leksikon ei laendanud ning mida ei saanud parandada ka kasutajasõnastikuga, kuna sellele polnud võimalik teist normaliseeritud vormi määrata. Selliste sõnade puhul, mille jaoks on ka normaliseeritud vorm analüsaatorile tundmatu (nt mõned uudis- ja slängisõnad), tuleb analüüs vastavalt vajadusele osaliselt või täielikult üle kirjutada.\n",
    "\n",
    "Seekord impordime `UserDictTagger`i ning anname ette sõnastiku, mis sisaldab viimast vigast sõna ning selle morfoloogilise analüüsi parandatud välju.\n",
    "\n",
    "Analüüsi **osaliselt** muutmiseks peab olema ülekirjutatud vähemalt üks väljadest `root`, `ending`, `clitic`, `form` või `partofspeech`. Kui juur `root` on defineeritud, peab kindlasti märkima ka sõnaliigi. Nende põhjal saavad ka atribuudid `lemma` ja `root_tokens` uued väärtused, ilma et neid eraldi täpsustaks. Praegu täpsustame sõnastikus kõik väljad, mis algses analüüsis valesti määrati (v.a automaatselt leitavad *lemma* ja *root_tokens*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mul</td>\n",
       "      <td>Mul</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>['mina']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>['veits']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>['halb']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olla</td>\n",
       "      <td>olla</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>da</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t2na</td>\n",
       "      <td>täna</td>\n",
       "      <td>täna</td>\n",
       "      <td>täna</td>\n",
       "      <td>['täna']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>täna</td>\n",
       "      <td>tänama</td>\n",
       "      <td>täna</td>\n",
       "      <td>['täna']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>muideks</td>\n",
       "      <td>muideks</td>\n",
       "      <td>muideks</td>\n",
       "      <td>muideks</td>\n",
       "      <td>['muideks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tahax</td>\n",
       "      <td>tahaks</td>\n",
       "      <td>tahtma</td>\n",
       "      <td>taht</td>\n",
       "      <td>['taht']</td>\n",
       "      <td>ks</td>\n",
       "      <td></td>\n",
       "      <td>ks</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukas</td>\n",
       "      <td>ibukas</td>\n",
       "      <td>['ibukas']</td>\n",
       "      <td>t</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Mul', [{'normalized_text': 'Mul', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'P'}]),\n",
       "Span('on', [{'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}, {'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "Span('veits', [{'normalized_text': 'veits', 'lemma': 'veits', 'root': 'veits', 'root_tokens': ['veits'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('halb', [{'normalized_text': 'halb', 'lemma': 'halb', 'root': 'halb', 'root_tokens': ['halb'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}]),\n",
       "Span('olla', [{'normalized_text': 'olla', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': 'a', 'clitic': '', 'form': 'da', 'partofspeech': 'V'}]),\n",
       "Span('t2na', [{'normalized_text': 'täna', 'lemma': 'täna', 'root': 'täna', 'root_tokens': ['täna'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}, {'normalized_text': 'täna', 'lemma': 'tänama', 'root': 'täna', 'root_tokens': ['täna'], 'ending': '0', 'clitic': '', 'form': 'o', 'partofspeech': 'V'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('muideks', [{'normalized_text': 'muideks', 'lemma': 'muideks', 'root': 'muideks', 'root_tokens': ['muideks'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Tahax', [{'normalized_text': 'tahaks', 'lemma': 'tahtma', 'root': 'taht', 'root_tokens': ['taht'], 'ending': 'ks', 'clitic': '', 'form': 'ks', 'partofspeech': 'V'}]),\n",
       "Span('ibukat', [{'normalized_text': 'ibukat', 'lemma': 'ibukas', 'root': 'ibukas', 'root_tokens': ['ibukas'], 'ending': 't', 'clitic': '', 'form': 'sg p', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import UserDictTagger\n",
    "\n",
    "userdict_2 = UserDictTagger(words_dict={'ibukat': {'root': 'ibukas', \n",
    "                                                   'partofspeech': 'S', \n",
    "                                                   'ending': 't', \n",
    "                                                   'form': 'sg p'}})\n",
    "\n",
    "userdict_2.retag(sent_slang)\n",
    "sent_slang.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui juhtub, et tundmatule sõnale vastab mitu analüüsi, tuleb need esitada sõnastike järjendina, kus iga sõnastik märgib üht võimalikku analüüsi. Atribuudid `root`, `ending`, `clitic`, `form` ja `partofspeech` peavad analüüside järjendina ette andmisel kindlasti täpsustatud olema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Kasutajasõnastiku (pool)automaatne loomine\n",
    "\n",
    "Suure korpuse korral on kasutajasõnastiku loomine siiski väga töömahukas tegevus ning täieliku käsitööna mitte eriti mõeldav. Parem lähenemine on kirjakeelsete vastete leidmine vähemalt osaliselt automatiseerida. Järgnevates ülesannetes uurimegi üht sellise automatiseerimisprotsessi alamosa: tundmatutele sõnadele kirjakeelsete vastete leidmist. Kõigepealt peame aga kindlaks tegema, millised sõnad saab üldse tundmatuteks lugeda (arvestades uuritava korpuse sõnestuse eripärasid)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ülesanne 3: Tundmatud sõnad (1,5 p)\n",
    "\n",
    "Looge programm, mis loeb failist `'netikeele_laused.txt'` laused (failis on iga lause eraldi real) ning teostab lausetel morf analüüsi (ilma oletamise, pärisnimede pakkumise ja ühestamiseta). \n",
    "\n",
    "Programm leiab: \n",
    "* mitu protsenti kõigist sõnadest jäid morf analüsaatorile tundmatuks (st sõnadele ei leitud analüüse)\n",
    "* 10 lauset, mis sisaldavad kõige rohkem tundmatuid sõnu.\n",
    "\n",
    "Lisaks:\n",
    "* kuvab programm leitud 10 lauset ja väljastab nendes tundmatuks jäänud sõnad ekraanile \n",
    "* salvestab leitud laused ja tundmatud sõnad ka kuhugi andmestruktuuri (nt sõnastik) – neid läheb tarvis ka järgmises ülesandes. Ekraanile väljastamisel peavad laused olema sorteeritud \"tundmatute arvu järgi\" kahanevalt.\n",
    "\n",
    "* Sõnade loendamisel tuleks välja jätta 1-tähelised \"sõnad\", ainult numbritest ja punktuatsioonist koosnevad sõnad (st näiteks 20-aastane on korrektne sõna);\n",
    "* \"Tundmatute sõnade\" hulka ei tuleks lugeda punktuatsiooni;\n",
    "* 10 kõige rohkem tundmatuid sõnu sisaldava lause hulka võib sattuda ka lauseid, milles on sama arv tundmatuid sõnu. Kui viimas(t)ele positsiooni(de)le on valida mitme sama arvu tundmatuid sisaldava lause vahel, siis võib valida lause(d), mis on algses (failis olevas) järjestuses eespool;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teisenduskauguse abil vastete leidmine\n",
    "\n",
    "Nüüd on meil teada, millist laadi sõnadele tuleb hakata kirjakeelseid vasteid otsima. \n",
    "Aga kuidas vasteid leida?\n",
    "Tehniliselt kõige lihtsam lähenemine on kasutada juba valmislahendust – proovida eelmises praktikumis tutvustatud automaatset õigekirjakorrektorit, mida võib ka rakendada tundmatutele sõnadele vastete leidmiseks.\n",
    "Siiski ei pruugi õigekirjakorrektor kõige paremaid tulemusi anda netikeele kõige konarlikemates lausetes, kus esineb eri tüüpi vigu ning nii mõnigi kord on tegemist süstemaatilise \"teisiti kirjutamisega\". \n",
    "\n",
    "Üldine meetod, mida rakendab (küll teatavate lisanüanssidega) ka õigekirjakorrektor, on tundmatute sõnade võrdlemine teadaolevate sõnade leksikoniga ning sõnade _sarnasuse_ põhjal vastete väljapakkumine. \n",
    "Seega, kui meil on olemas piisavalt mahukas kirjakeele korpus, võime selle põhjal ka ise teha teadaolevate sõnade loendi, noppida loendist välja tundmatute sõnadega _sarnased_ sõnad ja pakkuda neid vasteteks.\n",
    "\n",
    "_Kuidas hinnata sõnade sarnasust?_ Siin tuleb appi teisenduskaugus (ingl *edit distance*). Sisuliselt mõõdab teisenduskaugus, mitu teisendust/muutust tuleb teha, et saada ühest sõnest teine. Tavaliselt lubatakse kolme tüüpi muutuseid: 1) ühe tähe kustutamine, 2) ühe tähe lisamine, 3) ühe tähe asendamine mingi teise tähega. Teisenduskaugus ütleb, mitu sellist muutust tuleb minimaalselt teha – mida väiksem arv, seda sarnasemad kaks sõna on.\n",
    "\n",
    "Teisenduskauguse leidmist võib katsetada funktsiooni `nltk.metrics.distance.edit_distance` abil (funktsiooni sisaldav teek `nltk` peaks teil olema juba installitud, kuna see on üks `estnltk` eelduseid):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.metrics import edit_distance\n",
    "\n",
    "edit_distance('mõttetu', 'mõtetu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance('uit', 'uit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vt ka `nltk` teisenduskauguse funktsiooni [detailsemat kirjeldust](http://www.nltk.org/api/nltk.metrics.html#nltk.metrics.distance.edit_distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 4: Tundmatutele sõnadele vastete leidmine (2 p)\n",
    "\n",
    "See ülesanne koosneb kahest osast:\n",
    "\n",
    "#### Ülesanne 4.A: Minu soovitaja (1,25 p)\n",
    "\n",
    "Looge funktsioon, mis saab sisendiks tundmatu sõna ning tagastab sellele kõige sarnasemad vasted kirjakeelest. \n",
    "Funktsioon võiks osata pakkuda natukene rohkem vasteid kui EstNLTK [õigekirjakontrollija](https://github.com/estnltk/estnltk/blob/main/tutorials/nlp_pipeline/B_morphology/spelling_correction.ipynb). \n",
    "Seega, esimese sammuna võibki funktsioon kasutada õigekirjakorrektorit vastete leidmiseks, aga kui korrektor midagi pakkuda ei oska, tuleks teisenduskauguse abil ise vasteid otsida. \n",
    "Funktsioon tagastab sarnaste sõnade järjendi (ja tühijärjendi, kui vasteid üldse ei leitud).\n",
    "\n",
    "Teisenduskauguse abil võiks vasteid otsida ajakirjandustekstide sõnavarast (kataloogi `'aja_sloleht_1999_04_k'` tekstidest). \n",
    "Kui suures osas ajakirjendustekstide sõnavara tuleks arvestada (mida jätta ja mida võtta), jääb teie otsustada.\n",
    "Samuti jääb teie otsustada, kui palju ja millisel teisenduskaugusel vasteid tagastatakse (üldine põhimõte on, et mida vähem ja täpsemaid vasteid pakutakse, seda parem).\n",
    "\n",
    "  * **NB!** Kataloogi 'aja_sloleht_1999_04_k' tekstide sisselugemine ja nende põhjal sõnaloendi moodustamine peaks toimuma ainult üks kord – kindlasti ei tohiks seda teha igal soovitaja-funktsiooni väljakutsel. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ülesanne 4.B: Soovitaja rakendamine tundmatute tuvastamiseks (0,75 p)\n",
    "\n",
    "Rakendage oma soovitaja-funktsiooni ülesandes 3 leitud kümne \"kõige konarlikuma\" lause tundmatutel sõnadel. Väljastage:\n",
    "\n",
    "   * laused ning iga lause all nii tundmatud sõnad kui ka neile pakutavad vasted;\n",
    "   * (üle kõigi lausete) mitmele %-le tundmatutest sõnadest pakutakse vasteid;\n",
    "   * (üle kõigi lausete) milline on keskmine soovituste arv (ehk siis: mitu vastet keskmiselt iga tundmatu sõna kohta soovitatakse);\n",
    "\n",
    "Vajadusel täiendage oma funktsiooni nii, et vähemalt 90% tundmatutest sõnadest saaksid soovitusi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soovitustest kasutajasõnastikuni\n",
    "\n",
    "Eelmises ülesandes arendasime ja katsetasime soovitusfunktsiooni 10 lause tundmatutel sõnadel. \n",
    "Praktikas on tavaliselt eesmärgiks terve korpuse analüüs, seega on ka ülesanne üksjagu töömahukam. \n",
    "Kuidas praktikas kohandada morfoloogiline analüsaator netikeele tekstide analüüsimiseks, on kirjeldatud detailsemalt [selles artiklis](https://www.cl.ut.ee/yllitised/Muischnekjt_ERY2011_111-127.pdf). Üldine põhimõte on järgmine. Kirjakeelest erinevad ja haruldased sõnad peaksid olema kirjakeelsetest vormidest tuletatavad suhteliselt regulaarsete teisenduste abil. Ehk siis leitavad teisenduskauguse või veelgi spetsiifilisemate teisenduste kaudu; nende lisamine kasutajasõnastikku võiks toimuda suhteliselt automaatselt. Samas, kui sõnavorm pole tuletavav kirjakeelsest sõnast regulaarse teisenduse abil, peaks ta olema sageli kasutatav (\"et tema tähendus ja funktsioon kasutajatel meeles püsiks\") ja seega korpuse sõnasageduste uurimisel silma torkama. Sellised sõnavormid tuleks siis korpuse sagedusloendite uurimisel välja selgitada ja lisada kasutajasõnastikku käsitsi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giellatekno (GT) morfoloogilised kategooriad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siiani oleme vaadanud, kuidas parandada oma teksti morfoloogilist analüüsi nii, et see etteantud morfoloogiliste kategooriate süsteemis võimalikult korrektselt analüüsitud saaks. Võib aga juhtuda ka nii, et tekst on küll (piisavalt) korrektselt analüüsitud vaikimisi kasutatavate kategooriate järgi, ent see siiski millegipärast ei rahulda teksti töötlejat. Seetõttu on EstNLTK-s lisaks vaikimisi kasutatavale Filosofti süsteemile ka teine morfoloogiliste kategooriate süsteem: Giellatekno (GT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giellatekno morfoloogiliste kategooriate süsteemi saab EstNLTK-s kasutada järgnevalt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.taggers import GTMorphConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_converter = GTMorphConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Text('Mis siis, et kuuldavasti teevadki Poola torumehed nii Pariisis kui ka Brüsselis torud reaalselt korda.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GT morfoloogilise analüüsi tegemiseks peab olema tehtud nii morfoloogiline analüüs, kui ka osalausete märgendus, mida vaikimisi ei tehta. Osalauseanalüüs nõuab sõnade, lausete ja morfanalüüsi kihi olemasolu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "**Tehniline vahemärkus**: osalauseanalüüs kasutab java-t. Seega tuleb enne analüüsimist:\n",
    "* Installida süsteemi [*Java SE Runtime Environment*](https://www.java.com/en/download/win10.jsp);\n",
    "* Panna java käsk süsteemi keskkonnamuutujasse PATH. Windows-i ja Mac-i puhul tehakse seda tüüpiliselt juba installi käigus, aga kui on siiski tarvis seda käsitsi teha, siis detailsemat abi saab [siit](https://java.com/en/download/help/path.xml);\n",
    "\n",
    "\n",
    "Kuidas kontrollida, kas java on juba olemas või kas installimine õnnestus? Käsureakäsk `java -version` peaks kuvama infot installitud java versiooni kohta, näiteks midagi taolist:\n",
    "\n",
    "~~~\n",
    "java version \"14.0.1\" 2020-04-14\n",
    "Java(TM) SE Runtime Environment (build 14.0.1+7)\n",
    "Java HotSpot(TM) 64-Bit Server VM (build 14.0.1+7, mixed mode, sharing)  \n",
    "~~~\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Mis siis, et kuuldavasti teevadki Poola torumehed nii Pariisis kui ka Brüsselis torud reaalselt korda.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Mis siis, et kuuldavasti teevadki Poola torumehed nii Pariisis kui ka Brüsselis torud reaalselt korda.')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Märgendame tekstile peale vaikimisi toimiva Filosofti analüüsi\n",
    "text.tag_layer('clauses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Mis siis, et kuuldavasti teevadki Poola torumehed nii Pariisis kui ka Brüsselis torud reaalselt korda.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gt_morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Mis siis, et kuuldavasti teevadki Poola torumehed nii Pariisis kui ka Brüsselis torud reaalselt korda.')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teisendame morfoloogilise analüüsi GT formaati - tulemused on salvestatud kihis gt_morph_analysis\n",
    "gt_converter.tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>gt_morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mis</td>\n",
       "      <td>Mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>('mis',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Sg Nom</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>('mis',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Pl Nom</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>siis</td>\n",
       "      <td>siis</td>\n",
       "      <td>siis</td>\n",
       "      <td>siis</td>\n",
       "      <td>('siis',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>(',',)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>('et',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kuuldavasti</td>\n",
       "      <td>kuuldavasti</td>\n",
       "      <td>kuuldavasti</td>\n",
       "      <td>kuuldavasti</td>\n",
       "      <td>('kuuldavasti',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teevadki</td>\n",
       "      <td>teevadki</td>\n",
       "      <td>tegema</td>\n",
       "      <td>tege</td>\n",
       "      <td>('tege',)</td>\n",
       "      <td>vad</td>\n",
       "      <td>ki</td>\n",
       "      <td>Pers Prs Ind Pl 3 Aff</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Poola</td>\n",
       "      <td>Poola</td>\n",
       "      <td>Poola</td>\n",
       "      <td>Poola</td>\n",
       "      <td>('Poola',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Sg Gen</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>torumehed</td>\n",
       "      <td>torumehed</td>\n",
       "      <td>torumees</td>\n",
       "      <td>toru_mees</td>\n",
       "      <td>('toru', 'mees')</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>Pl Nom</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nii</td>\n",
       "      <td>nii</td>\n",
       "      <td>nii</td>\n",
       "      <td>nii</td>\n",
       "      <td>('nii',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pariisis</td>\n",
       "      <td>Pariisis</td>\n",
       "      <td>Pariis</td>\n",
       "      <td>Pariis</td>\n",
       "      <td>('Pariis',)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>Sg Ine</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kui</td>\n",
       "      <td>kui</td>\n",
       "      <td>kui</td>\n",
       "      <td>kui</td>\n",
       "      <td>('kui',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kui</td>\n",
       "      <td>kui</td>\n",
       "      <td>kui</td>\n",
       "      <td>('kui',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>('ka',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Brüsselis</td>\n",
       "      <td>Brüsselis</td>\n",
       "      <td>Brüssel</td>\n",
       "      <td>Brüssel</td>\n",
       "      <td>('Brüssel',)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>Sg Ine</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>torud</td>\n",
       "      <td>torud</td>\n",
       "      <td>toru</td>\n",
       "      <td>toru</td>\n",
       "      <td>('toru',)</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>Pl Nom</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>reaalselt</td>\n",
       "      <td>reaalselt</td>\n",
       "      <td>reaalselt</td>\n",
       "      <td>reaalselt</td>\n",
       "      <td>('reaalselt',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>korda</td>\n",
       "      <td>korda</td>\n",
       "      <td>kord</td>\n",
       "      <td>kord</td>\n",
       "      <td>('kord',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Sg Par</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>('.',)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='gt_morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Mis', [{'normalized_text': 'Mis', 'lemma': 'mis', 'root': 'mis', 'root_tokens': ('mis',), 'ending': '0', 'clitic': '', 'form': 'Sg Nom', 'partofspeech': 'P'}, {'normalized_text': 'Mis', 'lemma': 'mis', 'root': 'mis', 'root_tokens': ('mis',), 'ending': '0', 'clitic': '', 'form': 'Pl Nom', 'partofspeech': 'P'}]),\n",
       "Span('siis', [{'normalized_text': 'siis', 'lemma': 'siis', 'root': 'siis', 'root_tokens': ('siis',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': (',',), 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('et', [{'normalized_text': 'et', 'lemma': 'et', 'root': 'et', 'root_tokens': ('et',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('kuuldavasti', [{'normalized_text': 'kuuldavasti', 'lemma': 'kuuldavasti', 'root': 'kuuldavasti', 'root_tokens': ('kuuldavasti',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('teevadki', [{'normalized_text': 'teevadki', 'lemma': 'tegema', 'root': 'tege', 'root_tokens': ('tege',), 'ending': 'vad', 'clitic': 'ki', 'form': 'Pers Prs Ind Pl 3 Aff', 'partofspeech': 'V'}]),\n",
       "Span('Poola', [{'normalized_text': 'Poola', 'lemma': 'Poola', 'root': 'Poola', 'root_tokens': ('Poola',), 'ending': '0', 'clitic': '', 'form': 'Sg Gen', 'partofspeech': 'H'}]),\n",
       "Span('torumehed', [{'normalized_text': 'torumehed', 'lemma': 'torumees', 'root': 'toru_mees', 'root_tokens': ('toru', 'mees'), 'ending': 'd', 'clitic': '', 'form': 'Pl Nom', 'partofspeech': 'S'}]),\n",
       "Span('nii', [{'normalized_text': 'nii', 'lemma': 'nii', 'root': 'nii', 'root_tokens': ('nii',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('Pariisis', [{'normalized_text': 'Pariisis', 'lemma': 'Pariis', 'root': 'Pariis', 'root_tokens': ('Pariis',), 'ending': 's', 'clitic': '', 'form': 'Sg Ine', 'partofspeech': 'H'}]),\n",
       "Span('kui', [{'normalized_text': 'kui', 'lemma': 'kui', 'root': 'kui', 'root_tokens': ('kui',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}, {'normalized_text': 'kui', 'lemma': 'kui', 'root': 'kui', 'root_tokens': ('kui',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('ka', [{'normalized_text': 'ka', 'lemma': 'ka', 'root': 'ka', 'root_tokens': ('ka',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('Brüsselis', [{'normalized_text': 'Brüsselis', 'lemma': 'Brüssel', 'root': 'Brüssel', 'root_tokens': ('Brüssel',), 'ending': 's', 'clitic': '', 'form': 'Sg Ine', 'partofspeech': 'H'}]),\n",
       "Span('torud', [{'normalized_text': 'torud', 'lemma': 'toru', 'root': 'toru', 'root_tokens': ('toru',), 'ending': 'd', 'clitic': '', 'form': 'Pl Nom', 'partofspeech': 'S'}]),\n",
       "Span('reaalselt', [{'normalized_text': 'reaalselt', 'lemma': 'reaalselt', 'root': 'reaalselt', 'root_tokens': ('reaalselt',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('korda', [{'normalized_text': 'korda', 'lemma': 'kord', 'root': 'kord', 'root_tokens': ('kord',), 'ending': '0', 'clitic': '', 'form': 'Sg Par', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ('.',), 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.gt_morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boonusülesanne (0,5p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutvuge giellatekno formaadis morfoloogilise analüüsiga. Selleks teisendage järgneva teksti analüüs GT kujule ning printige välja iga tekstisõna koos selle mõlemas formaadis morfoloogilise analüüsiga (*form*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Kaks telgipäeva, 12. ja 13. juunil Tallinnas Vabaduse väljakul läksid väga edukalt. Saime kogeda nii vihma kui ka päikest, mürtsus puhkpillimuusika, ajakirjanikud sagisid ringi ning mis peamine – telgid olid tulvil heategudest. Kas ka sina käisid? Kui ei, tule järgmine aasta, paremat võimalust ei tule.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vastake küsimustele:\n",
    "* Mis on suurim sisuline erinevus GT ja Filosofti analüüside vahel? Vihje: vaadake verbianalüüse\n",
    "* Katseta *converter*'i loomisel lippe `disambiguate_sid_ksid=False` ja `disambiguate_neg=False`. Mis muutub?\n",
    "* Kui lähtuda teksti morfoloogilise analüüsi täpsusest ja saagisest, siis millisel juhul oleks mõistlik kasutada GT kuju, millisel juhul Filosofti oma?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analüüsi tõlgendamisel saab abi [siit](http://www.keeleveeb.ee/dict/corpus/shared/categories.html), soovi korral rohkem infot verbi morfoloogiliste kategooriate esitamise võimaluste kohta [siit](https://keeljakirjandus.ee/wp-content/uploads/2019/11/HJKaalep1_15.pdf)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
