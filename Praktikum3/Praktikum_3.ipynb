{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue\">Praktikum 3. Morfoloogilise analüüsi erijuhud</h1>\n",
    "<h3 style=\"color:blue\">Korpusepõhine ühestamine, morfoloogiline analüüs kasutajasõnastiku abil ja Giellatekno märgendid</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tänases praktikumis jätkame morfoloogilise analüüsi ja ühestamise teemadega. Kuna keerukamad analüüsitasemed (süntaks, semantika) toetuvad morfoloogilise analüüsi tulemustele, siis on oluline selle taseme analüüsile rohkem tähelepanu pöörata. Eriti oluliseks muutub see siis, kui analüüsida tuleb tekste, mille keelekasutus erineb kirjakeelest, nt netikeelt, slängi vms eesti keele allkeelt. Samuti võib sõnade morfoloogilist analüüsi parandada see, kui arvestame sõnade kasutust laiemas kontekstis: terves tekstis või _korpuses_ ¹."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * ¹ _korpus_ = loomuliku keele tekstide kogu. Täpsema määratluse korpuste kohta lingvistikas leiab [siit](https://et.wikipedia.org/wiki/Keelekorpus)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Morfoloogiline ühestamine\n",
    "\n",
    "Vaikimisi EstNLTK's kasutatav morfoloogiline ühestamine, millega tutvusite eelmises praktikumis, toimetab ühe lause piires **(seetõttu on analüüsiks vaja ka kihti *sentences*)**.  Lühidalt kirjeldades: statistilist / masinõppe lähenemist kasutades leitakse igale sõnale kontekstist lähtuvalt kõige tõenäolisem morfoloogiline analüüs, sealjuures üksikule sõnale analüüsi valimisel lähtutakse 1-2 eelneva sõna analüüsidest. Detailsemalt kirjeldab statistilist morfoloogilist ühestamist [see artikkel](http://www.cl.ut.ee/yllitised/kk_yhest_1998.pdf).\n",
    "\n",
    "Praktikas töötab lausepõhine ühestamine küllaltki hästi, aga selle täpsust on võimalik siiski veelgi suurendada. Ühe lause piires mitmeseks jäävad sõnad võivad mujal tekstis esineda üheselt tõlgendataval kujul (nt tähenduslikud (perekonna)nimed), seega, kui kasutada ühestamisel laiemat konteksti kui üks lause, saame lahendada lausepõhise ühestamise poolt lahendamata jäänud või valesti lahendatud mitmesusi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uurime lause- ja korpusepõhise morfoloogilise ühestamise erinevust järgmise \"näitekorpuse\" varal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_texts = ['Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.',\\\n",
    "          'Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.', \\\n",
    "          'Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Järjendi `corpus_texts` iga elementi tuleks käsitleda \"ühe tekstina\". Selleks muudame laused korpuses `Text`-objektideks ja rakendame meetodi `tag_layer()` kaudu morfoloogilise analüüsi tavalise, lausepõhise ühestamisega.  Sisuliselt teostab see meetod morfoloogilise analüüsi vastavalt sellele, milline `resolver` on kasutusel teksti märgendamisel *tag_layer* meetodiga ehk millised olid *resolver*'i parameetrite `guess`, `disambiguate` ja `propername` väärtused (eelmise praktikumi teema). Kui *resolver* ühtegi nimetatud parameetritest ei määra on vaikimisi kõik sisse lülitatud. \n",
    "\n",
    "Kasutame kõige selle tegemiseks väikest [tsükli-nõksu](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(text='Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.'),\n",
       " Text(text='Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.'),\n",
       " Text(text='Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "corpus = [Text(t).tag_layer(['morph_analysis']) for t in corpus_texts]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pärast teksti ühestamist trükime välja sõnad, mille analüüsid jäid mitmeseks. Kuvame eelnevalt tutvustatud nõksu abil morfoloogilise analüüsi tulemused nii, et oluline info oleks ühel real. Väljastame iga sõna analüüside osast ainult lemma, sõnaliigi ja käände- või pöördeinfo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.\n",
      "kohale => [('koha', 'S', 'sg all'), ('koht', 'S', 'sg all')]\n",
      "kuigi => [('kuigi', 'D', ''), ('kuigi', 'J', '')]\n",
      "\n",
      "Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.\n",
      "Teise => [('teine', 'O', 'sg g'), ('teine', 'P', 'sg g')]\n",
      "koha => [('koha', 'S', 'sg g'), ('koht', 'S', 'sg g')]\n",
      "mail => [('maa', 'S', 'pl ad'), ('mai', 'S', 'sg ad')]\n",
      "\n",
      "Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.\n",
      "summaga => [('summ', 'S', 'sg kom'), ('summa', 'S', 'sg kom')]\n",
      "on => [('olema', 'V', 'b'), ('olema', 'V', 'vad')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in corpus:\n",
    "    print(text.text)\n",
    "    # Trükime välja mitmeseks jäänud sõnade analüüsid (ainult lemma, sõnaliigi ja vorminimetuse)\n",
    "    for word in text.morph_analysis:\n",
    "        if len(word.annotations) > 1:\n",
    "            print(word.text, '=>',[(a.lemma, a.partofspeech, a.form) for a in word.annotations] )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korpusepõhine ühestamine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näha, on ühestamise tulemustes parandamisruumi küll. Proovime korpusepõhist ühestamist. Selleks käsitleme korpust Text-objektide kogumina ja impordime EstNLTK-st klassi VabamorfCorpusTagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import VabamorfCorpusTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loome tagger'i ning määrame selle lisatava kihi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_corpus_tagger = VabamorfCorpusTagger(output_layer='morph_analysis_with_cb_disamb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Märgendame teksti uuesti korpusõhise ühestajaga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(text='Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.'),\n",
       " Text(text='Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.'),\n",
       " Text(text='Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm_corpus_tagger.tag(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uurime tulemusi – väljastame uuesti mitmesed analüüsid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.\n",
      "kuigi => [('kuigi', 'D', ''), ('kuigi', 'J', '')]\n",
      "\n",
      "Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.\n",
      "Teise => [('teine', 'O', 'sg g'), ('teine', 'P', 'sg g')]\n",
      "\n",
      "Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.\n",
      "on => [('olema', 'V', 'b'), ('olema', 'V', 'vad')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in corpus:\n",
    "    print(text.text)\n",
    "    # Trükime välja mitmeseks jäänud sõnade analüüsid (ainult lemma, sõnaliigi ja vorminimetuse)\n",
    "    for word in text.morph_analysis_with_cb_disamb:\n",
    "        if len(word.annotations) > 1:\n",
    "            print( word.text,'=>',[(a.lemma, a.partofspeech, a.form) for a in word.annotations] )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lisaks on korpusepõhisest ühestamisest abi pärisnimeanalüüside korrastamisel. Kui mingi tavaline sõna on korpuse tekstides tõenäoliselt kasutusel pärisnimena (st esineb suure algustähega ka lausete keskel), siis valib korpusepõhine ühestaja pärisnime-analüüsid selle sõna tavapäraste analüüside asemel. Uurime, millised analüüsid valiti näitekorpuse suure tähega algavatele sõnadele nii vaikimisi kui ka korpuspõhisel ühestamisel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.\n",
      "Vaikimisi: Esimesele => [('esimene', 'O', 'sg all')]\n",
      "Korpusepõhine: Esimesele => [('esimene', 'O', 'sg all')]\n",
      "Vaikimisi: Jänes => [('jänes', 'S', 'sg n')]\n",
      "Korpusepõhine: Jänes => [('Jänes', 'H', 'sg n')]\n",
      "\n",
      "Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.\n",
      "Vaikimisi: Lõpparvestuses => [('lõpparvestus', 'S', 'sg in')]\n",
      "Korpusepõhine: Lõpparvestuses => [('lõpparvestus', 'S', 'sg in')]\n",
      "Vaikimisi: Konnale => [('konn', 'S', 'sg all')]\n",
      "Korpusepõhine: Konnale => [('Konn', 'H', 'sg all')]\n",
      "Vaikimisi: Teise => [('teine', 'O', 'sg g'), ('teine', 'P', 'sg g')]\n",
      "Korpusepõhine: Teise => [('teine', 'O', 'sg g'), ('teine', 'P', 'sg g')]\n",
      "Vaikimisi: Jänes => [('jänes', 'S', 'sg n')]\n",
      "Korpusepõhine: Jänes => [('Jäne', 'H', 'sg in')]\n",
      "Vaikimisi: Uus => [('uus', 'A', 'sg n')]\n",
      "Korpusepõhine: Uus => [('uus', 'A', 'sg n')]\n",
      "\n",
      "Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.\n",
      "Vaikimisi: Konn => [('konn', 'S', 'sg n')]\n",
      "Korpusepõhine: Konn => [('Konn', 'H', 'sg n')]\n",
      "Vaikimisi: Uue => [('uus', 'A', 'sg g')]\n",
      "Korpusepõhine: Uue => [('uus', 'A', 'sg g')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in corpus:\n",
    "    print(text.text)\n",
    "    # Trükime välja suure tähega algavate sõnade analüüsid\n",
    "    for word in text.words:\n",
    "        if word.text.istitle():\n",
    "            print( \"Vaikimisi:\", word.text,'=>',[(a.lemma, a.partofspeech, a.form) for a in word.morph_analysis.annotations] )\n",
    "            print( \"Korpusepõhine:\", word.text,'=>',[(a.lemma, a.partofspeech, a.form) \n",
    "                                   for a in word.morph_analysis_with_cb_disamb.annotations] )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näha, on sõnad _Jänes_ ja _Konn_ saanud korpuspõhisel ühestamisel pärisnime sõnaliigimärgendi (`'H'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tekstipõhine ühestamine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vahel võivad korpuse tekstid olla väga heterogeensed (näiteks erinevatel teemadel artiklid ühes ajakirjanduskorpuses) ja tekib oht, et sama sõna esineb kahes tekstis täiesti erinevates tähendustes. Sel juhul võib aga juhtuda, et liiga lai ühestamiskontekst (kogu korpus) ajab lemmad valeks. \n",
    "\n",
    "Kui kogu korpuse põhjal ühestamine tundubki liiga lai, on võimalik ühestada tekstipõhiselt, kasutades korpusepõhist ühestajat. See tähendab, et käsitleme iga korpuse teksti kui eraldiseisvat korpust, andes ühestajale ette vaid ühest tekstist koosneva järjendi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Text(text='Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.'), Text(text='Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.'), Text(text='Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.')]\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_tb_tagger = VabamorfCorpusTagger(output_layer='text_based_disamb')\n",
    "\n",
    "for corpus_text in corpus:\n",
    "    vm_tb_tagger.tag([corpus_text])  # käsitleme iga Text-objekti eraldi korpusena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Võrdleme korpuspõhise ja tekstipõhise ühestamise kaudu saadud märgenduste erinevusi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">kohale</span></span></td>\n",
       "      <td>kohale</td>\n",
       "      <td>koht</td>\n",
       "      <td>koht</td>\n",
       "      <td>[&#x27;koht&#x27;]</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('kohale', [{'normalized_text': 'kohale', 'lemma': 'koht', 'root': 'koht', 'root_tokens': ['koht'], 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'S'}])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">kohale</span></span></td>\n",
       "      <td>kohale</td>\n",
       "      <td>koha</td>\n",
       "      <td>koha</td>\n",
       "      <td>[&#x27;koha&#x27;]</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kohale</td>\n",
       "      <td>koht</td>\n",
       "      <td>koht</td>\n",
       "      <td>[&#x27;koht&#x27;]</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('kohale', [{'normalized_text': 'kohale', 'lemma': 'koha', 'root': 'koha', 'root_tokens': ['koha'], 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'S'}, {'normalized_text': 'kohale', 'lemma': 'koht', 'root': 'koht', 'root_tokens': ['koht'], 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'S'}])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Konnale</span></span></td>\n",
       "      <td>Konnale</td>\n",
       "      <td>Konn</td>\n",
       "      <td>Konn</td>\n",
       "      <td>[&#x27;Konn&#x27;]</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('Konnale', [{'normalized_text': 'Konnale', 'lemma': 'Konn', 'root': 'Konn', 'root_tokens': ['Konn'], 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'H'}])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Konnale</span></span></td>\n",
       "      <td>Konnale</td>\n",
       "      <td>Konnale</td>\n",
       "      <td>Konnale</td>\n",
       "      <td>[&#x27;Konnale&#x27;]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('Konnale', [{'normalized_text': 'Konnale', 'lemma': 'Konnale', 'root': 'Konnale', 'root_tokens': ['Konnale'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'H'}])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">mail</span></span></td>\n",
       "      <td>mail</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>[&#x27;mai&#x27;]</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('mail', [{'normalized_text': 'mail', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">mail</span></span></td>\n",
       "      <td>mail</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>[&#x27;maa&#x27;]</td>\n",
       "      <td>il</td>\n",
       "      <td></td>\n",
       "      <td>pl ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mail</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>[&#x27;mai&#x27;]</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('mail', [{'normalized_text': 'mail', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'il', 'clitic': '', 'form': 'pl ad', 'partofspeech': 'S'}, {'normalized_text': 'mail', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Konn</span></span></td>\n",
       "      <td>Konn</td>\n",
       "      <td>Konn</td>\n",
       "      <td>Konn</td>\n",
       "      <td>[&#x27;Konn&#x27;]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('Konn', [{'normalized_text': 'Konn', 'lemma': 'Konn', 'root': 'Konn', 'root_tokens': ['Konn'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'H'}])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Konn</span></span></td>\n",
       "      <td>Konn</td>\n",
       "      <td>konn</td>\n",
       "      <td>konn</td>\n",
       "      <td>[&#x27;konn&#x27;]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('Konn', [{'normalized_text': 'Konn', 'lemma': 'konn', 'root': 'konn', 'root_tokens': ['konn'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">summaga</span></span></td>\n",
       "      <td>summaga</td>\n",
       "      <td>summa</td>\n",
       "      <td>summa</td>\n",
       "      <td>[&#x27;summa&#x27;]</td>\n",
       "      <td>ga</td>\n",
       "      <td></td>\n",
       "      <td>sg kom</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('summaga', [{'normalized_text': 'summaga', 'lemma': 'summa', 'root': 'summa', 'root_tokens': ['summa'], 'ending': 'ga', 'clitic': '', 'form': 'sg kom', 'partofspeech': 'S'}])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">summaga</span></span></td>\n",
       "      <td>summaga</td>\n",
       "      <td>summ</td>\n",
       "      <td>summ</td>\n",
       "      <td>[&#x27;summ&#x27;]</td>\n",
       "      <td>ga</td>\n",
       "      <td></td>\n",
       "      <td>sg kom</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>summaga</td>\n",
       "      <td>summa</td>\n",
       "      <td>summa</td>\n",
       "      <td>[&#x27;summa&#x27;]</td>\n",
       "      <td>ga</td>\n",
       "      <td></td>\n",
       "      <td>sg kom</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('summaga', [{'normalized_text': 'summaga', 'lemma': 'summ', 'root': 'summ', 'root_tokens': ['summ'], 'ending': 'ga', 'clitic': '', 'form': 'sg kom', 'partofspeech': 'S'}, {'normalized_text': 'summaga', 'lemma': 'summa', 'root': 'summa', 'root_tokens': ['summa'], 'ending': 'ga', 'clitic': '', 'form': 'sg kom', 'partofspeech': 'S'}])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Korpuspõhise ja tekstipõhise ühestaja mittekattuvad märgendused\n",
    "for corpus_text in corpus:\n",
    "    for i, analysis in enumerate(corpus_text.morph_analysis_with_cb_disamb):\n",
    "        if corpus_text.text_based_disamb[i] != analysis:\n",
    "            display(analysis)\n",
    "            display(corpus_text.text_based_disamb[i])\n",
    "            print('*'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kuna näites toodud tekstid olid omavahel tugevasti seotud, on näha, et parema tulemuse andis seekord korpusepõhine ühestamine ja tekstipõhiselt jäid nii mõnedki sõnad mitmeseks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lisaks: kahetasemeline korpusepõhine ühestamine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korpusepõhist ühendajat saab kasutada veel kolmandatki moodi: EstNLTK võimaldab eksperimenteerida kahetasemelise korpusepõhise ühestamisega. Seda tasub katsetada samuti pigem heterogeensetel tekstidel. Kui meil on mingi alus, mille abil tekste võiks väiksemateks ja seotumateks osadeks liigitada, nt ajalehekorpuses artikli kuupäev või rubriik, on kahetasemelisel korpusepõhisel ühestamisel võimalik esmalt ühestada tekstid väiksema üksuse ning seejärel kogu korpuse põhjal. Kuna tegu on eksperimentaalse võimalusega, pole veel teada, kui palju selline lähenemine tulemusi parandab.\n",
    "\n",
    "Kahetasemeliseks korpusepõhiseks ühestamiseks tuleb tuttavale korpusepõhisele ühestajale argumendiks anda järjendite järjend, kus iga sisemine järjend sisaldab ühe alamhulga `Text`-objekte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "two_lvl_corpus = [['Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.',\n",
    "                   'Lõpparvestuses läks Karule esimene koht. Teise koha sai seekord Jänes. '\n",
    "                   'Uus võistlus toimub 2. mail.',\n",
    "                   'Jänesega jokk.'],\n",
    "                  ['Karu paistis silma suurima punktide summaga. Uue võistluse toimumisajaks '\n",
    "                   'on 2. mai.',\n",
    "                   'Karu ja Jänes jäävad ootama 2. maid.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Valmistame tekstid ühestamiseks ette\n",
    "nested_corpus = []\n",
    "for articles in two_lvl_corpus:\n",
    "    article_texts = []\n",
    "    for t in articles:\n",
    "        article_texts.append( Text(t).tag_layer(['words','sentences']) ) \n",
    "    nested_corpus.append(article_texts)  # lisame korpusse ühe artikli Text-objektid järjendina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Text(text='Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.'),\n",
       "  Text(text='Lõpparvestuses läks Karule esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.'),\n",
       "  Text(text='Jänesega jokk.')],\n",
       " [Text(text='Karu paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.'),\n",
       "  Text(text='Karu ja Jänes jäävad ootama 2. maid.')]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm_corpus_tagger = VabamorfCorpusTagger(output_layer='morph_analysis_with_two_lvl_disamb')\n",
    "vm_corpus_tagger.tag(nested_corpus)  # märgendame korraga kogu korpuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis_with_two_lvl_disamb</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Esimesele</td>\n",
       "      <td>Esimesele</td>\n",
       "      <td>esimene</td>\n",
       "      <td>esimene</td>\n",
       "      <td>['esimene']</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kohale</td>\n",
       "      <td>kohale</td>\n",
       "      <td>koht</td>\n",
       "      <td>koht</td>\n",
       "      <td>['koht']</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tuleb</td>\n",
       "      <td>tuleb</td>\n",
       "      <td>tulema</td>\n",
       "      <td>tule</td>\n",
       "      <td>['tule']</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jänes</td>\n",
       "      <td>Jänes</td>\n",
       "      <td>Jänes</td>\n",
       "      <td>Jänes</td>\n",
       "      <td>['Jänes']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kuigi</td>\n",
       "      <td>kuigi</td>\n",
       "      <td>kuigi</td>\n",
       "      <td>kuigi</td>\n",
       "      <td>['kuigi']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kuigi</td>\n",
       "      <td>kuigi</td>\n",
       "      <td>kuigi</td>\n",
       "      <td>['kuigi']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tema</td>\n",
       "      <td>tema</td>\n",
       "      <td>tema</td>\n",
       "      <td>tema</td>\n",
       "      <td>['tema']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>punktide</td>\n",
       "      <td>punktide</td>\n",
       "      <td>punkt</td>\n",
       "      <td>punkt</td>\n",
       "      <td>['punkt']</td>\n",
       "      <td>de</td>\n",
       "      <td></td>\n",
       "      <td>pl g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>summa</td>\n",
       "      <td>summa</td>\n",
       "      <td>summa</td>\n",
       "      <td>summa</td>\n",
       "      <td>['summa']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pole</td>\n",
       "      <td>pole</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>neg o</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kõrgeim</td>\n",
       "      <td>kõrgeim</td>\n",
       "      <td>kõrgeim</td>\n",
       "      <td>kõrgeim</td>\n",
       "      <td>['kõrgeim']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis_with_two_lvl_disamb', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Esimesele', [{'normalized_text': 'Esimesele', 'lemma': 'esimene', 'root': 'esimene', 'root_tokens': ['esimene'], 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'O'}]),\n",
       "Span('kohale', [{'normalized_text': 'kohale', 'lemma': 'koht', 'root': 'koht', 'root_tokens': ['koht'], 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'S'}]),\n",
       "Span('tuleb', [{'normalized_text': 'tuleb', 'lemma': 'tulema', 'root': 'tule', 'root_tokens': ['tule'], 'ending': 'b', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}]),\n",
       "Span('Jänes', [{'normalized_text': 'Jänes', 'lemma': 'Jänes', 'root': 'Jänes', 'root_tokens': ['Jänes'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'H'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('kuigi', [{'normalized_text': 'kuigi', 'lemma': 'kuigi', 'root': 'kuigi', 'root_tokens': ['kuigi'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}, {'normalized_text': 'kuigi', 'lemma': 'kuigi', 'root': 'kuigi', 'root_tokens': ['kuigi'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('tema', [{'normalized_text': 'tema', 'lemma': 'tema', 'root': 'tema', 'root_tokens': ['tema'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'P'}]),\n",
       "Span('punktide', [{'normalized_text': 'punktide', 'lemma': 'punkt', 'root': 'punkt', 'root_tokens': ['punkt'], 'ending': 'de', 'clitic': '', 'form': 'pl g', 'partofspeech': 'S'}]),\n",
       "Span('summa', [{'normalized_text': 'summa', 'lemma': 'summa', 'root': 'summa', 'root_tokens': ['summa'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('pole', [{'normalized_text': 'pole', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'neg o', 'partofspeech': 'V'}]),\n",
       "Span('kõrgeim', [{'normalized_text': 'kõrgeim', 'lemma': 'kõrgeim', 'root': 'kõrgeim', 'root_tokens': ['kõrgeim'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'U'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis_with_two_lvl_disamb</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Lõpparvestuses</td>\n",
       "      <td>Lõpparvestuses</td>\n",
       "      <td>lõpparvestus</td>\n",
       "      <td>lõpp_arvestus</td>\n",
       "      <td>['lõpp', 'arvestus']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>läks</td>\n",
       "      <td>läks</td>\n",
       "      <td>minema</td>\n",
       "      <td>mine</td>\n",
       "      <td>['mine']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Karule</td>\n",
       "      <td>Karule</td>\n",
       "      <td>Karu</td>\n",
       "      <td>Karu</td>\n",
       "      <td>['Karu']</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>esimene</td>\n",
       "      <td>esimene</td>\n",
       "      <td>esimene</td>\n",
       "      <td>esimene</td>\n",
       "      <td>['esimene']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koht</td>\n",
       "      <td>koht</td>\n",
       "      <td>koht</td>\n",
       "      <td>koht</td>\n",
       "      <td>['koht']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Teise</td>\n",
       "      <td>Teise</td>\n",
       "      <td>teine</td>\n",
       "      <td>teine</td>\n",
       "      <td>['teine']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Teise</td>\n",
       "      <td>teine</td>\n",
       "      <td>teine</td>\n",
       "      <td>['teine']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koha</td>\n",
       "      <td>koha</td>\n",
       "      <td>koht</td>\n",
       "      <td>koht</td>\n",
       "      <td>['koht']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sai</td>\n",
       "      <td>sai</td>\n",
       "      <td>saama</td>\n",
       "      <td>saa</td>\n",
       "      <td>['saa']</td>\n",
       "      <td>i</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>seekord</td>\n",
       "      <td>seekord</td>\n",
       "      <td>seekord</td>\n",
       "      <td>see_kord</td>\n",
       "      <td>['see', 'kord']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jänes</td>\n",
       "      <td>Jänes</td>\n",
       "      <td>Jänes</td>\n",
       "      <td>Jänes</td>\n",
       "      <td>['Jänes']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Uus</td>\n",
       "      <td>Uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>['uus']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>võistlus</td>\n",
       "      <td>võistlus</td>\n",
       "      <td>võistlus</td>\n",
       "      <td>võistlus</td>\n",
       "      <td>['võistlus']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>toimub</td>\n",
       "      <td>toimub</td>\n",
       "      <td>toimuma</td>\n",
       "      <td>toimu</td>\n",
       "      <td>['toimu']</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.</td>\n",
       "      <td>2.</td>\n",
       "      <td>2.</td>\n",
       "      <td>2.</td>\n",
       "      <td>['2.']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>?</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mail</td>\n",
       "      <td>mail</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis_with_two_lvl_disamb', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Lõpparvestuses', [{'normalized_text': 'Lõpparvestuses', 'lemma': 'lõpparvestus', 'root': 'lõpp_arvestus', 'root_tokens': ['lõpp', 'arvestus'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S'}]),\n",
       "Span('läks', [{'normalized_text': 'läks', 'lemma': 'minema', 'root': 'mine', 'root_tokens': ['mine'], 'ending': 's', 'clitic': '', 'form': 's', 'partofspeech': 'V'}]),\n",
       "Span('Karule', [{'normalized_text': 'Karule', 'lemma': 'Karu', 'root': 'Karu', 'root_tokens': ['Karu'], 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'H'}]),\n",
       "Span('esimene', [{'normalized_text': 'esimene', 'lemma': 'esimene', 'root': 'esimene', 'root_tokens': ['esimene'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'O'}]),\n",
       "Span('koht', [{'normalized_text': 'koht', 'lemma': 'koht', 'root': 'koht', 'root_tokens': ['koht'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Teise', [{'normalized_text': 'Teise', 'lemma': 'teine', 'root': 'teine', 'root_tokens': ['teine'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'O'}, {'normalized_text': 'Teise', 'lemma': 'teine', 'root': 'teine', 'root_tokens': ['teine'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'P'}]),\n",
       "Span('koha', [{'normalized_text': 'koha', 'lemma': 'koht', 'root': 'koht', 'root_tokens': ['koht'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span('sai', [{'normalized_text': 'sai', 'lemma': 'saama', 'root': 'saa', 'root_tokens': ['saa'], 'ending': 'i', 'clitic': '', 'form': 's', 'partofspeech': 'V'}]),\n",
       "Span('seekord', [{'normalized_text': 'seekord', 'lemma': 'seekord', 'root': 'see_kord', 'root_tokens': ['see', 'kord'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('Jänes', [{'normalized_text': 'Jänes', 'lemma': 'Jänes', 'root': 'Jänes', 'root_tokens': ['Jänes'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'H'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Uus', [{'normalized_text': 'Uus', 'lemma': 'uus', 'root': 'uus', 'root_tokens': ['uus'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}]),\n",
       "Span('võistlus', [{'normalized_text': 'võistlus', 'lemma': 'võistlus', 'root': 'võistlus', 'root_tokens': ['võistlus'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('toimub', [{'normalized_text': 'toimub', 'lemma': 'toimuma', 'root': 'toimu', 'root_tokens': ['toimu'], 'ending': 'b', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}]),\n",
       "Span('2.', [{'normalized_text': '2.', 'lemma': '2.', 'root': '2.', 'root_tokens': ['2.'], 'ending': '0', 'clitic': '', 'form': '?', 'partofspeech': 'O'}]),\n",
       "Span('mail', [{'normalized_text': 'mail', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis_with_two_lvl_disamb</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Jänesega</td>\n",
       "      <td>Jänesega</td>\n",
       "      <td>Jänes</td>\n",
       "      <td>Jänes</td>\n",
       "      <td>['Jänes']</td>\n",
       "      <td>ga</td>\n",
       "      <td></td>\n",
       "      <td>sg kom</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jokk</td>\n",
       "      <td>jokk</td>\n",
       "      <td>jokk</td>\n",
       "      <td>jokk</td>\n",
       "      <td>['jokk']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis_with_two_lvl_disamb', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Jänesega', [{'normalized_text': 'Jänesega', 'lemma': 'Jänes', 'root': 'Jänes', 'root_tokens': ['Jänes'], 'ending': 'ga', 'clitic': '', 'form': 'sg kom', 'partofspeech': 'H'}]),\n",
       "Span('jokk', [{'normalized_text': 'jokk', 'lemma': 'jokk', 'root': 'jokk', 'root_tokens': ['jokk'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis_with_two_lvl_disamb</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Karu</td>\n",
       "      <td>Karu</td>\n",
       "      <td>Karu</td>\n",
       "      <td>Karu</td>\n",
       "      <td>['Karu']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paistis</td>\n",
       "      <td>paistis</td>\n",
       "      <td>paistma</td>\n",
       "      <td>paist</td>\n",
       "      <td>['paist']</td>\n",
       "      <td>is</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>silma</td>\n",
       "      <td>silma</td>\n",
       "      <td>silm</td>\n",
       "      <td>silm</td>\n",
       "      <td>['silm']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>adt</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>suurima</td>\n",
       "      <td>suurima</td>\n",
       "      <td>suurim</td>\n",
       "      <td>suurim</td>\n",
       "      <td>['suurim']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>punktide</td>\n",
       "      <td>punktide</td>\n",
       "      <td>punkt</td>\n",
       "      <td>punkt</td>\n",
       "      <td>['punkt']</td>\n",
       "      <td>de</td>\n",
       "      <td></td>\n",
       "      <td>pl g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>summaga</td>\n",
       "      <td>summaga</td>\n",
       "      <td>summa</td>\n",
       "      <td>summa</td>\n",
       "      <td>['summa']</td>\n",
       "      <td>ga</td>\n",
       "      <td></td>\n",
       "      <td>sg kom</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Uue</td>\n",
       "      <td>Uue</td>\n",
       "      <td>uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>['uus']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>võistluse</td>\n",
       "      <td>võistluse</td>\n",
       "      <td>võistlus</td>\n",
       "      <td>võistlus</td>\n",
       "      <td>['võistlus']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>toimumisajaks</td>\n",
       "      <td>toimumisajaks</td>\n",
       "      <td>toimumisaeg</td>\n",
       "      <td>toimumis_aeg</td>\n",
       "      <td>['toimumis', 'aeg']</td>\n",
       "      <td>ks</td>\n",
       "      <td></td>\n",
       "      <td>sg tr</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.</td>\n",
       "      <td>2.</td>\n",
       "      <td>2.</td>\n",
       "      <td>2.</td>\n",
       "      <td>['2.']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>?</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis_with_two_lvl_disamb', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Karu', [{'normalized_text': 'Karu', 'lemma': 'Karu', 'root': 'Karu', 'root_tokens': ['Karu'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'H'}]),\n",
       "Span('paistis', [{'normalized_text': 'paistis', 'lemma': 'paistma', 'root': 'paist', 'root_tokens': ['paist'], 'ending': 'is', 'clitic': '', 'form': 's', 'partofspeech': 'V'}]),\n",
       "Span('silma', [{'normalized_text': 'silma', 'lemma': 'silm', 'root': 'silm', 'root_tokens': ['silm'], 'ending': '0', 'clitic': '', 'form': 'adt', 'partofspeech': 'S'}]),\n",
       "Span('suurima', [{'normalized_text': 'suurima', 'lemma': 'suurim', 'root': 'suurim', 'root_tokens': ['suurim'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'U'}]),\n",
       "Span('punktide', [{'normalized_text': 'punktide', 'lemma': 'punkt', 'root': 'punkt', 'root_tokens': ['punkt'], 'ending': 'de', 'clitic': '', 'form': 'pl g', 'partofspeech': 'S'}]),\n",
       "Span('summaga', [{'normalized_text': 'summaga', 'lemma': 'summa', 'root': 'summa', 'root_tokens': ['summa'], 'ending': 'ga', 'clitic': '', 'form': 'sg kom', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Uue', [{'normalized_text': 'Uue', 'lemma': 'uus', 'root': 'uus', 'root_tokens': ['uus'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'A'}]),\n",
       "Span('võistluse', [{'normalized_text': 'võistluse', 'lemma': 'võistlus', 'root': 'võistlus', 'root_tokens': ['võistlus'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span('toimumisajaks', [{'normalized_text': 'toimumisajaks', 'lemma': 'toimumisaeg', 'root': 'toimumis_aeg', 'root_tokens': ['toimumis', 'aeg'], 'ending': 'ks', 'clitic': '', 'form': 'sg tr', 'partofspeech': 'S'}]),\n",
       "Span('on', [{'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}, {'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "Span('2.', [{'normalized_text': '2.', 'lemma': '2.', 'root': '2.', 'root_tokens': ['2.'], 'ending': '0', 'clitic': '', 'form': '?', 'partofspeech': 'O'}]),\n",
       "Span('mai', [{'normalized_text': 'mai', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis_with_two_lvl_disamb</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Karu</td>\n",
       "      <td>Karu</td>\n",
       "      <td>Karu</td>\n",
       "      <td>Karu</td>\n",
       "      <td>['Karu']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>['ja']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jänes</td>\n",
       "      <td>Jänes</td>\n",
       "      <td>Jänes</td>\n",
       "      <td>Jänes</td>\n",
       "      <td>['Jänes']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jäävad</td>\n",
       "      <td>jäävad</td>\n",
       "      <td>jääma</td>\n",
       "      <td>jää</td>\n",
       "      <td>['jää']</td>\n",
       "      <td>vad</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ootama</td>\n",
       "      <td>ootama</td>\n",
       "      <td>ootama</td>\n",
       "      <td>oota</td>\n",
       "      <td>['oota']</td>\n",
       "      <td>ma</td>\n",
       "      <td></td>\n",
       "      <td>ma</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2.</td>\n",
       "      <td>2.</td>\n",
       "      <td>2.</td>\n",
       "      <td>2.</td>\n",
       "      <td>['2.']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>?</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maid</td>\n",
       "      <td>maid</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis_with_two_lvl_disamb', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Karu', [{'normalized_text': 'Karu', 'lemma': 'Karu', 'root': 'Karu', 'root_tokens': ['Karu'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'H'}]),\n",
       "Span('ja', [{'normalized_text': 'ja', 'lemma': 'ja', 'root': 'ja', 'root_tokens': ['ja'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('Jänes', [{'normalized_text': 'Jänes', 'lemma': 'Jänes', 'root': 'Jänes', 'root_tokens': ['Jänes'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'H'}]),\n",
       "Span('jäävad', [{'normalized_text': 'jäävad', 'lemma': 'jääma', 'root': 'jää', 'root_tokens': ['jää'], 'ending': 'vad', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "Span('ootama', [{'normalized_text': 'ootama', 'lemma': 'ootama', 'root': 'oota', 'root_tokens': ['oota'], 'ending': 'ma', 'clitic': '', 'form': 'ma', 'partofspeech': 'V'}]),\n",
       "Span('2.', [{'normalized_text': '2.', 'lemma': '2.', 'root': '2.', 'root_tokens': ['2.'], 'ending': '0', 'clitic': '', 'form': '?', 'partofspeech': 'O'}]),\n",
       "Span('maid', [{'normalized_text': 'maid', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'd', 'clitic': '', 'form': 'sg p', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for article in nested_corpus:\n",
    "    for article_text in article:\n",
    "        display(article_text.morph_analysis_with_two_lvl_disamb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korpusepõhise ühestamise teooriat kirjeldab [see artikkel](https://www.etis.ee/File/DownloadPublic/ce4606c7-41ba-4059-ac6d-6db2e40442e9?name=Fail_FAIA247-0082.pdf&type=application%2Fpdf). EstNLTK korpusepõhise ühestaja liidest kirjeldab detailsemalt [see abimaterjal](https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/nlp_pipeline/B_07b_morph_analysis_with_corpus-based_disambiguation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ülesanne 1: Kui palju vähendab korpusepõhine ühestamine mitmesust? (1,25p)\n",
    "\n",
    "Esimeseks ülesandeks on uurida, kui palju vähendab **korpusepõhine ühestamine** mitmesust. Kataloogis `'aja_sloleht_1999_04_k'` on SL Õhtulehe ajaleheartiklid. \n",
    "Igas failis on üks artikkel. \n",
    "Lugege sealt tekstid sisse ning teostage morfoloogiline ühestamine kahel erineval viisil: 1) tavaline, nn lausepõhine ühestamine, 2) korpusepõhine ühestamine, kus korpuseks on kõik artiklid, st terve kataloogi sisu.\n",
    "Leidke ja väljastage mõlema ühestamisetapi kohta mitmeseks jäänud sõnade arv ja osakaal kõigist sõnadest (%).\n",
    "\n",
    "Lisajuhis:\n",
    "\n",
    " * Failide kõvakettalt sisselugemine on üldiselt ressurssinõudlik operatsioon; seetõttu on soovitav ülesanne lahendada nii, et loete kõigi failide sisud kõigepealt mällu (nt järjendisse) ja lahendate alamülesanded 1) ja 2) mälus olevatel andmetel;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 2: Pärisnimede ühestamise kvaliteedi uurimine (1,75 p)\n",
    "\n",
    "Korpuste kasutajaid huvitab sageli pärisnimede otsimine. \n",
    "Järgnev ülesanne on uurida, kas ja kuidas aitab **tekstipõhine ühestamine** kaasa pärisnimeanalüüside kvaliteedi paranemisele.\n",
    "Looge programm, mis analüüsib korpust kataloogis `'aja_sloleht_1999_04_k'` ning väljastab kõik laused, kus leidub sõnu, mille puhul tavaline ühestamine ei andnud üldse pärisnime analüüsi, aga tekstipõhise ühestamise järel sai sõna ühese pärisnime analüüsi. Programm väljastab lausete tekstid, ühese pärisnimeanalüüsi saanud sõnad ja nende analüüside muutuse. Näide:\n",
    "\n",
    "    >> aja_sloleht_1999_04_15__20.txt\n",
    "    Matkamiksi peakorraldaja Andrus Nõmm tunnistas , et turvafirma Desperada kuuele töötajale ei ole tal midagi ette heita .\n",
    "     Nõmm\n",
    "       [('nõmm', 'S', 'sg n')]\n",
    "       ==>\n",
    "       [('Nõmm', 'H', 'sg n')]\n",
    "\n",
    "    “ Olin ka ise seal , ” rääkis Nõmm .\n",
    "     Nõmm\n",
    "       [('nõmm', 'S', 'sg n')]\n",
    "       ==>\n",
    "       [('Nõmm', 'H', 'sg n')]\n",
    "\n",
    "    Viha noorukite peale Kare ei pea , sest kaupluse alkoholikäive suurened messi ajal mitu korda .\n",
    "     Kare\n",
    "       [('kare', 'A', 'sg n')]\n",
    "       ==>\n",
    "       [('Kare', 'H', 'sg n')]\n",
    "    \n",
    "Kuidas sellele ülesandele võiks läheneda? Esmalt leida igast lausest sõnad, mis said (tekstipõhise) ühestamise tulemusena ühese pärisnime analüüsi (sõnaliik: `'H'`) ning võrrelda seda tavalise ühestamise väljundiga (eelmise ülesande ühestamine 1). Leidke sobiva muutusega sõnad.\n",
    "Väljastage laused, kuhu tekkisid ühese pärisnimeanalüüsiga sõnad, ning vastavad sõnad ja nende analüüside muutused (väljund võiks olla eeltoodud näitega sarnane).\n",
    "\n",
    "Veel näpunäiteid:\n",
    "\n",
    "  * Kui teete tsükli, mis käib üle korpuse kõigi tekstide, arvestage sellega, et korpus on üksjagu mahukas. Alguses on katsetamiseks soovitav teha kõigepealt tsükkel, mis katkestatakse [`break`](https://docs.python.org/3.5/tutorial/controlflow.html#break-and-continue-statements-and-else-clauses-on-loops) käsuga, kui teatud arv esimesi tekste (või lauseid) on juba läbitud. Kui olete jõudnud niikaugele, et programm töötab ilusti väiksel osal korpusest, siis saab ka katkestusest loobuda ja panna tsükli(d) jooksma üle kogu korpuse;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Morfoloogiline analüüs ja ühestamine kasutajasõnastiku abil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morfoloogiline analüsaator töötab kõige paremini tekstidel, mis järgivad kirjakeele norme. Kuigi analüsaator sisaldab ka tundmatute sõnade oletajat, ei saa selle täpsusele lootma jääda, kui analüüsitavad tekstid erinevad kirjakeelest suurel määral. Üks võimalus, kuidas analüüsi täpsemaks teha on morfoloogilise analüüsi lekskioni laiendamine kõnekeelega. Seda saame teha make_resolveriga nagu ühestamist ja oletamistki, määrates parameetri `slang_lex`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.resolve_layer_dag import make_resolver\n",
    "\n",
    "resolver = make_resolver(slang_lex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sent = \"Mul on veits halb olla täna, muideks. Tahax ibukat.\"\n",
    "\n",
    "# Loome tavalise morf. analüüsiga teksti\n",
    "sent_regular = Text(sent).tag_layer() \n",
    "\n",
    "# Slängiga laiendatud morf. analüüs\n",
    "sent_slang = Text(sent).tag_layer(resolver=resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mul</td>\n",
       "      <td>Mul</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>['mina']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>['veits']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>['halb']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olla</td>\n",
       "      <td>olla</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>da</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>täna</td>\n",
       "      <td>täna</td>\n",
       "      <td>täna</td>\n",
       "      <td>täna</td>\n",
       "      <td>['täna']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>muideks</td>\n",
       "      <td>muideks</td>\n",
       "      <td>mui</td>\n",
       "      <td>mui</td>\n",
       "      <td>['mui']</td>\n",
       "      <td>deks</td>\n",
       "      <td></td>\n",
       "      <td>pl tr</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tahax</td>\n",
       "      <td>Tahax</td>\n",
       "      <td>Tahax</td>\n",
       "      <td>Tahax</td>\n",
       "      <td>['Tahax']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>['ibukat']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Mul', [{'normalized_text': 'Mul', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'P'}]),\n",
       "Span('on', [{'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}, {'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "Span('veits', [{'normalized_text': 'veits', 'lemma': 'veits', 'root': 'veits', 'root_tokens': ['veits'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('halb', [{'normalized_text': 'halb', 'lemma': 'halb', 'root': 'halb', 'root_tokens': ['halb'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}]),\n",
       "Span('olla', [{'normalized_text': 'olla', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': 'a', 'clitic': '', 'form': 'da', 'partofspeech': 'V'}]),\n",
       "Span('täna', [{'normalized_text': 'täna', 'lemma': 'täna', 'root': 'täna', 'root_tokens': ['täna'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('muideks', [{'normalized_text': 'muideks', 'lemma': 'mui', 'root': 'mui', 'root_tokens': ['mui'], 'ending': 'deks', 'clitic': '', 'form': 'pl tr', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Tahax', [{'normalized_text': 'Tahax', 'lemma': 'Tahax', 'root': 'Tahax', 'root_tokens': ['Tahax'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'H'}]),\n",
       "Span('ibukat', [{'normalized_text': 'ibukat', 'lemma': 'ibukat', 'root': 'ibukat', 'root_tokens': ['ibukat'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sent_regular.morph_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tavalise morfoloogilise analüüsi puhul on saanud osaliselt või täiesti vale märgenduse neli sõna: *veits*, *muideks*, *Tahax*, *ibukat*.\n",
    "\n",
    "Vaatame laiendatud leksikoniga analüüsi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mul</td>\n",
       "      <td>Mul</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>['mina']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>veits</td>\n",
       "      <td>['veits']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>halb</td>\n",
       "      <td>['halb']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olla</td>\n",
       "      <td>olla</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>da</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>täna</td>\n",
       "      <td>täna</td>\n",
       "      <td>täna</td>\n",
       "      <td>täna</td>\n",
       "      <td>['täna']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>muideks</td>\n",
       "      <td>muideks</td>\n",
       "      <td>muideks</td>\n",
       "      <td>muideks</td>\n",
       "      <td>['muideks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tahax</td>\n",
       "      <td>Tahax</td>\n",
       "      <td>Tahax</td>\n",
       "      <td>Tahax</td>\n",
       "      <td>['Tahax']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>ibukat</td>\n",
       "      <td>['ibukat']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Mul', [{'normalized_text': 'Mul', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'P'}]),\n",
       "Span('on', [{'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}, {'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "Span('veits', [{'normalized_text': 'veits', 'lemma': 'veits', 'root': 'veits', 'root_tokens': ['veits'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('halb', [{'normalized_text': 'halb', 'lemma': 'halb', 'root': 'halb', 'root_tokens': ['halb'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}]),\n",
       "Span('olla', [{'normalized_text': 'olla', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': 'a', 'clitic': '', 'form': 'da', 'partofspeech': 'V'}]),\n",
       "Span('täna', [{'normalized_text': 'täna', 'lemma': 'täna', 'root': 'täna', 'root_tokens': ['täna'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('muideks', [{'normalized_text': 'muideks', 'lemma': 'muideks', 'root': 'muideks', 'root_tokens': ['muideks'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Tahax', [{'normalized_text': 'Tahax', 'lemma': 'Tahax', 'root': 'Tahax', 'root_tokens': ['Tahax'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'H'}]),\n",
       "Span('ibukat', [{'normalized_text': 'ibukat', 'lemma': 'ibukat', 'root': 'ibukat', 'root_tokens': ['ibukat'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sent_slang.morph_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Nagu selgub ka, ei piisa alati ainult slang_lexi määramisest, et tulemused oleksid rahuldavad. Seetõttu kasutatakse netikeele vms eesti keele allkeele automaatseks analüüsimiseks nn _kasutajasõnastiku lähenemist_. Selleks on EstNLTKs klass `UserDictTagger`, mis võimaldab kasutajasõnastikku ühekaupa sõnu ja analüüse lisada või need CSV-failist laadida. `UserDictTagger` märgendab üle `morph_analysis` kihi.\n",
    "\n",
    "Vaatame seda protsessi samm-sammult netikeele lausete näitel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kasutajasõnastiku abil saab märgendusi muuta kahel moel: märgendusi osaliselt üle kirjutades ja märgendusi täielikult üle kirjutades. Vaatame kõigepealt **osalist ülekirjutamist**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esmalt märgendame teksti vaikimise seadetega:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>kas</td>\n",
       "      <td>kas</td>\n",
       "      <td>kas</td>\n",
       "      <td>kas</td>\n",
       "      <td>['kas']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keegi</td>\n",
       "      <td>keegi</td>\n",
       "      <td>keegi</td>\n",
       "      <td>keegi</td>\n",
       "      <td>['keegi']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juttu</td>\n",
       "      <td>juttu</td>\n",
       "      <td>jutt</td>\n",
       "      <td>jutt</td>\n",
       "      <td>['jutt']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>['ei']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>neg</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>viitci</td>\n",
       "      <td>viitci</td>\n",
       "      <td>viitcima</td>\n",
       "      <td>viitci</td>\n",
       "      <td>['viitci']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ajada</td>\n",
       "      <td>ajada</td>\n",
       "      <td>ajama</td>\n",
       "      <td>aja</td>\n",
       "      <td>['aja']</td>\n",
       "      <td>da</td>\n",
       "      <td></td>\n",
       "      <td>da</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>['?']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('kas', [{'normalized_text': 'kas', 'lemma': 'kas', 'root': 'kas', 'root_tokens': ['kas'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('keegi', [{'normalized_text': 'keegi', 'lemma': 'keegi', 'root': 'keegi', 'root_tokens': ['keegi'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "Span('juttu', [{'normalized_text': 'juttu', 'lemma': 'jutt', 'root': 'jutt', 'root_tokens': ['jutt'], 'ending': '0', 'clitic': '', 'form': 'sg p', 'partofspeech': 'S'}]),\n",
       "Span('ei', [{'normalized_text': 'ei', 'lemma': 'ei', 'root': 'ei', 'root_tokens': ['ei'], 'ending': '0', 'clitic': '', 'form': 'neg', 'partofspeech': 'V'}]),\n",
       "Span('viitci', [{'normalized_text': 'viitci', 'lemma': 'viitcima', 'root': 'viitci', 'root_tokens': ['viitci'], 'ending': '0', 'clitic': '', 'form': 'o', 'partofspeech': 'V'}]),\n",
       "Span('ajada', [{'normalized_text': 'ajada', 'lemma': 'ajama', 'root': 'aja', 'root_tokens': ['aja'], 'ending': 'da', 'clitic': '', 'form': 'da', 'partofspeech': 'V'}]),\n",
       "Span('?', [{'normalized_text': '?', 'lemma': '?', 'root': '?', 'root_tokens': ['?'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Text('kas keegi juttu ei viitci ajada ?').tag_layer()\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Sõna *viitci* märgendus oli osaliselt korrektne: sõnaliik, vorm ja lõpp on korrektsed. Siiski tahaks, et lemma järgiks kirjakeele normi. Impordime kasutajasõnastiku loomiseks klassi `UserDictTagger` ja loome selle objekti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from estnltk.taggers import UserDictTagger\n",
    "userdict = UserDictTagger(ignore_case=True)  # vaikimisi suurtähetundlik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Analüüsi osaliselt muutmiseks peab olema ülekirjutatud vähemalt üks väljadest `root`, `ending`, `clitic`, `form` või `partofspeech`. Kui juur `root` on defineeritud, peab märkima ka sõnaliigi. Nende põhjal saavad ka atribuudid `lemma` ja `root_tokens` uued väärtused, ilma et neid eraldi täpsustaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "userdict.add_word('viitci', {'root': 'viitsi', 'partofspeech': 'V'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parandame anlüüsid ja vaatame muudatust:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">viitci</span></span></td>\n",
       "      <td>viitci</td>\n",
       "      <td>viitsima</td>\n",
       "      <td>viitsi</td>\n",
       "      <td>[&#x27;viitsi&#x27;]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('viitci', [{'normalized_text': 'viitci', 'lemma': 'viitsima', 'root': 'viitsi', 'root_tokens': ['viitsi'], 'ending': '0', 'clitic': '', 'form': 'o', 'partofspeech': 'V'}])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdict.retag(text)\n",
    "text.morph_analysis[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Analüüside **täielikku ülekirjutamist** alustame samuti morfoloogilisest analüüsist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Sa</td>\n",
       "      <td>Sa</td>\n",
       "      <td>sina</td>\n",
       "      <td>sina</td>\n",
       "      <td>['sina']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ajad</td>\n",
       "      <td>ajad</td>\n",
       "      <td>aeg</td>\n",
       "      <td>aeg</td>\n",
       "      <td>['aeg']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sássi</td>\n",
       "      <td>sássi</td>\n",
       "      <td>sáss</td>\n",
       "      <td>sáss</td>\n",
       "      <td>['sáss']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>sássi</td>\n",
       "      <td>sássi</td>\n",
       "      <td>sássi</td>\n",
       "      <td>['sássi']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>inimmeste</td>\n",
       "      <td>inimmeste</td>\n",
       "      <td>inimmest</td>\n",
       "      <td>inim_mest</td>\n",
       "      <td>['inim', 'mest']</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>pl p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>erinevad</td>\n",
       "      <td>erinevad</td>\n",
       "      <td>erinev</td>\n",
       "      <td>erinev</td>\n",
       "      <td>['erinev']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>käsitlusviisid</td>\n",
       "      <td>käsitlusviisid</td>\n",
       "      <td>käsitlusviis</td>\n",
       "      <td>käsitlus_viis</td>\n",
       "      <td>['käsitlus', 'viis']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>['ja']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lóodusnähhtuste</td>\n",
       "      <td>lóodusnähhtuste</td>\n",
       "      <td>lóodusnähhtus</td>\n",
       "      <td>lóodusnähhtus</td>\n",
       "      <td>['lóodusnähhtus']</td>\n",
       "      <td>te</td>\n",
       "      <td></td>\n",
       "      <td>pl g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>lóodusnähhtuste</td>\n",
       "      <td>lóodusnähhtuste</td>\n",
       "      <td>lóodusnähhtuste</td>\n",
       "      <td>['lóodusnähhtuste']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kinndla</td>\n",
       "      <td>kinndla</td>\n",
       "      <td>kinndla</td>\n",
       "      <td>kinndla</td>\n",
       "      <td>['kinndla']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vahekorra</td>\n",
       "      <td>vahekorra</td>\n",
       "      <td>vahekord</td>\n",
       "      <td>vahe_kord</td>\n",
       "      <td>['vahe', 'kord']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Sa', [{'normalized_text': 'Sa', 'lemma': 'sina', 'root': 'sina', 'root_tokens': ['sina'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "Span('ajad', [{'normalized_text': 'ajad', 'lemma': 'aeg', 'root': 'aeg', 'root_tokens': ['aeg'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('sássi', [{'normalized_text': 'sássi', 'lemma': 'sáss', 'root': 'sáss', 'root_tokens': ['sáss'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}, {'normalized_text': 'sássi', 'lemma': 'sássi', 'root': 'sássi', 'root_tokens': ['sássi'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span('inimmeste', [{'normalized_text': 'inimmeste', 'lemma': 'inimmest', 'root': 'inim_mest', 'root_tokens': ['inim', 'mest'], 'ending': 'e', 'clitic': '', 'form': 'pl p', 'partofspeech': 'S'}]),\n",
       "Span('erinevad', [{'normalized_text': 'erinevad', 'lemma': 'erinev', 'root': 'erinev', 'root_tokens': ['erinev'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}]),\n",
       "Span('käsitlusviisid', [{'normalized_text': 'käsitlusviisid', 'lemma': 'käsitlusviis', 'root': 'käsitlus_viis', 'root_tokens': ['käsitlus', 'viis'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('ja', [{'normalized_text': 'ja', 'lemma': 'ja', 'root': 'ja', 'root_tokens': ['ja'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('lóodusnähhtuste', [{'normalized_text': 'lóodusnähhtuste', 'lemma': 'lóodusnähhtus', 'root': 'lóodusnähhtus', 'root_tokens': ['lóodusnähhtus'], 'ending': 'te', 'clitic': '', 'form': 'pl g', 'partofspeech': 'S'}, {'normalized_text': 'lóodusnähhtuste', 'lemma': 'lóodusnähhtuste', 'root': 'lóodusnähhtuste', 'root_tokens': ['lóodusnähhtuste'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span('kinndla', [{'normalized_text': 'kinndla', 'lemma': 'kinndla', 'root': 'kinndla', 'root_tokens': ['kinndla'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span('vahekorra', [{'normalized_text': 'vahekorra', 'lemma': 'vahekord', 'root': 'vahe_kord', 'root_tokens': ['vahe', 'kord'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"Sa ajad sássi inimmeste erinevad käsitlusviisid ja lóodusnähhtuste kinndla vahekorra.\" \n",
    "text = Text(sent).tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Meie näide on lihtne selles mõttes, et kuigi siin on mitte-kirjakeelseid sõnavorme (nt *inimmeste*, *lóodusnähhtuste*), leidub kõigile sõnadele siiski kirjakeeles vaste. Seega saame tekitada mitte-kirjakeelsete vormide morfoloogilised analüüsid, kui analüüsime vastavaid kirjakeele sõnavorme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Loome uue kasutajasõnastiku\n",
    "userdict = UserDictTagger( ignore_case=True )\n",
    "# Lisame tundmatute sõnade vormid koos neile vastavate kirjakeele sõnade analüüsidega\n",
    "userdict.add_word('inimmeste', [{'normalized_text': 'inimeste', 'form': 'pl g', 'root': 'inimene', 'ending': 'te', 'partofspeech': 'S', 'clitic': ''}])\n",
    "userdict.add_word('kinndla', [{'normalized_text': 'kindla', 'form': 'sg g', 'root': 'kindel', 'ending': '0', 'partofspeech': 'A', 'clitic': ''}])\n",
    "userdict.add_word('lóodusnähhtuste', [{'normalized_text': 'loodusnähtuste', 'form': 'pl g', 'root': 'loodus_nähtus', 'ending': 'te', 'partofspeech': 'S', 'clitic': ''}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Sa</td>\n",
       "      <td>Sa</td>\n",
       "      <td>sina</td>\n",
       "      <td>sina</td>\n",
       "      <td>['sina']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ajad</td>\n",
       "      <td>ajad</td>\n",
       "      <td>aeg</td>\n",
       "      <td>aeg</td>\n",
       "      <td>['aeg']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sássi</td>\n",
       "      <td>sássi</td>\n",
       "      <td>sáss</td>\n",
       "      <td>sáss</td>\n",
       "      <td>['sáss']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>sássi</td>\n",
       "      <td>sássi</td>\n",
       "      <td>sássi</td>\n",
       "      <td>['sássi']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>inimmeste</td>\n",
       "      <td>inimeste</td>\n",
       "      <td>inimene</td>\n",
       "      <td>inimene</td>\n",
       "      <td>['inimene']</td>\n",
       "      <td>te</td>\n",
       "      <td></td>\n",
       "      <td>pl g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>erinevad</td>\n",
       "      <td>erinevad</td>\n",
       "      <td>erinev</td>\n",
       "      <td>erinev</td>\n",
       "      <td>['erinev']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>käsitlusviisid</td>\n",
       "      <td>käsitlusviisid</td>\n",
       "      <td>käsitlusviis</td>\n",
       "      <td>käsitlus_viis</td>\n",
       "      <td>['käsitlus', 'viis']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>['ja']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lóodusnähhtuste</td>\n",
       "      <td>loodusnähtuste</td>\n",
       "      <td>loodusnähtus</td>\n",
       "      <td>loodus_nähtus</td>\n",
       "      <td>['loodus', 'nähtus']</td>\n",
       "      <td>te</td>\n",
       "      <td></td>\n",
       "      <td>pl g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kinndla</td>\n",
       "      <td>kindla</td>\n",
       "      <td>kindel</td>\n",
       "      <td>kindel</td>\n",
       "      <td>['kindel']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vahekorra</td>\n",
       "      <td>vahekorra</td>\n",
       "      <td>vahekord</td>\n",
       "      <td>vahe_kord</td>\n",
       "      <td>['vahe', 'kord']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Sa', [{'normalized_text': 'Sa', 'lemma': 'sina', 'root': 'sina', 'root_tokens': ['sina'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "Span('ajad', [{'normalized_text': 'ajad', 'lemma': 'aeg', 'root': 'aeg', 'root_tokens': ['aeg'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('sássi', [{'normalized_text': 'sássi', 'lemma': 'sáss', 'root': 'sáss', 'root_tokens': ['sáss'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}, {'normalized_text': 'sássi', 'lemma': 'sássi', 'root': 'sássi', 'root_tokens': ['sássi'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span('inimmeste', [{'normalized_text': 'inimeste', 'lemma': 'inimene', 'root': 'inimene', 'root_tokens': ['inimene'], 'ending': 'te', 'clitic': '', 'form': 'pl g', 'partofspeech': 'S'}]),\n",
       "Span('erinevad', [{'normalized_text': 'erinevad', 'lemma': 'erinev', 'root': 'erinev', 'root_tokens': ['erinev'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}]),\n",
       "Span('käsitlusviisid', [{'normalized_text': 'käsitlusviisid', 'lemma': 'käsitlusviis', 'root': 'käsitlus_viis', 'root_tokens': ['käsitlus', 'viis'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('ja', [{'normalized_text': 'ja', 'lemma': 'ja', 'root': 'ja', 'root_tokens': ['ja'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('lóodusnähhtuste', [{'normalized_text': 'loodusnähtuste', 'lemma': 'loodusnähtus', 'root': 'loodus_nähtus', 'root_tokens': ['loodus', 'nähtus'], 'ending': 'te', 'clitic': '', 'form': 'pl g', 'partofspeech': 'S'}]),\n",
       "Span('kinndla', [{'normalized_text': 'kindla', 'lemma': 'kindel', 'root': 'kindel', 'root_tokens': ['kindel'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'A'}]),\n",
       "Span('vahekorra', [{'normalized_text': 'vahekorra', 'lemma': 'vahekord', 'root': 'vahe_kord', 'root_tokens': ['vahe', 'kord'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdict.retag( text )\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näha *lóodusnähhtuste* näitel, kirjutab sellisel moel analüüside lisamine üle kõik olemasolevad analüüsid. Atribuudid `root`, `ending`, `clitic`, `form` ja `partofspeech` peavad analüüside järjendina ette andmisel kindlasti täpsustatud olema. Ette saab anda ka mitu võimalikku analüüsi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sõnal *sassi* võib kirjakeeles olla kaks analüüsi, lisame mõlemad kasutajasõnastikku *sássi* vasteks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "userdict.add_word('sássi', [{'normalized_text': 'sassi', 'form': '', 'root': 'sassi', 'ending': '0', 'partofspeech': 'D', 'clitic': ''},\n",
    "                           {'normalized_text': 'sassi', 'form': 'adt', 'root': 'sasi', 'ending': '0', 'partofspeech': 'S', 'clitic': ''}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">sássi</span></span></td>\n",
       "      <td>sassi</td>\n",
       "      <td>sassi</td>\n",
       "      <td>sassi</td>\n",
       "      <td>[&#x27;sassi&#x27;]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>sassi</td>\n",
       "      <td>sasi</td>\n",
       "      <td>sasi</td>\n",
       "      <td>[&#x27;sasi&#x27;]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>adt</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('sássi', [{'normalized_text': 'sassi', 'lemma': 'sassi', 'root': 'sassi', 'root_tokens': ['sassi'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}, {'normalized_text': 'sassi', 'lemma': 'sasi', 'root': 'sasi', 'root_tokens': ['sasi'], 'ending': '0', 'clitic': '', 'form': 'adt', 'partofspeech': 'S'}])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdict.retag(text)\n",
    "text.morph_analysis[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaadeldavas lauses on siiski õige vaid üks kahest analüüsist.\n",
    "Impordime Vabamorfi lausepõhise ühestaja, et saada ühestatud `morph_analysis` kiht uute tulemuste põhjal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">sássi</span></span></td>\n",
       "      <td>sassi</td>\n",
       "      <td>sassi</td>\n",
       "      <td>sassi</td>\n",
       "      <td>[&#x27;sassi&#x27;]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('sássi', [{'normalized_text': 'sassi', 'lemma': 'sassi', 'root': 'sassi', 'root_tokens': ['sassi'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import VabamorfDisambiguator\n",
    "\n",
    "vm_disambiguator = VabamorfDisambiguator()\n",
    "vm_disambiguator.retag(text)\n",
    "text.morph_analysis[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Kasutajasõnastiku (pool-)automaatne loomine\n",
    "\n",
    "Suure korpuse korral on kasutajasõnastiku loomine siiski väga töömahukas tegevus ning täieliku käsitööna mitte eriti mõeldav. Parem lähenemine on kirjakeelsete vastete leidmine vähemalt osaliselt automatiseerida. Järgnevates ülesannetes uurimegi üht sellise automatiseerimisprotsessi alamosa: tundmatutele sõnadele kirjakeelsete vastete leidmist. Kõigepealt peame aga kindlaks tegema, millised sõnad saab üldse tundmatuteks lugeda (arvestades uuritava korpuse sõnestuse eripärasid)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ülesanne 3: Tundmatud sõnad (1,5 p)\n",
    "\n",
    "Looge programm, mis loeb failist `'netikeele_laused.txt'` laused (failis on iga lause eraldi real) ning teostab lausetel morf analüüsi (ilma oletamise, pärisnimede pakkumise ja ühestamiseta). \n",
    "\n",
    "Programm leiab: \n",
    "* mitu protsenti kõigist sõnadest jäid morf analüsaatorile tundmatuks (st sõnadele ei leitud analüüse)\n",
    "* 10 lauset, mis sisaldavad kõige rohkem tundmatuid sõnu.\n",
    "\n",
    "Leitud 10 lauset ja nendes tundmatuks jäänud sõnad väljastatakse ekraanile ning ühtlasi salvestatakse ka kuhugi andmestruktuuri – neid läheb tarvis ka järgmises ülesandes. Ekraanile väljastamisel peavad laused olema sorteeritud \"tundmatute arvu järgi\" kahanevalt.\n",
    "\n",
    "  * Sõnade loendamisel tuleks välja jätta 1-tähelised \"sõnad\", ainult numbritest ja punktuatsioonist koosnevad sõnad (st näiteks 20-aastane on korrektne sõna);\n",
    "  * \"Tundmatute sõnade\" hulka ei tuleks lugeda punktuatsiooni;\n",
    "  * 10 kõige rohkem tundmatuid sõnu sisaldava lause hulka võib sattuda ka lauseid, milles on sama arv tundmatuid sõnu. Kui viimas(t)ele positsiooni(de)le on valida mitme sama arvu tundmatuid sisaldava lause vahel, siis võib valida lause(d), mis on algses (failis olevas) järjestuses eespool;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teisenduskauguse abil vastete leidmine\n",
    "\n",
    "Nüüd on meil teada, millist laadi sõnadele tuleb hakata kirjakeelseid vasteid otsima. \n",
    "Aga kuidas vasteid leida?\n",
    "Tehniliselt kõige lihtsam lähenemine on kasutada juba valmislahendust – proovida eelmises praktikumis tutvustatud automaatset õigekirjakorrektorit, mida võib ka rakendada tundmatutele sõnadele vastete leidmiseks.\n",
    "Siiski ei pruugi õigekirjakorrektor kõige paremaid tulemusi anda netikeele kõige konarlikemates lausetes, kus esineb eri tüüpi vigu ning nii mõnigi kord on tegemist süstemaatilise \"teisiti kirjutamisega\". \n",
    "\n",
    "Üldine meetod, mida rakendab (küll teatavate lisanüanssidega) ka õigekirjakorrektor, on tundmatute sõnade võrdlemine teadaolevate sõnade leksikoniga ning sõnade _sarnasuse_ põhjal vastete väljapakkumine. \n",
    "Seega, kui meil on olemas piisavalt mahukas kirjakeele korpus, võime selle põhjal ka ise teha teadaolevate sõnade loendi, noppida loendist välja tundmatute sõnadega _sarnased_ sõnad ja pakkuda neid vasteteks.\n",
    "\n",
    "_Kuidas hinnata sõnade sarnasust?_ Siin tuleb appi teisenduskaugus (ingl *edit distance*). Sisuliselt mõõdab teisenduskaugus, mitu teisendust/muutust tuleb teha, et saada ühest sõnest teine. Tavaliselt lubatakse kolme tüüpi muutuseid: 1) ühe tähe kustutamine, 2) ühe tähe lisamine, 3) ühe tähe asendamine mingi teise tähega. Teisenduskaugus ütleb, mitu sellist muutust tuleb minimaalselt teha – mida väiksem arv, seda sarnasemad kaks sõna on.\n",
    "\n",
    "Teisenduskauguse leidmist võib katsetada funktsiooni `nltk.metrics.distance.edit_distance` abil (funktsiooni sisaldav teek `nltk` peaks teil olema juba installitud, kuna see on üks `estnltk` eelduseid):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.metrics.distance import edit_distance\n",
    "\n",
    "edit_distance('pizza', 'pitsa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance('mõttetu', 'mõtetu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance('uit', 'uit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vt ka `nltk` teisenduskauguse funktsiooni [detailsemat kirjeldust](http://www.nltk.org/api/nltk.metrics.html#nltk.metrics.distance.edit_distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 4: Tundmatutele sõnadele vastete leidmine (2 p)\n",
    "\n",
    "See ülesanne koosneb kahest osast:\n",
    "\n",
    "#### Ülesanne 4.A: Minu soovitaja (1,25 p)\n",
    "\n",
    "Looge funktsioon, mis saab sisendiks tundmatu sõna ning tagastab sellele kõige sarnasemad vasted kirjakeelest. \n",
    "Funktsioon võiks osata pakkuda natukene rohkem vasteid kui EstNLTK [õigekirjakontrollija](https://nbviewer.jupyter.org/github/estnltk/estnltk/blob/version_1.6/tutorials/nlp_pipeline/B_03_segmentation_words_spelling_normalization.ipynb). \n",
    "Seega, esimese sammuna võibki funktsioon kasutada õigekirjakorrektorit vastete leidmiseks, aga kui korrektor midagi pakkuda ei oska, tuleks teisenduskauguse abil ise vasteid otsida. \n",
    "Funktsioon tagastab sarnaste sõnade järjendi (ja tühijärjendi, kui vasteid üldse ei leitud).\n",
    "\n",
    "Teisenduskauguse abil võiks vasteid otsida ajakirjandustekstide sõnavarast (kataloogi `'aja_sloleht_1999_04_k'` tekstidest). \n",
    "Kui suures osas ajakirjendustekstide sõnavara tuleks arvestada (mida jätta ja mida võtta), jääb teie otsustada.\n",
    "Samuti jääb teie otsustada, kui palju ja millisel teisenduskaugusel vasteid tagastatakse (üldine põhimõte on, et mida vähem ja täpsemaid vasteid pakutakse, seda parem).\n",
    "\n",
    "  * **NB!** Kataloogi 'aja_sloleht_1999_04_k' tekstide sisselugemine ja nende põhjal sõnaloendi moodustamine peaks toimuma ainult üks kord – kindlasti ei tohiks seda teha igal soovitaja-funktsiooni väljakutsel. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ülesanne 4.B: Soovitaja rakendamine tundmatute tuvastamiseks (0,75 p)\n",
    "\n",
    "Rakendage oma soovitaja-funktsiooni ülesandes 3 leitud kümne \"kõige konarlikuma\" lause tundmatutel sõnadel. Väljastage:\n",
    "\n",
    "   * laused ning iga lause all nii tundmatud sõnad kui ka neile pakutavad vasted;\n",
    "   * (üle kõigi lausete) mitmele %-le tundmatutest sõnadest pakutakse vasteid;\n",
    "   * (üle kõigi lausete) milline on keskmine soovituste arv (ehk siis: mitu vastet keskmiselt iga tundmatu sõna kohta soovitatakse);\n",
    "\n",
    "Vajadusel täiendage oma funktsiooni nii, et vähemalt 90% tundmatutest sõnadest saaksid soovitusi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soovitustest kasutajasõnastikuni\n",
    "\n",
    "Eelmises ülesandes arendasime ja katsetasime soovitusfunktsiooni 10 lause tundmatutel sõnadel. \n",
    "Praktikas on tavaliselt eesmärgiks terve korpuse analüüs, seega on ka ülesanne üksjagu töömahukam. \n",
    "Kuidas praktikas kohandada morfoloogiline analüsaator netikeele tekstide analüüsimiseks, on kirjeldatud detailsemalt [selles artiklis](https://www.etis.ee/File/DownloadPublic/ef492abe-ba06-4e86-9fee-a7e5cd44eeb6?name=Fail_ERYa7.07_Muischnek_pp111-127.pdf&type=application%2Fpdf). Üldine põhimõte on järgmine. Kirjakeelest erinevad ja haruldased sõnad peaksid olema kirjakeelsetest vormidest tuletatavad suhteliselt regulaarsete teisenduste abil. Ehk siis leitavad teisenduskauguse või veelgi spetsiifilisemate teisenduste kaudu; nende lisamine kasutajasõnastikku võiks toimuda suhteliselt automaatselt. Samas, kui sõnavorm pole tuletavav kirjakeelsest sõnast regulaarse teisenduse abil, peaks ta olema sageli kasutatav (\"et tema tähendus ja funktsioon kasutajatel meeles püsiks\") ja seega korpuse sõnasageduste uurimisel silma torkama. Sellised sõnavormid tuleks siis korpuse sagedusloendite uurimisel välja selgitada ja lisada kasutajasõnastikku käsitsi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giellatekno (GT) morfoloogilised kategooriad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siiani oleme vaadanud, kuidas parandada oma teksti morfoloogilist analüüsi nii, et see etteantud morfoloogiliste kategooriate süsteemis võimalikult korrektselt analüüsitud saaks. Võib aga juhtuda ka nii, et tekst on küll (piisavalt) korrektselt analüüsitud vaikimisi kasutatavate kategooriate järgi, ent see siiski millegipärast ei rahulda teksti töötlejat. Seetõttu on EstNLTK-s lisaks vaikimisi kasutatavale Filosofti süsteemile ka teine morfoloogiliste kategooriate süsteem: Giellatekno (GT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giellatekno morfoloogiliste kategooriate süsteemi saab EstNLTK-s kasutada järgnevalt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.taggers import GTMorphConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_converter = GTMorphConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Text('Mis siis, et kuuldavasti teevadki Poola torumehed nii Pariisis kui ka Brüsselis torud reaalselt korda.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GT morfoloogilise analüüsi tegemiseks peab olema tehtud nii morfoloogiline analüüs, kui ka osalausete märgendus, mida vaikimisi ei tehta. Osalauseanalüüs nõuab sõnade, lausete ja morfanalüüsi kihi olemasolu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "**Tehniline vahemärkus**: osalauseanalüüs kasutab java-t. Seega tuleb enne analüüsimist:\n",
    "* Installida süsteemi [*Java SE Runtime Environment*](https://www.java.com/en/download/win10.jsp);\n",
    "* Panna java käsk süsteemi keskkonnamuutujasse PATH. Windows-i ja Mac-i puhul tehakse seda tüüpiliselt juba installi käigus, aga kui on siiski tarvis seda käsitsi teha, siis detailsemat abi saab [siit](https://java.com/en/download/help/path.xml);\n",
    "\n",
    "\n",
    "Kuidas kontrollida, kas java on juba olemas või kas installimine õnnestus? Käsureakäsk `java -version` peaks kuvama infot installitud java versiooni kohta, näiteks midagi taolist:\n",
    "\n",
    "~~~\n",
    "java version \"14.0.1\" 2020-04-14\n",
    "Java(TM) SE Runtime Environment (build 14.0.1+7)\n",
    "Java HotSpot(TM) 64-Bit Server VM (build 14.0.1+7, mixed mode, sharing)  \n",
    "~~~\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Mis siis, et kuuldavasti teevadki Poola torumehed nii Pariisis kui ka Brüsselis torud reaalselt korda.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Mis siis, et kuuldavasti teevadki Poola torumehed nii Pariisis kui ka Brüsselis torud reaalselt korda.')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Märgendame tekstile peale vaikimisi toimiva Filosofti analüüsi\n",
    "text.tag_layer(['clauses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Mis siis, et kuuldavasti teevadki Poola torumehed nii Pariisis kui ka Brüsselis torud reaalselt korda.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gt_morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Mis siis, et kuuldavasti teevadki Poola torumehed nii Pariisis kui ka Brüsselis torud reaalselt korda.')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teisendame morfoloogilise analüüsi GT formaati - tulemused on salvestatud kihis gt_morph_analysis\n",
    "gt_converter.tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>gt_morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mis</td>\n",
       "      <td>Mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>('mis',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Pl Nom</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>mis</td>\n",
       "      <td>('mis',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Sg Nom</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>siis</td>\n",
       "      <td>siis</td>\n",
       "      <td>siis</td>\n",
       "      <td>siis</td>\n",
       "      <td>('siis',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>(',',)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>('et',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kuuldavasti</td>\n",
       "      <td>kuuldavasti</td>\n",
       "      <td>kuuldavasti</td>\n",
       "      <td>kuuldavasti</td>\n",
       "      <td>('kuuldavasti',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teevadki</td>\n",
       "      <td>teevadki</td>\n",
       "      <td>tegema</td>\n",
       "      <td>tege</td>\n",
       "      <td>('tege',)</td>\n",
       "      <td>vad</td>\n",
       "      <td>ki</td>\n",
       "      <td>Pers Prs Ind Pl 3 Aff</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Poola</td>\n",
       "      <td>Poola</td>\n",
       "      <td>Poola</td>\n",
       "      <td>Poola</td>\n",
       "      <td>('Poola',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Sg Gen</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>torumehed</td>\n",
       "      <td>torumehed</td>\n",
       "      <td>torumees</td>\n",
       "      <td>toru_mees</td>\n",
       "      <td>('toru', 'mees')</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>Pl Nom</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nii</td>\n",
       "      <td>nii</td>\n",
       "      <td>nii</td>\n",
       "      <td>nii</td>\n",
       "      <td>('nii',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pariisis</td>\n",
       "      <td>Pariisis</td>\n",
       "      <td>Pariis</td>\n",
       "      <td>Pariis</td>\n",
       "      <td>('Pariis',)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>Sg Ine</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kui</td>\n",
       "      <td>kui</td>\n",
       "      <td>kui</td>\n",
       "      <td>kui</td>\n",
       "      <td>('kui',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kui</td>\n",
       "      <td>kui</td>\n",
       "      <td>kui</td>\n",
       "      <td>('kui',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>('ka',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Brüsselis</td>\n",
       "      <td>Brüsselis</td>\n",
       "      <td>Brüssel</td>\n",
       "      <td>Brüssel</td>\n",
       "      <td>('Brüssel',)</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>Sg Ine</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>torud</td>\n",
       "      <td>torud</td>\n",
       "      <td>toru</td>\n",
       "      <td>toru</td>\n",
       "      <td>('toru',)</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>Pl Nom</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>reaalselt</td>\n",
       "      <td>reaalselt</td>\n",
       "      <td>reaalselt</td>\n",
       "      <td>reaalselt</td>\n",
       "      <td>('reaalselt',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>korda</td>\n",
       "      <td>korda</td>\n",
       "      <td>kord</td>\n",
       "      <td>kord</td>\n",
       "      <td>('kord',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Sg Par</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>('.',)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='gt_morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Mis', [{'normalized_text': 'Mis', 'lemma': 'mis', 'root': 'mis', 'root_tokens': ('mis',), 'ending': '0', 'clitic': '', 'form': 'Pl Nom', 'partofspeech': 'P'}, {'normalized_text': 'Mis', 'lemma': 'mis', 'root': 'mis', 'root_tokens': ('mis',), 'ending': '0', 'clitic': '', 'form': 'Sg Nom', 'partofspeech': 'P'}]),\n",
       "Span('siis', [{'normalized_text': 'siis', 'lemma': 'siis', 'root': 'siis', 'root_tokens': ('siis',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': (',',), 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('et', [{'normalized_text': 'et', 'lemma': 'et', 'root': 'et', 'root_tokens': ('et',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('kuuldavasti', [{'normalized_text': 'kuuldavasti', 'lemma': 'kuuldavasti', 'root': 'kuuldavasti', 'root_tokens': ('kuuldavasti',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('teevadki', [{'normalized_text': 'teevadki', 'lemma': 'tegema', 'root': 'tege', 'root_tokens': ('tege',), 'ending': 'vad', 'clitic': 'ki', 'form': 'Pers Prs Ind Pl 3 Aff', 'partofspeech': 'V'}]),\n",
       "Span('Poola', [{'normalized_text': 'Poola', 'lemma': 'Poola', 'root': 'Poola', 'root_tokens': ('Poola',), 'ending': '0', 'clitic': '', 'form': 'Sg Gen', 'partofspeech': 'H'}]),\n",
       "Span('torumehed', [{'normalized_text': 'torumehed', 'lemma': 'torumees', 'root': 'toru_mees', 'root_tokens': ('toru', 'mees'), 'ending': 'd', 'clitic': '', 'form': 'Pl Nom', 'partofspeech': 'S'}]),\n",
       "Span('nii', [{'normalized_text': 'nii', 'lemma': 'nii', 'root': 'nii', 'root_tokens': ('nii',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('Pariisis', [{'normalized_text': 'Pariisis', 'lemma': 'Pariis', 'root': 'Pariis', 'root_tokens': ('Pariis',), 'ending': 's', 'clitic': '', 'form': 'Sg Ine', 'partofspeech': 'H'}]),\n",
       "Span('kui', [{'normalized_text': 'kui', 'lemma': 'kui', 'root': 'kui', 'root_tokens': ('kui',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}, {'normalized_text': 'kui', 'lemma': 'kui', 'root': 'kui', 'root_tokens': ('kui',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('ka', [{'normalized_text': 'ka', 'lemma': 'ka', 'root': 'ka', 'root_tokens': ('ka',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('Brüsselis', [{'normalized_text': 'Brüsselis', 'lemma': 'Brüssel', 'root': 'Brüssel', 'root_tokens': ('Brüssel',), 'ending': 's', 'clitic': '', 'form': 'Sg Ine', 'partofspeech': 'H'}]),\n",
       "Span('torud', [{'normalized_text': 'torud', 'lemma': 'toru', 'root': 'toru', 'root_tokens': ('toru',), 'ending': 'd', 'clitic': '', 'form': 'Pl Nom', 'partofspeech': 'S'}]),\n",
       "Span('reaalselt', [{'normalized_text': 'reaalselt', 'lemma': 'reaalselt', 'root': 'reaalselt', 'root_tokens': ('reaalselt',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('korda', [{'normalized_text': 'korda', 'lemma': 'kord', 'root': 'kord', 'root_tokens': ('kord',), 'ending': '0', 'clitic': '', 'form': 'Sg Par', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ('.',), 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.gt_morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boonusülesanne (0,5p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutvuge giellatekno formaadis morfoloogilise analüüsiga. Selleks teisendage järgneva teksti analüüs GT kujule ning printige välja iga tekstisõna koos selle mõlemas formaadis morfoloogilise analüüsiga (*form*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Kaks telgipäeva, 12. ja 13. juunil Tallinnas Vabaduse väljakul läksid väga edukalt. Saime kogeda nii vihma kui ka päikest, mürtsus puhkpillimuusika, ajakirjanikud sagisid ringi ning mis peamine – telgid olid tulvil heategudest. Kas ka sina käisid? Kui ei, tule järgmine aasta, paremat võimalust ei tule.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vastake küsimustele:\n",
    "* Mis on suurim sisuline erinevus GT ja Filosofti analüüside vahel? Vihje: vaadake verbianalüüse\n",
    "* Katseta *converter*'i loomisel lippe `disambiguate_sid_ksid=False` ja `disambiguate_neg=False`. Mis muutub?\n",
    "* Kui lähtuda teksti morfoloogilise analüüsi täpsusest ja saagisest, siis millisel juhul oleks mõistlik kasutada GT kuju, millisel juhul Filosofti oma?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analüüsi tõlgendamisel saab abi [siit](http://www.keeleveeb.ee/dict/corpus/shared/categories.html), soovi korral rohkem infot verbi morfoloogiliste kategooriate esitamise võimaluste kohta [siit](https://keeljakirjandus.ee/wp-content/uploads/2019/11/HJKaalep1_15.pdf)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
