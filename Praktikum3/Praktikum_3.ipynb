{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue\">Praktikum 3. Morfoloogilise analüüsi erijuhud</h1>\n",
    "<h3 style=\"color:blue\">Korpusepõhine ühestamine, morfoloogiline analüüs kasutajasõnastiku abil ja Giellatekno märgendid</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tänases praktikumis jätkame morfoloogilise analüüsi ja ühestamise teemadega. Kuna keerukamad analüüsitasemed (süntaks, semantika) toetuvad morfoloogilise analüüsi tulemustele, siis on oluline selle taseme analüüsile rohkem tähelepanu pöörata. Eriti oluliseks muutub see siis, kui analüüsida tuleb tekste, mille keelekasutus erineb kirjakeelest, nt netikeelt, slängi vms eesti keele allkeelt. Samuti võib sõnade morfoloogilist analüüsi parandada see, kui arvestame sõnade kasutust laiemas kontekstis: terves tekstis või _korpuses_ ¹."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * ¹ _korpus_ = loomuliku keele tekstide kogu. Täpsema määratluse korpuste kohta lingvistikas leiab [siit](https://et.wikipedia.org/wiki/Keelekorpus)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Teksti- ja korpusepõhine morfoloogiline ühestamine\n",
    "\n",
    "Vaikimisi EstNLTK's kasutatav morfoloogiline ühestamine, millega tutvusite eelmises praktikumis, toimetab ühe lause piires. Lühidalt kirjeldades: statistilist / masinõppe lähenemist kasutades leitakse igale sõnale kontekstist lähtuvalt kõige tõenäolisem morfoloogiline analüüs, sealjuures üksikule sõnale analüüsi valimisel lähtutakse 1-2 eelneva sõna analüüsidest. Detailsemalt kirjeldab statistilist morfoloogilist ühestamist [see artikkel](http://www.cl.ut.ee/yllitised/kk_yhest_1998.pdf).\n",
    "\n",
    "Praktikas töötab lausepõhine ühestamine küllaltki hästi, aga selle täpsust on võimalik siiski veelgi suurendada. Ühe lause piires mitmeseks jäävad sõnad võivad mujal tekstis esineda üheselt tõlgendataval kujul, seega, kui kasutada ühestamisel laiemat konteksti kui üks lause, saame lahendada lausepõhise ühestamise poolt lahendamata jäänud või valesti lahendatud mitmesusi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enne kui läheme edasi, tuleb ära rääkida üks **tehniline, aga siiski oluline jutt**. Eelmises praktikumis vaatasime mitmeid mugavaid variante teksti morfoloogiliste analüüside kättesaamiseks, nt `text.analysis` andis meile kõigi sõnade analüüside järjendi, `text.lemmas` lemmade järjendi, `text.postags` sõnaliikide järjendi jne. Näiliselt on need `Text` objekti atribuudid, aga tegelikult peituvad nende taga nn _mugavusfunktsioonid_. Väljakutsumisel kontrollivad mugavusfunktsioonid kõigepealt, kas morfoloogiline analüüs on tehtud (kui pole, siis teevad selle), ning seejärel nopivad analüüsist välja nõutud tulemused (kas siis lemmad, sõnaliigid vms). Mugavusfunktsioonide kasutamisel tuleb olla aga ettevaatlik, et mitte komistada järgmiste probleemide otsa:\n",
    "\n",
    "* mugavusfunktsioonide (`text.words`, `text.analysis`, `text.lemmas` jne) abil **ei ole võimalik** `Text` objekti sisu muuta. Omistamise saab küll teha (nt `text.words=[]`), aga tegelik sisu sellest ei muutu. Kuna `Text` objekt on sõnastiku-tüüpi andmestruktuur, siis saab selle sisu muuta ainult nii, nagu muudetakse sõnastikku, nt omistades `text['words']=[]`;\n",
    "\n",
    "* mugavusfunktsioonid (`text.words`, `text.analysis`, `text.lemmas` jne) jäädvustavad esimesel väljakutsumisel tagastatava sisu mälupuhvrisse ja edaspidi **tagastavad vana sisu**. Seega, kui muudate `Text` objekti ja kutsute pärast muutmist mugavusfunktsiooni uuesti  välja, ei näe te muutmise tulemust. Ainult siis, kui pöördute `Text` objekti poole kasutades sõnastiku võtmeid (nt `text['words']`), on garanteeritud, et saate kätte kõige värskema sisu;\n",
    "\n",
    "Arvestades neid probleeme ning seda, et käesolevas praktikumis tuleb üsna palju tegemist morfoloogiliste analüüside kohendamise / muutmisega, siis proovime siin kasutada mugavusfunktsioone nii vähe kui võimalik. Andmetele ligipääs on sel viisil küll natukene keerukam, aga samas on garanteeritud, et kõik toimib nii, nagu peab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uurime lause- ja korpusepõhise morfoloogilise ühestamise erinevust järgmise \"näitekorpuse\" varal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.',\\\n",
    "          'Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.', \\\n",
    "          'Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sisuliselt käsitleme järjendi `corpus` iga elementi \"ühe tekstina\". \n",
    "\n",
    "Kõigepealt rakendame korpusel morfoloogilist analüüsi koos tavalise, lausepõhise ühestamisega. Kasutame selleks `Text` objekti meetodit `tag_analysis()`. Sisuliselt teostab see meetod morfoloogilise analüüsi vastavalt sellele, millised olid parameetrite `guess`, `disambiguate` ja `propername` väärtused `Text` objekti loomisel (eelmise praktikumi teema) ning kui ühtegi nimetatud parameetritest ei kasutata, eeldab vaikimisi, et kõik on sisse lülitatud. Pärast teksti ühestamist trükime välja sõnad, mille analüüsid jäid mitmeseks. Kasutame sealjuures väikest tsükli-nõksu, et kuvada morfoloogilise analüüsi tulemused nii, et oluline info oleks ühel real. Väljastame iga sõna analüüside osast ainult lemma, sõnaliigi ja käände-/pöördeinfo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.\n",
      "kohale => [('koht', 'S', 'sg all'), ('koha', 'S', 'sg all')]\n",
      "kuigi => [('kuigi', 'D', ''), ('kuigi', 'J', '')]\n",
      "Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.\n",
      "Teise => [('teine', 'O', 'sg g'), ('teine', 'P', 'sg g')]\n",
      "koha => [('koht', 'S', 'sg g'), ('koha', 'S', 'sg g')]\n",
      "mail => [('maa', 'S', 'pl ad'), ('mai', 'S', 'sg ad')]\n",
      "Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.\n",
      "summaga => [('summ', 'S', 'sg kom'), ('summa', 'S', 'sg kom')]\n",
      "on => [('olema', 'V', 'b'), ('olema', 'V', 'vad')]\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "for text_str in corpus:\n",
    "    text = Text(text_str)\n",
    "    print(text)\n",
    "    # Teostame tavalise, lausepõhise teksti ühestamise\n",
    "    text.tag_analysis()\n",
    "    # Trükime välja mitmeseks jäänud sõnade analüüsid (ainult lemma, sõnaliigi ja vorminimetuse)\n",
    "    for word in text['words']:\n",
    "        if len(word['analysis']) > 1:\n",
    "            print( word['text'],'=>',[(a['lemma'],a['partofspeech'],a['form']) for a in word['analysis']] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näha, on ühestamise tulemustes parandamisruumi küll. Proovime korpusepõhist ühestamist.\n",
    "\n",
    "EstNLTK's klass `Disambiguator` sisaldab meetodit `disambiguate()`, millele antakse sisendiks analüüsitav korpus järjendi kujul. See võibki olla sõnede järjend, nagu meie näitejärjend `corpus`, aga see võib olla ka järjend, mis koosneb `Text` objektidest. Viimasel juhul on oluline meeles pidada, et kui annate sisendiks järjendi `Text` objektidest, millele on juba tehtud morfoloogiline analüüs, siis vanad analüüsitulemused kustutatakse ning analüüsiga alustatakse nullist.\n",
    "\n",
    "Sisuliselt teostab meetod `disambiguate()` nii tavalise kui ka korpusepõhise ühestamise ning tagastab järjendi `Text` objektidest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Disambiguator\n",
    "disamb = Disambiguator()\n",
    "\n",
    "# Rakendame korpusepõhist ühestamist näitekorpusel\n",
    "disambiguated_texts = disamb.disambiguate(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uurime tulemusi -- väljastame uuesti mitmesed analüüsid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.\n",
      "kuigi => [('kuigi', 'D', ''), ('kuigi', 'J', '')]\n",
      "Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.\n",
      "Teise => [('teine', 'O', 'sg g'), ('teine', 'P', 'sg g')]\n",
      "Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.\n",
      "on => [('olema', 'V', 'b'), ('olema', 'V', 'vad')]\n"
     ]
    }
   ],
   "source": [
    "for text in disambiguated_texts:\n",
    "    print(text.text)\n",
    "    # Trükime välja mitmeseks jäänud sõnade analüüsid (ainult lemma, sõnaliigi ja vorminimetuse)\n",
    "    for word in text['words']:\n",
    "        if len(word['analysis']) > 1:\n",
    "            print( word['text'],'=>',[(a['lemma'],a['partofspeech'],a['form']) for a in word['analysis']] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lisaks on korpusepõhisest ühestamisest abi pärisnimeanalüüside korrastamisel. Kui mingi tavaline sõna on korpuse tekstides tõenäoliselt kasutusel pärisnimena (st esineb suure algustähega ka lausete keskel), siis valib korpusepõhine ühestaja pärisnime-analüüsid selle sõna tavapäraste analüüside asemel. Uurime, millised analüüsid valiti näitekorpuse suure tähega algavatele sõnadele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.\n",
      "Esimesele => [('esimene', 'O', 'sg all')]\n",
      "Jänes => [('Jänes', 'H', 'sg n')]\n",
      "Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.\n",
      "Lõpparvestuses => [('lõpparvestus', 'S', 'sg in')]\n",
      "Konnale => [('Konn', 'H', 'sg all')]\n",
      "Teise => [('teine', 'O', 'sg g'), ('teine', 'P', 'sg g')]\n",
      "Jänes => [('Jäne', 'H', 'sg in')]\n",
      "Uus => [('uus', 'A', 'sg n')]\n",
      "Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.\n",
      "Konn => [('Konn', 'H', 'sg n')]\n",
      "Uue => [('uus', 'A', 'sg g')]\n"
     ]
    }
   ],
   "source": [
    "for text in disambiguated_texts:\n",
    "    print(text.text)\n",
    "    # Trükime välja suure tähega algavate sõnade analüüsid\n",
    "    for word in text['words']:\n",
    "        if word['text'].istitle():\n",
    "            print( word['text'],'=>',[(a['lemma'],a['partofspeech'],a['form']) for a in word['analysis']] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näha, on sõnad _Jänes_ ja _Konn_ saanud pärisnime sõnaliigimärgendi (`'H'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Tekstipõhine ühestamine_**. Korpusepõhise ühestaja abil võib teostada ka tekstipõhist ühestamist ehk siis: ühestamist, kus \"korpuseks\" on üks tekst. \n",
    "See võib olla vajalik siis, kui korpuse tekstid on väga heterogeensed ning üks sõna võib esineda kahes tekstis täiesti erinevates tähendustes (omada erinevat lemmat). \n",
    "Sellisel juhul võib liiga lai ühestamiskontekst (terve korpus) ajada lemmad valeks ning parem on piirduda väiksema kontekstiga.\n",
    "\n",
    "Tekstipõhiseks ühestamiseks tuleb lihtsalt ühestamismeetodile anda ette järjend, mis sisaldab ühte teksti:\n",
    "\n",
    "       disamb = Disambiguator()\n",
    "       disambiguated_texts = disamb.disambiguate([my_text])\n",
    "       \n",
    "ning pärast tulemusteks saadud järjendist tekst uuesti välja noppida:\n",
    "       \n",
    "       disambiguated_text = disambiguated_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korpusepõhise ühestamise teooriat kirjeldab [see artikkel](https://www.etis.ee/File/DownloadPublic/ce4606c7-41ba-4059-ac6d-6db2e40442e9?name=Fail_FAIA247-0082.pdf&type=application%2Fpdf). EstNLTK korpusepõhise ühestaja liidest kirjeldab detailsemalt [see abimaterjal](https://estnltk.github.io/estnltk/1.4.1/tutorials/disambiguation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 1: Kui palju vähendab korpusepõhine ühestamine mitmesust? (1,25p)\n",
    "\n",
    "Esimeseks ülesandeks on uurida, kui palju vähendab **korpusepõhine ühestamine** mitmesust. Kataloogis `'aja_sloleht_1999_04_k'` on SL Õhtulehe ajaleheartiklid. \n",
    "Igas failis on üks artikkel. \n",
    "Lugege sealt tekstid sisse ning teostage morfoloogiline ühestamine kahel erineval viisil: 1) tavaline, nn lausepõhine ühestamine, 2) korpusepõhine ühestamine, kus korpuseks on kõik artiklid, st terve kataloogi sisu.\n",
    "Leidke ja väljastage mõlema ühestamisetapi kohta mitmeseks jäänud sõnade arv ja osakaal kõigist sõnadest (%).\n",
    "\n",
    "Lisajuhis:\n",
    "\n",
    " * Failide kõvakettalt sisselugemine on üldiselt ressurssinõudlik operatsioon; seetõttu on soovitav ülesanne lahendada nii, et loete kõigi failide sisud kõigepealt mällu (nt järjendisse) ja lahendate alamülesanded 1) ja 2) mälus olevatel andmetel;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 2: Pärisnimede ühestamise kvaliteedi uurimine (1,75 p)\n",
    "\n",
    "Korpuste kasutajaid huvitab sageli pärisnimede otsimine. \n",
    "Järgnev ülesanne on uurida, kas ja kuidas aitab **tekstipõhine ühestamine** kaasa pärisnimeanalüüside kvaliteedi paranemisele.\n",
    "Looge programm, mis analüüsib korpust kataloogis `'aja_sloleht_1999_04_k'` ning väljastab kõik laused, kus leidub sõnu, mille puhul tavaline ühestamine ei andnud üldse pärisnime analüüsi, aga tekstipõhise ühestamise järel sai sõna ühese pärisnime analüüsi. Programm väljastab lausete tekstid, ühese pärisnimeanalüüsi saanud sõnad ja nende analüüside muutuse. Näide:\n",
    "\n",
    "    >> aja_sloleht_1999_04_15__20.txt\n",
    "    Matkamiksi peakorraldaja Andrus Nõmm tunnistas , et turvafirma Desperada kuuele töötajale ei ole tal midagi ette heita .\n",
    "     Nõmm\n",
    "       [('nõmm', 'S', 'sg n')]\n",
    "       ==>\n",
    "       [('Nõmm', 'H', 'sg n')]\n",
    "\n",
    "    “ Olin ka ise seal , ” rääkis Nõmm .\n",
    "     Nõmm\n",
    "       [('nõmm', 'S', 'sg n')]\n",
    "       ==>\n",
    "       [('Nõmm', 'H', 'sg n')]\n",
    "\n",
    "    Viha noorukite peale Kare ei pea , sest kaupluse alkoholikäive suurened messi ajal mitu korda .\n",
    "     Kare\n",
    "       [('kare', 'A', 'sg n')]\n",
    "       ==>\n",
    "       [('Kare', 'H', 'sg n')]\n",
    "    \n",
    "Kuidas sellele ülesandele võiks läheneda? Teostage kõigepealt kataloogi `'aja_sloleht_1999_04_k'` failidel tekstipõhised ühestamised ning paigutage ühestamise tulemused (morfoloogiliselt ühesed `Text` objektid) järjendisse.\n",
    "Seejärel läbige tekstid lause-kaupa ning leidke igast lausest sõnad, mis said (tekstipõhise) ühestamise tulemusena ühese pärisnime analüüsi (sõnaliik: `'H'`).\n",
    "Kui lauses leidus vähemalt üks selline sõna, teostage kogu lausel (lause tekstil) morfoloogiline analüüs uuesti, aga kasutage nüüd tavalist ühestamist (eelmise ülesande ühestamine 1).\n",
    "Lõpuks võrrelge kahe ühestamise tulemusi pärisnimeanalüüsi saanud sõnade peal ja leidke sobiva muutusega sõnad.\n",
    "Väljastage laused, kuhu tekkisid ühese pärisnimeanalüüsiga sõnad, ning vastavad sõnad ja nende analüüside muutused (väljund võiks olla eeltoodud näitega sarnane).\n",
    "\n",
    "Veel näpunäiteid:\n",
    "\n",
    "  * Kui teete tsükli, mis käib üle korpuse kõigi tekstide, arvestage sellega, et korpus on üksjagu mahukas. Alguses on katsetamiseks soovitav teha kõigepealt tsükkel, mis katkestatakse [`break`](https://docs.python.org/3.5/tutorial/controlflow.html#break-and-continue-statements-and-else-clauses-on-loops) käsuga, kui teatud arv esimesi tekste (või lauseid) on juba läbitud. Kui olete jõudnud niikaugele, et programm töötab ilusti väiksel osal korpusest, siis saab ka katkestusest loobuda ja panna tsükli(d) jooksma üle kogu korpuse;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morfoloogiline analüüs ja ühestamine kasutajasõnastiku abil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morfoloogiline analüsaator töötab kõige paremini tekstidel, mis järgivad kirjakeele norme. Kuigi analüsaator sisaldab ka tundmatute sõnade oletajat, ei saa selle täpsusele lootma jääda, kui analüüsitavad tekstid erinevad kirjakeelest suurel määral. Seetõttu kasutatakse netikeele vms eesti keele allkeele automaatseks analüüsimiseks nn _kasutajasõnastiku lähenemist_. Kõigepealt luuakse (poolautomaatselt) kasutajasõnastik, kus on toodud kirjakeelest erinevate sõnavormide korrektsed morfoloogilised analüüsid. Seejärel teostatakse automaatne morfoloogiline analüüs ilma ühestamiseta ning analüüsi tulemustes asendatakse kasutajasõnastikus olevate sõnade (automaat)analüüsid nende korrektsete analüüsidega. Viimase sammuna rakendatakse morfoloogiliselt analüüsitud tekstil ühestamist.\n",
    "\n",
    "Vaatame seda protsessi samm-sammult ühe netikeele lause näitel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Sa ajad sássi inimmeste erinevad käsitlusviisid ja lóodusnähhtuste kinndla vahekorra.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meie näide on lihtne selles mõttes, et kuigi siin on mitte-kirjakeelseid sõnavorme (nt _inimmeste_, _lóodusnähhtuste_), leidub kõigile sõnadele siiski kirjakeeles vaste. Seega saame tekitada mitte-kirjakeelsete vormide morfoloogilised analüüsid, kui analüüsime vastavaid kirjakeele sõnavorme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "# Loome uue kasutajasõnastiku\n",
    "user_dict = {}\n",
    "# Lisame tundmatute sõnade vormid koos neile vastavate kirjakeele sõnade analüüsidega\n",
    "user_dict[\"inimmeste\"]       = Text('inimeste', guess=False, disambiguate=False, propername=False ).analysis[0]\n",
    "user_dict[\"lóodusnähhtuste\"] = Text('loodusnähtuste', guess=False, disambiguate=False, propername=False ).analysis[0]\n",
    "user_dict[\"kinndla\"]         = Text('kindla', guess=False, disambiguate=False, propername=False ).analysis[0]\n",
    "user_dict[\"sássi\"]           = Text('sassi', guess=False, disambiguate=False, propername=False ).analysis[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tulemuseks saame sellise sõnastiku:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inimmeste': [{'clitic': '',\n",
       "   'ending': 'te',\n",
       "   'form': 'pl g',\n",
       "   'lemma': 'inimene',\n",
       "   'partofspeech': 'S',\n",
       "   'root': 'inimene',\n",
       "   'root_tokens': ['inimene']}],\n",
       " 'kinndla': [{'clitic': '',\n",
       "   'ending': '0',\n",
       "   'form': 'sg g',\n",
       "   'lemma': 'kindel',\n",
       "   'partofspeech': 'A',\n",
       "   'root': 'kindel',\n",
       "   'root_tokens': ['kindel']}],\n",
       " 'lóodusnähhtuste': [{'clitic': '',\n",
       "   'ending': 'te',\n",
       "   'form': 'pl g',\n",
       "   'lemma': 'loodusnähtus',\n",
       "   'partofspeech': 'S',\n",
       "   'root': 'loodus_nähtus',\n",
       "   'root_tokens': ['loodus', 'nähtus']}],\n",
       " 'sássi': [{'clitic': '',\n",
       "   'ending': '0',\n",
       "   'form': '',\n",
       "   'lemma': 'sassi',\n",
       "   'partofspeech': 'D',\n",
       "   'root': 'sassi',\n",
       "   'root_tokens': ['sassi']},\n",
       "  {'clitic': '',\n",
       "   'ending': '0',\n",
       "   'form': 'adt',\n",
       "   'lemma': 'sasi',\n",
       "   'partofspeech': 'S',\n",
       "   'root': 'sasi',\n",
       "   'root_tokens': ['sasi']}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * _Aga kui morfoloogiline analüsaator ei oskagi kirjakeelset vastet analüüsida (tegemist on uudissõnaga vms)?_ Siis on põhimõtteliselt võimalik sõna morfoloogiliste analüüside järjend ka ise käsitsi tekitada. Sellisel juhul tuleks aga väga täpselt jälgida, et analüüse kirjeldavad sõnastikud sisaldaksid kõiki nõutud võtmeid (`'clitic'`, `'ending'`, `'form'`, `'lemma'`, `'partofspeech'`, `'root'`, `'root_tokens'`) ja võtmete väärtused oleksid sellises formaadis, mida kasutab morfoloogiline analüsaator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Järgmise sammuna teostame tekstil morfoloogilise analüüsi ilma ühestamise ja pärisnimede oletamiseta. Oletamise enda jätame sisse (selleks, et lauselõpu punktile ikkagi analüüs külge tuleks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teostame morf analüüsi (oletamisega, aga ilma ühestamiseta)\n",
    "morph_analysed = Text(text, guess=True, disambiguate=False, propername=False)\n",
    "morph_analysed = morph_analysed.tag_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kasutame taaskord \"kompaktset\" tulemuste väljastamise viisi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sa => [('sina', 'P', 'sg n')]\n",
      "ajad => [('aeg', 'S', 'pl n'), ('ajama', 'V', 'd')]\n",
      "sássi => [('sáss', 'S', 'adt'), ('sáss', 'S', 'sg g'), ('sáss', 'S', 'sg p'), ('sássi', 'S', 'sg g'), ('sássi', 'S', 'sg n')]\n",
      "inimmeste => [('inimmest', 'S', 'pl p')]\n",
      "erinevad => [('erinema', 'V', 'vad'), ('erinev', 'A', 'pl n')]\n",
      "käsitlusviisid => [('käsitlusviis', 'S', 'pl n')]\n",
      "ja => [('ja', 'J', '')]\n",
      "lóodusnähhtuste => [('lóodusnähhtune', 'A', 'pl g'), ('lóodusnähhtus', 'S', 'pl g'), ('lóodusnähhtuste', 'S', 'sg g'), ('lóodusnähhtuste', 'S', 'sg n')]\n",
      "kinndla => [('kinndla', 'S', 'sg g'), ('kinndla', 'S', 'sg n')]\n",
      "vahekorra => [('vahekord', 'S', 'sg g')]\n",
      ". => [('.', 'Z', '')]\n"
     ]
    }
   ],
   "source": [
    "for word in morph_analysed['words']:\n",
    "    analysis = [ (a['lemma'], a['partofspeech'], a['form']) for a in word['analysis'] ]\n",
    "    print( word['text'],'=>',analysis )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu tulemustest võib näha, on oletaja segaduses ja pakub üksjagu veidraid variante. Sõnale _kinddla_ ei suudagi oletaja õige sõnaliigiga vastet (ehk siis: omadussõna) pakkuda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Õnneks on meil kasutajasõnastik, mille abil saame tulemusi korrigeerida. Selleks teeme tsükli üle morfoloogilisi analüüse sisaldava `'words'` kihi ning kirjutame üle kõikide kasutajasõnastikus olevate sõnade analüüsid. On oluline üle rõhutada: selleks, et muutused läbi läheksid, tuleb `Text` objekti poole pöörduda kui sõnastiku poole -- ehk siis võtmete kaudu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in morph_analysed['words']:\n",
    "    # Kas sõna on kasutajasõnastikus? \n",
    "    # Kui on, saame selle analüüsi sealt:\n",
    "    if word['text'] in user_dict:\n",
    "        # Kirjutame analüüsi üle kasutajasõnastiku analüüsiga\n",
    "        word['analysis'] = user_dict[ word['text'] ]\n",
    "        # Hea on panna ka sõnale märge juurde, et see pärineb\n",
    "        # kasutajasõnastikust (juhuks, kui hiljem on vaja \n",
    "        # eristada tavalisi kirjakeele sõnu kasutajasõnastiku\n",
    "        # sõnadest)\n",
    "        word['from_user_dict'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paragraphs': [{'end': 85, 'start': 0}],\n",
       " 'sentences': [{'end': 85, 'start': 0}],\n",
       " 'text': 'Sa ajad sássi inimmeste erinevad käsitlusviisid ja lóodusnähhtuste kinndla vahekorra.',\n",
       " 'words': [{'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'sg n',\n",
       "     'lemma': 'sina',\n",
       "     'partofspeech': 'P',\n",
       "     'root': 'sina',\n",
       "     'root_tokens': ['sina']}],\n",
       "   'end': 2,\n",
       "   'start': 0,\n",
       "   'text': 'Sa'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 'd',\n",
       "     'form': 'pl n',\n",
       "     'lemma': 'aeg',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'aeg',\n",
       "     'root_tokens': ['aeg']},\n",
       "    {'clitic': '',\n",
       "     'ending': 'd',\n",
       "     'form': 'd',\n",
       "     'lemma': 'ajama',\n",
       "     'partofspeech': 'V',\n",
       "     'root': 'aja',\n",
       "     'root_tokens': ['aja']}],\n",
       "   'end': 7,\n",
       "   'start': 3,\n",
       "   'text': 'ajad'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'sassi',\n",
       "     'partofspeech': 'D',\n",
       "     'root': 'sassi',\n",
       "     'root_tokens': ['sassi']},\n",
       "    {'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'adt',\n",
       "     'lemma': 'sasi',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'sasi',\n",
       "     'root_tokens': ['sasi']}],\n",
       "   'end': 13,\n",
       "   'from_user_dict': True,\n",
       "   'start': 8,\n",
       "   'text': 'sássi'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 'te',\n",
       "     'form': 'pl g',\n",
       "     'lemma': 'inimene',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'inimene',\n",
       "     'root_tokens': ['inimene']}],\n",
       "   'end': 23,\n",
       "   'from_user_dict': True,\n",
       "   'start': 14,\n",
       "   'text': 'inimmeste'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 'vad',\n",
       "     'form': 'vad',\n",
       "     'lemma': 'erinema',\n",
       "     'partofspeech': 'V',\n",
       "     'root': 'erine',\n",
       "     'root_tokens': ['erine']},\n",
       "    {'clitic': '',\n",
       "     'ending': 'd',\n",
       "     'form': 'pl n',\n",
       "     'lemma': 'erinev',\n",
       "     'partofspeech': 'A',\n",
       "     'root': 'erinev',\n",
       "     'root_tokens': ['erinev']}],\n",
       "   'end': 32,\n",
       "   'start': 24,\n",
       "   'text': 'erinevad'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 'd',\n",
       "     'form': 'pl n',\n",
       "     'lemma': 'käsitlusviis',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'käsitlus_viis',\n",
       "     'root_tokens': ['käsitlus', 'viis']}],\n",
       "   'end': 47,\n",
       "   'start': 33,\n",
       "   'text': 'käsitlusviisid'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'ja',\n",
       "     'partofspeech': 'J',\n",
       "     'root': 'ja',\n",
       "     'root_tokens': ['ja']}],\n",
       "   'end': 50,\n",
       "   'start': 48,\n",
       "   'text': 'ja'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 'te',\n",
       "     'form': 'pl g',\n",
       "     'lemma': 'loodusnähtus',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'loodus_nähtus',\n",
       "     'root_tokens': ['loodus', 'nähtus']}],\n",
       "   'end': 66,\n",
       "   'from_user_dict': True,\n",
       "   'start': 51,\n",
       "   'text': 'lóodusnähhtuste'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'sg g',\n",
       "     'lemma': 'kindel',\n",
       "     'partofspeech': 'A',\n",
       "     'root': 'kindel',\n",
       "     'root_tokens': ['kindel']}],\n",
       "   'end': 74,\n",
       "   'from_user_dict': True,\n",
       "   'start': 67,\n",
       "   'text': 'kinndla'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'sg g',\n",
       "     'lemma': 'vahekord',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'vahe_kord',\n",
       "     'root_tokens': ['vahe', 'kord']}],\n",
       "   'end': 84,\n",
       "   'start': 75,\n",
       "   'text': 'vahekorra'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '',\n",
       "     'form': '',\n",
       "     'lemma': '.',\n",
       "     'partofspeech': 'Z',\n",
       "     'root': '.',\n",
       "     'root_tokens': ['.']}],\n",
       "   'end': 85,\n",
       "   'start': 84,\n",
       "   'text': '.'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veendume, et muutused läksid läbi -- kuvame teksti / sõnastiku sisu:\n",
    "morph_analysed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sa => [('sina', 'P', 'sg n')]\n",
      "ajad => [('aeg', 'S', 'pl n'), ('ajama', 'V', 'd')]\n",
      "sássi => [('sassi', 'D', ''), ('sasi', 'S', 'adt')]\n",
      "inimmeste => [('inimene', 'S', 'pl g')]\n",
      "erinevad => [('erinema', 'V', 'vad'), ('erinev', 'A', 'pl n')]\n",
      "käsitlusviisid => [('käsitlusviis', 'S', 'pl n')]\n",
      "ja => [('ja', 'J', '')]\n",
      "lóodusnähhtuste => [('loodusnähtus', 'S', 'pl g')]\n",
      "kinndla => [('kindel', 'A', 'sg g')]\n",
      "vahekorra => [('vahekord', 'S', 'sg g')]\n",
      ". => [('.', 'Z', '')]\n"
     ]
    }
   ],
   "source": [
    "# Tulemused kompaktsel kujul:\n",
    "for word in morph_analysed['words']:\n",
    "    print(word['text'],'=>',[(a['lemma'],a['partofspeech'],a['form']) for a in word['analysis']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viimase sammuna rakendame _lausepõhist / statistilist ühestamist_. Põhimõtteliselt on \"sügaval EstNLTK kõhus\" olemas eraldi meetod, mis tegelebki ainult lausepõhise ühestamisega. Meetod `estnltk.vabamorf.morf.disambiguate()` saab sisendiks ühe lause sisu (s.o järjendi, mis koosneb lause sõnu kirjeldavatest sõnastikest, iga sõna morf analüüsid võtme `'analysis'` all), ning tagastab \"ühestatud koopia\" sellest järjendist. Kuna sisend-järjendit ennast ühestamise käigus ei muudeta, siis peame muutuste sisseviimiseks tagastatud järjendist analüüsid välja noppima ning kirjutama algsed analüüsid uutega üle. Kõik kokku käib nii:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.vabamorf.morf import disambiguate\n",
    "\n",
    "sentences = morph_analysed.divide('words', 'sentences')\n",
    "for sentence in sentences:\n",
    "    # 1) rakendame lause sõnade järjendil morf ühestamist\n",
    "    disambiguated = disambiguate(sentence)\n",
    "    # 2) viime muutused sisse:\n",
    "    #    asendame algsed analüüsid uute, ühestatud analüüsidega\n",
    "    for orig, new in zip(sentence, disambiguated):\n",
    "        orig['analysis'] = new['analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **NB!** Eelmises praktikumis kasutasite meetodit `split_by()` teksti tükeldamiseks, nüüd aga kasutame meetodit `divide()`. Kuigi need meetodid teevad näiliselt sama asja, on antud juhul nende erinevus väga oluline. `split_by()` tekitab teksti jagamisel uued `Text` objektid (mis sisaldavad koopiaid vana objekti mingitest alamosadest, nt lausetest), samas `divide()` tagastab meile konkreetsed alamosad vanast objektist (nt laused). Seega, kui rakendaksime ühestamist `split_by()` tulemustel, toimuks ühestamine küll koopia-objektidel, aga vana / terviklik tekst jääks ikkagi muutmata / ühestamata. Meetod `divide()` võimaldab aga muuta vana objekti. Rohkem saab lugeda `divide()` kohta [siit](https://estnltk.github.io/estnltk/1.4.1/tutorials/text.html#dividing-elements-by-layers) ja `split_by()` kohta [siit](https://estnltk.github.io/estnltk/1.4.1/tutorials/text.html#splitting-by-layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sa => [('sina', 'P', 'sg n')]\n",
      "ajad => [('aeg', 'S', 'pl n')]\n",
      "sássi => [('sassi', 'D', '')]\n",
      "inimmeste => [('inimene', 'S', 'pl g')]\n",
      "erinevad => [('erinev', 'A', 'pl n')]\n",
      "käsitlusviisid => [('käsitlusviis', 'S', 'pl n')]\n",
      "ja => [('ja', 'J', '')]\n",
      "lóodusnähhtuste => [('loodusnähtus', 'S', 'pl g')]\n",
      "kinndla => [('kindel', 'A', 'sg g')]\n",
      "vahekorra => [('vahekord', 'S', 'sg g')]\n",
      ". => [('.', 'Z', '')]\n"
     ]
    }
   ],
   "source": [
    "# Tulemused kompaktsel kujul:\n",
    "for word in morph_analysed['words']:\n",
    "    print(word['text'],'=>',[(a['lemma'],a['partofspeech'],a['form']) for a in word['analysis']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kasutajasõnastiku (pool-)automaatne loomine\n",
    "\n",
    "Suure korpuse korral on kasutajasõnastiku loomine siiski väga töömahukas tegevus ning täieliku käsitööna mitte eriti mõeldav. Parem lähenemine on kirjakeelsete vastete leidmine vähemalt osaliselt automatiseerida. Järgnevates ülesannetes uurimegi üht sellise automatiseerimisprotsessi alamosa: tundmatutele sõnadele kirjakeelsete vastete leidmist. Kõigepealt peame aga kindlaks tegema, millised sõnad saab üldse tundmatuteks lugeda (arvestades uuritava korpuse sõnestuse eripärasid)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 3: Tundmatud sõnad (1,5 p)\n",
    "\n",
    "Looge programm, mis loeb failist `'netikeele_laused.txt'` laused (failis on iga lause eraldi real) ning teostab lausetel morf analüüsi (ilma oletamise, pärisnimede pakkumise ja ühestamiseta). \n",
    "Programm leiab, mitu % kõigist sõnadest jäid morf analüsaatorile tundmatuks (st sõnadele ei leitud analüüse), ning leiab 10 lauset, mis sisaldavad kõige rohkem tundmatuid sõnu. \n",
    "Leitud 10 lauset ja nendes tundmatuks jäänud sõnad väljastatakse ekraanile (sorteerituna \"tundmatute arvu järgi\" kahanevalt) ning ühtlasi salvestatakse ka kuhugi andmestruktuuri -- neid lauseid läheb tarvis ka järgmises ülesandes.\n",
    "\n",
    "  * Sõnade loendamisel tuleks välja jätta 1-tähelised \"sõnad\", numbritest ja punktuatsioonist koosnevad sõnad;\n",
    "  * \"Tundmatute sõnade\" hulka ei tuleks lugeda punktuatsiooni;\n",
    "  * 10 kõige rohkem tundmatuid sõnu sisaldava lause hulka võib sattuda ka lauseid, milles on sama arv tundmatuid sõnu. Kui viimas(t)ele positsiooni(de)le on valida mitme sama arvu tundmatuid sisaldava lause vahel, siis võib valida lause(d), mis on algses (failis olevas) järjestuses eespool;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teisenduskauguse abil vastete leidmine\n",
    "\n",
    "Nüüd on meil teada, millist laadi sõnadele tuleb hakata kirjakeelseid vasteid otsima. \n",
    "Aga kuidas vasteid leida?\n",
    "Tehniliselt kõige lihtsam lähenemine on kasutada juba valmislahendust -- proovida eelmises praktikumis tutvustatud automaatset [õigekirjakorrektorit](https://estnltk.github.io/estnltk/1.4.1/tutorials/text.html#correcting-spelling), mida võib ka rakendada tundmatutele sõnadele vastete leidmiseks.\n",
    "Siiski ei pruugi õigekirjakorrektor netikeele kõige konarlikemates lausetes, kus esineb eri tüüpi vigu ning nii mõnigi kord on tegemist süstemaatilise \"teisiti kirjutamisega\", kõige paremaid tulemusi anda. \n",
    "\n",
    "Üldine meetod, mida rakendab (küll teatavate lisanüanssidega) ka õigekirjakorrektor, on tundmatute sõnade võrdlemine teadaolevate sõnade leksikoniga ning sõnade _sarnasuse_ põhjal vastete väljapakkumine. \n",
    "Seega, kui meil on olemas piisavalt mahukas kirjakeele korpus, võime selle põhjal ka ise teha teadaolevate sõnade loendi, noppida loendist välja tundmatute sõnadega _sarnased_ sõnad ja pakkuda neid vasteteks.\n",
    "\n",
    "_Kuidas hinnata sõnade sarnasust?_ Siin tuleb appi teisenduskaugus (ingl _edit distance_). Sisuliselt mõõdab teisenduskaugus, mitu teisendust / muutust tuleb teha, et saada ühest sõnest teine. Tavaliselt lubatakse kolme tüüpi muutuseid: 1) ühe tähe kustutamine, 2) ühe tähe lisamine, 3) ühe tähe asendamine mingi teise tähega. Teisenduskaugus ütleb, mitu sellist muutust tuleb minimaalselt teha -- mida väiksem arv, seda sarnasemad kaks sõna on.\n",
    "\n",
    "Teisenduskauguse leidmist võib katsetada funktsiooni `nltk.metrics.distance.edit_distance` abil (funktsiooni sisaldav teek `nltk` peaks teil olema juba installitud, kuna see on üks `estnltk` eelduseid):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.metrics.distance import edit_distance\n",
    "\n",
    "edit_distance('pizza', 'pitsa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance('mõttetu', 'mõtetu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance('uit', 'uit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vt ka `nltk` teisenduskauguse funktsiooni [detailsemat kirjeldust](http://www.nltk.org/api/nltk.metrics.html#nltk.metrics.distance.edit_distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 4: Tundmatutele sõnadele vastete leidmine (2 p)\n",
    "\n",
    "See ülesanne koosneb kahest osast:\n",
    "\n",
    "#### Ülesanne 4.A: Minu soovitaja (1,25 p)\n",
    "\n",
    "Looge funktsioon, mis saab sisendiks tundmatu sõna ning tagastab sellele kõige sarnasemad kirjakeele vasted. \n",
    "Funktsioon võiks osata pakkuda natukene rohkem vasteid kui EstNLTK [õigekirjakontrollija](https://estnltk.github.io/estnltk/1.4.1/tutorials/text.html#correcting-spelling). \n",
    "Seega, esimese sammuna võibki funktsioon kasutada õigekirjakorrektorit vastete leidmiseks, aga kui korrektor midagi pakkuda ei oska, tuleks teisenduskauguse abil ise vasteid otsida. \n",
    "Funktsioon tagastab sarnaste sõnade järjendi (ja tühijärjendi, kui vasteid üldse ei leitud).\n",
    "\n",
    "Teisenduskauguse abil võiks vasteid otsida ajakirjandustekstide sõnavarast (kataloogi `'aja_sloleht_1999_04_k'` tekstidest). \n",
    "Kui suures osas ajakirjendustekstide sõnavara tuleks arvestada (mida jätta ja mida võtta), jääb teie otsustada.\n",
    "Samuti jääb teie otsustada, kui palju ja millisel teisenduskaugusel vasteid tagastatakse (üldine põhimõte on, et mida vähem ja täpsemaid vasteid pakutakse, seda parem).\n",
    "\n",
    "  * **NB!** Kataloogi 'aja_sloleht_1999_04_k' tekstide sisselugemine ja nende põhjal sõnaloendi moodustamine peaks toimuma ainult üks kord -- kindlasti ei tohiks seda teha igal soovitaja-funktsiooni väljakutsel. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ülesanne 4.B: Soovitaja rakendamine tundmatute tuvastamiseks (0,75 p)\n",
    "\n",
    "Rakendage oma soovitaja-funktsiooni ülesandes 3 leitud kümne \"kõige konarlikuma\" lause tundmatutel sõnadel. Väljastage:\n",
    "\n",
    "   * laused ning iga lause all nii tundmatud sõnad kui ka neile pakutavad vasted;\n",
    "   * (üle kõigi lausete) mitmele %-le tundmatutest sõnadest pakutakse vasteid;\n",
    "   * (üle kõigi lausete) milline on keskmine soovituste arv (ehk siis: mitu vastet keskmiselt iga tundmatu sõna kohta soovitatakse);\n",
    "\n",
    "Vajadusel täiendage oma funktsiooni nii, et vähemalt 90% tundmatutest sõnadest saaksid soovitusi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soovitustest kasutajasõnastikuni\n",
    "\n",
    "Eelmises ülesandes arendasime ja katsetasime soovitusfunktsiooni 10 lause tundmatutel sõnadel. \n",
    "Praktikas on tavaliselt eesmärgiks terve korpuse analüüs, seega on ka ülesanne üksjagu töömahukam. \n",
    "Kuidas praktikas kohandada morfoloogiline analüsaator netikeele tekstide analüüsimiseks, on kirjeldatud detailsemalt [selles artiklis](https://www.etis.ee/File/DownloadPublic/ef492abe-ba06-4e86-9fee-a7e5cd44eeb6?name=Fail_ERYa7.07_Muischnek_pp111-127.pdf&type=application%2Fpdf). Üldine põhimõte on järgmine. Kirjakeelest erinevad ja haruldased sõnad peaksid olema kirjakeelsetest vormidest tuletatavad suhteliselt regulaarsete teisenduste abil. Ehk siis leitavad teisenduskauguse või veelgi spetsiifilisemate teisenduste kaudu; nende lisamine kasutajasõnastikku võiks toimuda suhteliselt automaatselt. Samas, kui sõnavorm pole tuletavav kirjakeelsest sõnast regulaarse teisenduse abil, peaks ta olema sageli kasutatav (\"et tema tähendus ja funktsioon kasutajatel meeles püsiks\") ja seega korpuse sõnasageduste uurimisel silma torkama. Sellised sõnavormid tuleks siis korpuse sagedusloendite uurimisel välja selgitada ja lisada kasutajasõnastikku käsitsi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giellatekno (GT) morfoloogilised kategooriad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siiani oleme vaadanud, kuidas parandada oma teksti morfoloogilist analüüsi nii, et see etteantud morfoloogiliste kategooriate süsteemis võimalikult korrektselt analüüsitud saaks. Võib aga juhtuda ka nii, et tekst on küll (piisavalt) korrektselt analüüsitud vaikimisi kasutatavate kategooriate järgi, ent see siiski millegipärast ei rahulda teksti töötlejat. Seetõttu on EstNLTK-s lisaks vaikimisi kasutatavale Filosofti süsteemile ka teine morfoloogiliste kategooriate süsteem: Giellatekno (GT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tehniline vahemärkus**: programm, mis konverteerib kategooriad Filosofti süsteemist Giellatekno süsteemi, kasutab `java`-t. Seega tuleb enne konverteri kasutamist:\n",
    "\n",
    "  * Installida süsteemi [_Java SE Runtime Environment_](https://www.java.com/en/download/) (versioon >= 1.8);\n",
    "  \n",
    "  * Panna `java` käsk süsteemi keskkonnamuutujasse PATH. Windows-i ja Mac-i puhul tehakse seda tüüpiliselt juba installi käigus, aga kui on siiski tarvis seda käsitsi teha, siis detailsemat abi saab [siit](https://java.com/en/download/help/path.xml);\n",
    "\n",
    "Kuidas kontrollida, kas `java` on juba olemas või kas installimine õnnestus? Käsureakäsk `java -version` peaks kuvama infot installitud `java` versiooni kohta, näiteks midagi taolist:\n",
    "\n",
    "    java version \"1.8.0_171\"\n",
    "    Java(TM) SE Runtime Environment (build 1.8.0_171-b11)\n",
    "    Java HotSpot(TM) 64-Bit Server VM (build 25.171-b11, mixed mode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giellatekno morfoloogiliste kategooriate süsteemi saab EstNLTK-s kasutada järgnevalt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.converters.gt_conversion import convert_to_gt\n",
    "from estnltk import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Text('Mis siis, et kuuldavasti teevadki Poola torumehed nii Pariisis kui ka Brüsselis torud reaalselt korda.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paragraphs': [{'end': 102, 'start': 0}],\n",
       " 'sentences': [{'end': 102, 'start': 0}],\n",
       " 'text': 'Mis siis, et kuuldavasti teevadki Poola torumehed nii Pariisis kui ka Brüsselis torud reaalselt korda.',\n",
       " 'words': [{'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'pl n',\n",
       "     'lemma': 'mis',\n",
       "     'partofspeech': 'P',\n",
       "     'root': 'mis',\n",
       "     'root_tokens': ['mis']},\n",
       "    {'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'sg n',\n",
       "     'lemma': 'mis',\n",
       "     'partofspeech': 'P',\n",
       "     'root': 'mis',\n",
       "     'root_tokens': ['mis']}],\n",
       "   'end': 3,\n",
       "   'start': 0,\n",
       "   'text': 'Mis'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'siis',\n",
       "     'partofspeech': 'D',\n",
       "     'root': 'siis',\n",
       "     'root_tokens': ['siis']}],\n",
       "   'end': 8,\n",
       "   'start': 4,\n",
       "   'text': 'siis'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '',\n",
       "     'form': '',\n",
       "     'lemma': ',',\n",
       "     'partofspeech': 'Z',\n",
       "     'root': ',',\n",
       "     'root_tokens': [',']}],\n",
       "   'end': 9,\n",
       "   'start': 8,\n",
       "   'text': ','},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'et',\n",
       "     'partofspeech': 'J',\n",
       "     'root': 'et',\n",
       "     'root_tokens': ['et']}],\n",
       "   'end': 12,\n",
       "   'start': 10,\n",
       "   'text': 'et'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'kuuldavasti',\n",
       "     'partofspeech': 'D',\n",
       "     'root': 'kuuldavasti',\n",
       "     'root_tokens': ['kuuldavasti']}],\n",
       "   'end': 24,\n",
       "   'start': 13,\n",
       "   'text': 'kuuldavasti'},\n",
       "  {'analysis': [{'clitic': 'ki',\n",
       "     'ending': 'vad',\n",
       "     'form': 'vad',\n",
       "     'lemma': 'tegema',\n",
       "     'partofspeech': 'V',\n",
       "     'root': 'tege',\n",
       "     'root_tokens': ['tege']}],\n",
       "   'end': 33,\n",
       "   'start': 25,\n",
       "   'text': 'teevadki'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'sg g',\n",
       "     'lemma': 'Poola',\n",
       "     'partofspeech': 'H',\n",
       "     'root': 'Poola',\n",
       "     'root_tokens': ['Poola']}],\n",
       "   'end': 39,\n",
       "   'start': 34,\n",
       "   'text': 'Poola'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 'd',\n",
       "     'form': 'pl n',\n",
       "     'lemma': 'torumees',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'toru_mees',\n",
       "     'root_tokens': ['toru', 'mees']}],\n",
       "   'end': 49,\n",
       "   'start': 40,\n",
       "   'text': 'torumehed'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'nii',\n",
       "     'partofspeech': 'D',\n",
       "     'root': 'nii',\n",
       "     'root_tokens': ['nii']}],\n",
       "   'end': 53,\n",
       "   'start': 50,\n",
       "   'text': 'nii'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 's',\n",
       "     'form': 'sg in',\n",
       "     'lemma': 'Pariis',\n",
       "     'partofspeech': 'H',\n",
       "     'root': 'Pariis',\n",
       "     'root_tokens': ['Pariis']}],\n",
       "   'end': 62,\n",
       "   'start': 54,\n",
       "   'text': 'Pariisis'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'kui',\n",
       "     'partofspeech': 'D',\n",
       "     'root': 'kui',\n",
       "     'root_tokens': ['kui']},\n",
       "    {'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'kui',\n",
       "     'partofspeech': 'J',\n",
       "     'root': 'kui',\n",
       "     'root_tokens': ['kui']}],\n",
       "   'end': 66,\n",
       "   'start': 63,\n",
       "   'text': 'kui'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'ka',\n",
       "     'partofspeech': 'D',\n",
       "     'root': 'ka',\n",
       "     'root_tokens': ['ka']}],\n",
       "   'end': 69,\n",
       "   'start': 67,\n",
       "   'text': 'ka'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 's',\n",
       "     'form': 'sg in',\n",
       "     'lemma': 'Brüssel',\n",
       "     'partofspeech': 'H',\n",
       "     'root': 'Brüssel',\n",
       "     'root_tokens': ['Brüssel']}],\n",
       "   'end': 79,\n",
       "   'start': 70,\n",
       "   'text': 'Brüsselis'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 'd',\n",
       "     'form': 'pl n',\n",
       "     'lemma': 'toru',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'toru',\n",
       "     'root_tokens': ['toru']}],\n",
       "   'end': 85,\n",
       "   'start': 80,\n",
       "   'text': 'torud'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'reaalselt',\n",
       "     'partofspeech': 'D',\n",
       "     'root': 'reaalselt',\n",
       "     'root_tokens': ['reaalselt']}],\n",
       "   'end': 95,\n",
       "   'start': 86,\n",
       "   'text': 'reaalselt'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'sg p',\n",
       "     'lemma': 'kord',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'kord',\n",
       "     'root_tokens': ['kord']}],\n",
       "   'end': 101,\n",
       "   'start': 96,\n",
       "   'text': 'korda'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '',\n",
       "     'form': '',\n",
       "     'lemma': '.',\n",
       "     'partofspeech': 'Z',\n",
       "     'root': '.',\n",
       "     'root_tokens': ['.']}],\n",
       "   'end': 102,\n",
       "   'start': 101,\n",
       "   'text': '.'}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Märgendame tekstile peale Filosofti analüüsi\n",
    "text.tag_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teisendame morfoloogilise analüüsi GT formaati - selleks luuakse uus kiht nimega 'gt_words\n",
    "text = convert_to_gt(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': 'Pl Nom',\n",
       "    'lemma': 'mis',\n",
       "    'partofspeech': 'P',\n",
       "    'root': 'mis',\n",
       "    'root_tokens': ['mis']},\n",
       "   {'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': 'Sg Nom',\n",
       "    'lemma': 'mis',\n",
       "    'partofspeech': 'P',\n",
       "    'root': 'mis',\n",
       "    'root_tokens': ['mis']}],\n",
       "  'end': 3,\n",
       "  'start': 0,\n",
       "  'text': 'Mis'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'siis',\n",
       "    'partofspeech': 'D',\n",
       "    'root': 'siis',\n",
       "    'root_tokens': ['siis']}],\n",
       "  'end': 8,\n",
       "  'start': 4,\n",
       "  'text': 'siis'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '',\n",
       "    'form': '',\n",
       "    'lemma': ',',\n",
       "    'partofspeech': 'Z',\n",
       "    'root': ',',\n",
       "    'root_tokens': [',']}],\n",
       "  'end': 9,\n",
       "  'start': 8,\n",
       "  'text': ','},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'et',\n",
       "    'partofspeech': 'J',\n",
       "    'root': 'et',\n",
       "    'root_tokens': ['et']}],\n",
       "  'end': 12,\n",
       "  'start': 10,\n",
       "  'text': 'et'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'kuuldavasti',\n",
       "    'partofspeech': 'D',\n",
       "    'root': 'kuuldavasti',\n",
       "    'root_tokens': ['kuuldavasti']}],\n",
       "  'end': 24,\n",
       "  'start': 13,\n",
       "  'text': 'kuuldavasti'},\n",
       " {'analysis': [{'clitic': 'ki',\n",
       "    'ending': 'vad',\n",
       "    'form': 'Pers Prs Ind Pl 3 Aff',\n",
       "    'lemma': 'tegema',\n",
       "    'partofspeech': 'V',\n",
       "    'root': 'tege',\n",
       "    'root_tokens': ['tege']}],\n",
       "  'end': 33,\n",
       "  'start': 25,\n",
       "  'text': 'teevadki'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': 'Sg Gen',\n",
       "    'lemma': 'Poola',\n",
       "    'partofspeech': 'H',\n",
       "    'root': 'Poola',\n",
       "    'root_tokens': ['Poola']}],\n",
       "  'end': 39,\n",
       "  'start': 34,\n",
       "  'text': 'Poola'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': 'd',\n",
       "    'form': 'Pl Nom',\n",
       "    'lemma': 'torumees',\n",
       "    'partofspeech': 'S',\n",
       "    'root': 'toru_mees',\n",
       "    'root_tokens': ['toru', 'mees']}],\n",
       "  'end': 49,\n",
       "  'start': 40,\n",
       "  'text': 'torumehed'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'nii',\n",
       "    'partofspeech': 'D',\n",
       "    'root': 'nii',\n",
       "    'root_tokens': ['nii']}],\n",
       "  'end': 53,\n",
       "  'start': 50,\n",
       "  'text': 'nii'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': 's',\n",
       "    'form': 'Sg Ine',\n",
       "    'lemma': 'Pariis',\n",
       "    'partofspeech': 'H',\n",
       "    'root': 'Pariis',\n",
       "    'root_tokens': ['Pariis']}],\n",
       "  'end': 62,\n",
       "  'start': 54,\n",
       "  'text': 'Pariisis'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'kui',\n",
       "    'partofspeech': 'D',\n",
       "    'root': 'kui',\n",
       "    'root_tokens': ['kui']},\n",
       "   {'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'kui',\n",
       "    'partofspeech': 'J',\n",
       "    'root': 'kui',\n",
       "    'root_tokens': ['kui']}],\n",
       "  'end': 66,\n",
       "  'start': 63,\n",
       "  'text': 'kui'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'ka',\n",
       "    'partofspeech': 'D',\n",
       "    'root': 'ka',\n",
       "    'root_tokens': ['ka']}],\n",
       "  'end': 69,\n",
       "  'start': 67,\n",
       "  'text': 'ka'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': 's',\n",
       "    'form': 'Sg Ine',\n",
       "    'lemma': 'Brüssel',\n",
       "    'partofspeech': 'H',\n",
       "    'root': 'Brüssel',\n",
       "    'root_tokens': ['Brüssel']}],\n",
       "  'end': 79,\n",
       "  'start': 70,\n",
       "  'text': 'Brüsselis'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': 'd',\n",
       "    'form': 'Pl Nom',\n",
       "    'lemma': 'toru',\n",
       "    'partofspeech': 'S',\n",
       "    'root': 'toru',\n",
       "    'root_tokens': ['toru']}],\n",
       "  'end': 85,\n",
       "  'start': 80,\n",
       "  'text': 'torud'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'reaalselt',\n",
       "    'partofspeech': 'D',\n",
       "    'root': 'reaalselt',\n",
       "    'root_tokens': ['reaalselt']}],\n",
       "  'end': 95,\n",
       "  'start': 86,\n",
       "  'text': 'reaalselt'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': 'Sg Par',\n",
       "    'lemma': 'kord',\n",
       "    'partofspeech': 'S',\n",
       "    'root': 'kord',\n",
       "    'root_tokens': ['kord']}],\n",
       "  'end': 101,\n",
       "  'start': 96,\n",
       "  'text': 'korda'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '',\n",
       "    'form': '',\n",
       "    'lemma': '.',\n",
       "    'partofspeech': 'Z',\n",
       "    'root': '.',\n",
       "    'root_tokens': ['.']}],\n",
       "  'end': 102,\n",
       "  'start': 101,\n",
       "  'text': '.'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['gt_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boonusülesanne (0,5p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutvuge giellatekno formaadis morfoloogilise analüüsiga. Selleks teisendage järgneva teksti analüüs GT kujule ning printige välja iga tekstisõna koos selle mõlemas formaadis morfoloogilise analüüsiga (*form*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Kaks telgipäeva, 12. ja 13. juunil Tallinnas Vabaduse väljakul läksid väga edukalt. Saime kogeda nii vihma kui ka päikest, mürtsus puhkpillimuusika, ajakirjanikud sagisid ringi ning mis peamine – telgid olid tulvil heategudest. Kas ka sina käisid? Kui ei, tule järgmine aasta, paremat võimalust ei tule.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vastake küsimustele:\n",
    "* Mis on suurim sisuline erinevus GT ja Filosofti analüüside vahel? Vihje: vaadake verbianalüüse\n",
    "* Kui lähtuda teksti morfoloogilise analüüsi täpsusest ja saagisest, siis millisel juhul oleks mõistlik kasutada GT kuju, millisel juhul Filosofti oma?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soovi korral rohkem infot verbi morfoloogiliste kategooriate esitamise võimaluste kohta [siit](http://kjk.eki.ee/download_pdf/582)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
