{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue\">Praktikum 3. Morfoloogilise analüüsi erijuhud</h1>\n",
    "<h3 style=\"color:blue\">Korpusepõhine ühestamine, morfoloogiline analüüs kasutajasõnastiku abil ja Giellatekno märgendid</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**22. september 2017**\n",
    "\n",
    "**Ülesannete esitamise tähtaeg 1. oktoober 2017 23:55**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tänases praktikumis jätkame morfoloogilise analüüsi ja ühestamise teemadega. Kuna keerukamad analüüsitasemed (süntaks, semantika) toetuvad morfoloogilise analüüsi tulemustele, siis on oluline selle taseme analüüsile rohkem tähelepanu pöörata. Eriti oluliseks muutub see siis, kui analüüsida tuleb tekste, mille keelekasutus erineb kirjakeelest, nt netikeelt, slängi vms eesti keele allkeelt. Samuti võib sõnade morfoloogilist analüüsi parandada see, kui arvestame sõnade kasutust laiemas kontekstis: terves tekstis või korpuses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Teksti- ja korpusepõhine morfoloogiline ühestamine\n",
    "\n",
    "Vaikimisi EstNLTK's kasutatav morfoloogiline ühestamine, millega tutvusite eelmises praktikumis, toimetab ühe lause piires. Lühidalt kirjeldades: statistilist / masinõppe lähenemist kasutades leitakse igale sõnale kontekstist lähtuvalt kõige tõenäolisem morfoloogiline analüüs, sealjuures üksikule sõnale analüüsi valimisel lähtutakse 1-2 eelneva sõna analüüsidest. Detailsemalt kirjeldab statistilist morfoloogilist ühestamist [see artikkel](http://www.cl.ut.ee/yllitised/kk_yhest_1998.pdf).\n",
    "\n",
    "Praktikas töötab lausepõhine ühestamine küllaltki hästi, aga selle täpsust on võimalik siiski veelgi suurendada. Ühe lause piires mitmeseks jäävad sõnad võivad mujal tekstis esineda üheselt tõlgendataval kujul, seega, kui kasutada ühestamisel laiemat konteksti kui üks lause, saame lahendada lausepõhise ühestamise poolt lahendamata jäänud või valesti lahendatud mitmesusi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enne kui läheme edasi, tuleb ära rääkida üks **tehniline, aga siiski oluline jutt**. Eelmises praktikumis vaatasime mitmeid mugavaid variante teksti morfoloogiliste analüüside kättesaamiseks, nt `text.analysis` andis meile kõigi sõnade analüüside järjendi, `text.lemmas` lemmade järjendi, `text.postags` sõnaliikide järjendi jne. Näiliselt on need `Text` objekti atribuudid, aga tegelikult peituvad nende taga nn _mugavusfunktsioonid_. Väljakutsumisel kontrollivad mugavusfunktsioonid kõigepealt, kas morfoloogiline analüüs on tehtud (kui pole, siis teevad selle), ning seejärel nopivad analüüsist välja nõutud tulemused (kas siis lemmad, sõnaliigid vms). Mugavusfunktsioonide kasutamisel tuleb olla aga ettevaatlik, et mitte komistada järgmiste probleemide otsa:\n",
    "\n",
    "* mugavusfunktsioonide (`text.words`, `text.analysis`, `text.lemmas` jne) abil **ei ole võimalik** `Text` objekti sisu muuta. Omistamise saab küll teha (nt `text.words=[]`), aga tegelik sisu sellest ei muutu. Kuna `Text` objekt on sõnastiku-tüüpi andmestruktuur, siis saab selle sisu muuta ainult nii, nagu muudetakse sõnastikku, nt omistades `text['words']=[]`;\n",
    "\n",
    "\n",
    "* mugavusfunktsioonid (`text.words`, `text.analysis`, `text.lemmas` jne) jäädvustavad esimesel väljakutsumisel tagastatava sisu mälupuhvrisse ja edaspidi **tagastavad vana sisu**. Seega, kui muudate `Text` objekti ja kutsute pärast muutmist mugavusfunktsiooni uuesti  välja, ei näe te muutmise tulemust. Ainult siis, kui pöördute `Text` objekti poole kasutades sõnastiku võtmeid (nt `text['words']`), on garanteeritud, et saate kätte kõige värskema sisu;\n",
    "\n",
    "Arvestades neid probleeme ning seda, et käesolevas praktikumis tuleb üsna palju tegemist morfoloogiliste analüüside kohendamise / muutmisega, siis proovime siin kasutada mugavusfunktsioone nii vähe kui võimalik. Andmetele ligipääs on sel viisil küll natukene keerukam, aga samas on garanteeritud, et kõik toimib nii, nagu peab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uurime lause- ja korpusepõhise morfoloogilise ühestamise erinevust järgmise \"näitekorpuse\" varal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = ['Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.',\\\n",
    "          'Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.', \\\n",
    "          'Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sisuliselt käsitleme järjendi `corpus` iga elementi \"ühe tekstina\". \n",
    "\n",
    "Kõigepealt rakendame korpusel morfoloogilist analüüsi koos tavalise, lausepõhise ühestamisega. Kasutame selleks `Text` objekti meetodit `tag_analysis()`. Sisuliselt teostab see meetod morfoloogilise analüüsi vastavalt sellele, millised olid parameetrite `guess`, `disambiguate` ja `propername` väärtused `Text` objekti loomisel (eelmise praktikumi teema) ning kui ühtegi nimetatud parameetritest ei kasutata, eeldab vaikimisi, et kõik on sisse lülitatud. Pärast teksti ühestamist trükime välja sõnad, mille analüüsid jäid mitmeseks. Kasutame sealjuures väikest tsükli-nõksu, et kuvada morfoloogilise analüüsi tulemused nii, et oluline info oleks ühel real. Väljastame iga sõna analüüside osast ainult lemma, sõnaliigi ja käände-/pöördeinfo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.\n",
      "kohale => [('koht', 'S', 'sg all'), ('koha', 'S', 'sg all')]\n",
      "kuigi => [('kuigi', 'D', ''), ('kuigi', 'J', '')]\n",
      "Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.\n",
      "Teise => [('teine', 'O', 'sg g'), ('teine', 'P', 'sg g')]\n",
      "koha => [('koht', 'S', 'sg g'), ('koha', 'S', 'sg g')]\n",
      "mail => [('maa', 'S', 'pl ad'), ('mai', 'S', 'sg ad')]\n",
      "Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.\n",
      "summaga => [('summ', 'S', 'sg kom'), ('summa', 'S', 'sg kom')]\n",
      "on => [('olema', 'V', 'b'), ('olema', 'V', 'vad')]\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "for text_str in corpus:\n",
    "    text = Text(text_str)\n",
    "    print(text)\n",
    "    # Teostame tavalise, lausepõhise teksti ühestamise\n",
    "    text.tag_analysis()\n",
    "    # Trükime välja mitmeseks jäänud sõnade analüüsid (ainult lemma, sõnaliigi ja vorminimetuse)\n",
    "    for word in text.words:\n",
    "        if len(word['analysis']) > 1:\n",
    "            print( word['text'],'=>',[(a['lemma'],a['partofspeech'],a['form']) for a in word['analysis']] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näha, on ühestamise tulemustes parandamisruumi küll. Proovime korpusepõhist ühestamist.\n",
    "\n",
    "EstNLTK's klass `Disambiguator` sisaldab meetodit `disambiguate()`, millele antakse sisendiks analüüsitav korpus järjendi kujul. See võibki olla sõnede järjend, nagu meie näitejärjend `corpus`, aga see võib olla ka järjend, mis koosneb `Text` objektidest. Viimasel juhul on oluline meeles pidada, et kui annate sisendiks järjendi `Text` objektidest, millele on juba tehtud morfoloogiline analüüs, siis vanad analüüsitulemused kustutatakse ning analüüsiga alustatakse nullist.\n",
    "\n",
    "Sisuliselt teostab meetod `disambiguate()` nii tavalise kui ka korpusepõhise ühestamise ning tagastab järjendi `Text` objektidest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estnltk import Disambiguator\n",
    "disamb = Disambiguator()\n",
    "\n",
    "# Rakendame korpusepõhist ühestamist näitekorpusel\n",
    "disambiguated_texts = disamb.disambiguate(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uurime tulemusi -- väljastame uuesti mitmesed analüüsid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.\n",
      "kuigi => [('kuigi', 'D', ''), ('kuigi', 'J', '')]\n",
      "Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.\n",
      "Teise => [('teine', 'O', 'sg g'), ('teine', 'P', 'sg g')]\n",
      "Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.\n",
      "on => [('olema', 'V', 'b'), ('olema', 'V', 'vad')]\n"
     ]
    }
   ],
   "source": [
    "for text in disambiguated_texts:\n",
    "    print(text.text)\n",
    "    # Trükime välja mitmeseks jäänud sõnade analüüsid (ainult lemma, sõnaliigi ja vorminimetuse)\n",
    "    for word in text.words:\n",
    "        if len(word['analysis']) > 1:\n",
    "            print( word['text'],'=>',[(a['lemma'],a['partofspeech'],a['form']) for a in word['analysis']] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lisaks on korpusepõhisest ühestamisest abi pärisnimeanalüüside korrastamisel. Kui mingi tavaline sõna on korpuse tekstides tõenäoliselt kasutusel pärisnimena (st esineb suure algustähega ka lausete keskel), siis valib korpusepõhine ühestaja pärisnime-analüüsid selle sõna tavapäraste analüüside asemel. Uurime, millised analüüsid valiti näitekorpuse suure tähega algavatele sõnadele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esimesele kohale tuleb Jänes, kuigi tema punktide summa pole kõrgeim.\n",
      "Esimesele => [('esimene', 'O', 'sg all')]\n",
      "Jänes => [('Jänes', 'H', 'sg n')]\n",
      "Lõpparvestuses läks Konnale esimene koht. Teise koha sai seekord Jänes. Uus võistlus toimub 2. mail.\n",
      "Lõpparvestuses => [('lõpparvestus', 'S', 'sg in')]\n",
      "Konnale => [('Konn', 'H', 'sg all')]\n",
      "Teise => [('teine', 'O', 'sg g'), ('teine', 'P', 'sg g')]\n",
      "Jänes => [('Jäne', 'H', 'sg in')]\n",
      "Uus => [('uus', 'A', 'sg n')]\n",
      "Konn paistis silma suurima punktide summaga. Uue võistluse toimumisajaks on 2. mai.\n",
      "Konn => [('Konn', 'H', 'sg n')]\n",
      "Uue => [('uus', 'A', 'sg g')]\n"
     ]
    }
   ],
   "source": [
    "for text in disambiguated_texts:\n",
    "    print(text.text)\n",
    "    # Trükime välja suure tähega algavate sõnade analüüsid\n",
    "    for word in text.words:\n",
    "        if word['text'].istitle():\n",
    "            print( word['text'],'=>',[(a['lemma'],a['partofspeech'],a['form']) for a in word['analysis']] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näha, on sõnad _Jänes_ ja _Konn_ saanud pärisnime sõnaliigimärgendi (`'H'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korpusepõhise ühestamise teooriat kirjeldab [see artikkel](https://www.etis.ee/File/DownloadPublic/ce4606c7-41ba-4059-ac6d-6db2e40442e9?name=Fail_FAIA247-0082.pdf&type=application%2Fpdf). EstNLTK korpusepõhise ühestaja liidest kirjeldab detailsemalt [see abimaterjal](https://estnltk.github.io/estnltk/1.4.1/tutorials/disambiguation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 1: Kui palju vähendab korpusepõhine ühestamine mitmesust? (1,5p)\n",
    "\n",
    "Esimeseks ülesandeks on uurida, kui palju vähendab korpusepõhine ühestamine mitmesust. Kataloogis `'aja_sloleht_1999_04_k'` on SL Õhtulehe ajaleheartiklid, ühes failis üks artikkel. Lugege sealt tekstid sisse ning teostage morfoloogiline ühestamine kolmel erineval viisil: 1) tavaline, lausepõhine ühestamine, 2) tekstipõhine ühestamine, st korpusepõhine ühestamine, kus \"korpuseks\" on üks tekst/artikkel, 3) korpusepõhine ühestamine, kus korpuseks ongi kõik artiklid, st terve kataloogi sisu.\n",
    "Leidke ja väljastage iga ühestamisetapi kohta mitmeseks jäänud sõnade arv ja osakaal kõigist sõnadest (%).\n",
    "\n",
    "Juhiseid:\n",
    "\n",
    " * Failide kõvakettalt sisselugemine on üldiselt ressurssinõudlik operatsioon; seetõttu on väga soovitav ülesanne lahendada nii, et loete kõigi failide sisud kõigepealt mällu (nt järjendisse) ja ülesande alamosi 1), 2) ja 3) lahendades toimetate mälus olevatel andmetel;\n",
    " \n",
    " * Kuidas teha \"tekstipõhist ühestamist\" ehk anda meetodile `disambiguate()` ette täpselt üks tekst? Tuleb lihtsalt anda ette järjend, mis sisaldab ühte teksti :)\n",
    " \n",
    "       disambiguate([minu_tekst])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 2: Korpusepõhise ühestamise kvaliteedi uurimine (1,5 p)\n",
    "\n",
    "Lingvistidel oleks tarvis uurida korpusepõhise ühestamise kvaliteeti, st leida täpselt, milliseid mitmesusi see parandab. Teostage kataloogi `'aja_sloleht_1999_04_k'` failidel tavaline ühestamine (eelmise ülesande ühestamine 1) ning kogu korpusel põhinev ühestamine (eelmise ülesande ühestamine 3) ja leidke, millised sõnad olid tavaühestamise järel mitmesed ning muutusid korpusepõhise ühestamise tagajärjel üheseks. Väljastage: \n",
    "\n",
    " 1. laused, kus mitmesus vähenes, \n",
    " 2. sõnad, kus mitmesus vähenes, ja konkreetsed analüüside loendid, mis muutusid. \n",
    "   \n",
    "Kirjutage kogu korpuse tulemused ühte tekstifaili. Näiteks võiks tulemus olla sarnasel kujul:\n",
    "```\n",
    "aja_sloleht_1999_04_15__2.txt\n",
    "Võlg tasutakse maksegraafiku alusel .\n",
    " * alusel\n",
    "   [('alune', 'S', 'sg ad'), ('alus', 'S', 'sg ad')]\n",
    "   ==>\n",
    "   [('alus', 'S', 'sg ad')]\n",
    "\n",
    "Liidu peasekretäri Jaak Uudmäe sõnul on võlg piinlik lugu , mis tuleb kiires korras kustutada .\n",
    " * Liidu\n",
    "   [('Liit', 'H', 'sg g'), ('Liidu', 'H', 'sg g'), ('Liidud', 'H', 'sg g')]\n",
    "   ==>\n",
    "   [('Liit', 'H', 'sg g')]\n",
    "```\n",
    "\n",
    "  * Üks võimalik lahenduskäik: Kõigepealt teostage korpusepõhine ühestamine. Seejärel tehke tsükkel üle korpusepõhise ühestamise tulemuste ning jagage tekstid lauseteks (kuidas, sellest rääkisime eelmises praksis). Võtke välja iga lause algtekst, looge sellest uus `Text` objekt ning teostage ka lausepõhine ühestamine. Lõpuks võrrelge tulemusi sõna-sõna haaval ja väljastage erinevused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morfoloogiline analüüs ja ühestamine kasutajasõnastiku abil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morfoloogiline analüsaator töötab kõige paremini tekstidel, mis järgivad kirjakeele norme. Kuigi analüsaator sisaldab ka tundmatute sõnade oletajat, ei saa selle täpsusele lootma jääda, kui analüüsitavad tekstid erinevad kirjakeelest suurel määral. Seetõttu kasutatakse netikeele vms eesti keele allkeele automaatseks analüüsimiseks nn _kasutajasõnastiku lähenemist_. Kõigepealt luuakse (poolautomaatselt) kasutajasõnastik, kus on toodud kirjakeelest erinevate sõnavormide korrektsed morfoloogilised analüüsid. Seejärel teostatakse automaatne morfoloogiline analüüs ilma ühestamiseta ning analüüsi tulemustes asendatakse kasutajasõnastikus olevate sõnade (automaat)analüüsid nende korrektsete analüüsidega. Viimase sammuna rakendatakse morfoloogiliselt analüüsitud tekstil ühestamist.\n",
    "\n",
    "Vaatame seda protsessi samm-sammult ühe netikeele lause näitel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"Sa ajad sássi inimmeste erinevad käsitlusviisid ja lóodusnähhtuste kinndla vahekorra.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meie näide on lihtne selles mõttes, et kuigi siin on mitte-kirjakeelseid sõnavorme (nt _inimmeste_, _lóodusnähhtuste_), leidub kõigile sõnadele siiski kirjakeeles vaste. Seega saame tekitada mitte-kirjakeelsete vormide morfoloogilised analüüsid, kui analüüsime vastavaid kirjakeele sõnavorme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "# Loome uue kasutajasõnastiku\n",
    "user_dict = {}\n",
    "# Lisame tundmatute sõnade vormid koos neile vastavate kirjakeele sõnade analüüsidega\n",
    "user_dict[\"inimmeste\"]       = Text('inimeste', guess=False, disambiguate=False, propername=False ).analysis[0]\n",
    "user_dict[\"lóodusnähhtuste\"] = Text('loodusnähtuste', guess=False, disambiguate=False, propername=False ).analysis[0]\n",
    "user_dict[\"kinndla\"]         = Text('kindla', guess=False, disambiguate=False, propername=False ).analysis[0]\n",
    "user_dict[\"sássi\"]           = Text('sassi', guess=False, disambiguate=False, propername=False ).analysis[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tulemuseks saame sellise sõnastiku:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inimmeste': [{'clitic': '',\n",
       "   'ending': 'te',\n",
       "   'form': 'pl g',\n",
       "   'lemma': 'inimene',\n",
       "   'partofspeech': 'S',\n",
       "   'root': 'inimene',\n",
       "   'root_tokens': ['inimene']}],\n",
       " 'kinndla': [{'clitic': '',\n",
       "   'ending': '0',\n",
       "   'form': 'sg g',\n",
       "   'lemma': 'kindel',\n",
       "   'partofspeech': 'A',\n",
       "   'root': 'kindel',\n",
       "   'root_tokens': ['kindel']}],\n",
       " 'lóodusnähhtuste': [{'clitic': '',\n",
       "   'ending': 'te',\n",
       "   'form': 'pl g',\n",
       "   'lemma': 'loodusnähtus',\n",
       "   'partofspeech': 'S',\n",
       "   'root': 'loodus_nähtus',\n",
       "   'root_tokens': ['loodus', 'nähtus']}],\n",
       " 'sássi': [{'clitic': '',\n",
       "   'ending': '0',\n",
       "   'form': '',\n",
       "   'lemma': 'sassi',\n",
       "   'partofspeech': 'D',\n",
       "   'root': 'sassi',\n",
       "   'root_tokens': ['sassi']},\n",
       "  {'clitic': '',\n",
       "   'ending': '0',\n",
       "   'form': 'adt',\n",
       "   'lemma': 'sasi',\n",
       "   'partofspeech': 'S',\n",
       "   'root': 'sasi',\n",
       "   'root_tokens': ['sasi']}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * _Aga kui morfoloogiline analüsaator ei oskagi kirjakeelset vastet analüüsida (tegemist on uudissõnaga vms)?_ Siis on põhimõtteliselt võimalik sõna morfoloogiliste analüüside järjend ka ise käsitsi tekitada. Sellisel juhul tuleks aga väga täpselt jälgida, et analüüse kirjeldavad sõnastikud sisaldaksid kõiki nõutud võtmeid (`'clitic'`, `'ending'`, `'form'`, `'lemma'`, `'partofspeech'`, `'root'`, `'root_tokens'`) ja võtmete väärtused oleksid sellises formaadis, mida kasutab morfoloogiline analüsaator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Järgmise sammuna teostame tekstil morfoloogilise analüüsi ilma ühestamise ja pärisnimede oletamiseta. Oletamise enda jätame sisse (selleks, et lauselõpu punktile ikkagi analüüs külge tuleks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Teostame morf analüüsi (oletamisega, aga ilma ühestamiseta)\n",
    "morph_analysed = Text(text, guess=True, disambiguate=False, propername=False)\n",
    "morph_analysed = morph_analysed.tag_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kasutame taaskord \"kompaktset\" tulemuste väljastamise viisi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sa => [('sina', 'P', 'sg n')]\n",
      "ajad => [('aeg', 'S', 'pl n'), ('ajama', 'V', 'd')]\n",
      "sássi => [('sáss', 'S', 'adt'), ('sáss', 'S', 'sg g'), ('sáss', 'S', 'sg p'), ('sássi', 'S', 'sg g'), ('sássi', 'S', 'sg n')]\n",
      "inimmeste => [('inimmest', 'S', 'pl p')]\n",
      "erinevad => [('erinema', 'V', 'vad'), ('erinev', 'A', 'pl n')]\n",
      "käsitlusviisid => [('käsitlusviis', 'S', 'pl n')]\n",
      "ja => [('ja', 'J', '')]\n",
      "lóodusnähhtuste => [('lóodusnähhtune', 'A', 'pl g'), ('lóodusnähhtus', 'S', 'pl g'), ('lóodusnähhtuste', 'S', 'sg g'), ('lóodusnähhtuste', 'S', 'sg n')]\n",
      "kinndla => [('kinndla', 'S', 'sg g'), ('kinndla', 'S', 'sg n')]\n",
      "vahekorra => [('vahekord', 'S', 'sg g')]\n",
      ". => [('.', 'Z', '')]\n"
     ]
    }
   ],
   "source": [
    "for word in morph_analysed.words:\n",
    "    analysis = [ (a['lemma'], a['partofspeech'], a['form']) for a in word['analysis'] ]\n",
    "    print( word['text'],'=>',analysis )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu tulemustest võib näha, on oletaja segaduses ja pakub üksjagu veidraid variante. Sõnale _kinddla_ ei suudagi oletaja õige sõnaliigiga vastet (ehk siis: omadussõna) pakkuda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Õnneks on meil kasutajasõnastik, mille abil saame tulemusi korrigeerida. Selleks teeme tsükli üle morfoloogilisi analüüse sisaldava `'words'` kihi ning kirjutame üle kõikide kasutajasõnastikus olevate sõnade analüüsid. On oluline üle rõhutada: selleks, et muutused läbi läheksid, tuleb `Text` objekti poole pöörduda kui sõnastiku poole -- ehk siis võtmete kaudu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in morph_analysed['words']:\n",
    "    # Kas sõna on kasutajasõnastikus? \n",
    "    # Kui on, saame selle analüüsi sealt:\n",
    "    if word['text'] in user_dict:\n",
    "        # Kirjutame analüüsi üle kasutajasõnastiku analüüsiga\n",
    "        word['analysis'] = user_dict[ word['text'] ]\n",
    "        # Hea on panna ka sõnale märge juurde, et see pärineb\n",
    "        # kasutajasõnastikust (juhuks, kui hiljem on vaja \n",
    "        # eristada tavalisi kirjakeele sõnu kasutajasõnastiku\n",
    "        # sõnadest)\n",
    "        word['from_user_dict'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paragraphs': [{'end': 85, 'start': 0}],\n",
       " 'sentences': [{'end': 85, 'start': 0}],\n",
       " 'text': 'Sa ajad sássi inimmeste erinevad käsitlusviisid ja lóodusnähhtuste kinndla vahekorra.',\n",
       " 'words': [{'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'sg n',\n",
       "     'lemma': 'sina',\n",
       "     'partofspeech': 'P',\n",
       "     'root': 'sina',\n",
       "     'root_tokens': ['sina']}],\n",
       "   'end': 2,\n",
       "   'start': 0,\n",
       "   'text': 'Sa'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 'd',\n",
       "     'form': 'pl n',\n",
       "     'lemma': 'aeg',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'aeg',\n",
       "     'root_tokens': ['aeg']},\n",
       "    {'clitic': '',\n",
       "     'ending': 'd',\n",
       "     'form': 'd',\n",
       "     'lemma': 'ajama',\n",
       "     'partofspeech': 'V',\n",
       "     'root': 'aja',\n",
       "     'root_tokens': ['aja']}],\n",
       "   'end': 7,\n",
       "   'start': 3,\n",
       "   'text': 'ajad'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'sassi',\n",
       "     'partofspeech': 'D',\n",
       "     'root': 'sassi',\n",
       "     'root_tokens': ['sassi']},\n",
       "    {'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'adt',\n",
       "     'lemma': 'sasi',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'sasi',\n",
       "     'root_tokens': ['sasi']}],\n",
       "   'end': 13,\n",
       "   'from_user_dict': True,\n",
       "   'start': 8,\n",
       "   'text': 'sássi'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 'te',\n",
       "     'form': 'pl g',\n",
       "     'lemma': 'inimene',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'inimene',\n",
       "     'root_tokens': ['inimene']}],\n",
       "   'end': 23,\n",
       "   'from_user_dict': True,\n",
       "   'start': 14,\n",
       "   'text': 'inimmeste'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 'vad',\n",
       "     'form': 'vad',\n",
       "     'lemma': 'erinema',\n",
       "     'partofspeech': 'V',\n",
       "     'root': 'erine',\n",
       "     'root_tokens': ['erine']},\n",
       "    {'clitic': '',\n",
       "     'ending': 'd',\n",
       "     'form': 'pl n',\n",
       "     'lemma': 'erinev',\n",
       "     'partofspeech': 'A',\n",
       "     'root': 'erinev',\n",
       "     'root_tokens': ['erinev']}],\n",
       "   'end': 32,\n",
       "   'start': 24,\n",
       "   'text': 'erinevad'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 'd',\n",
       "     'form': 'pl n',\n",
       "     'lemma': 'käsitlusviis',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'käsitlus_viis',\n",
       "     'root_tokens': ['käsitlus', 'viis']}],\n",
       "   'end': 47,\n",
       "   'start': 33,\n",
       "   'text': 'käsitlusviisid'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'ja',\n",
       "     'partofspeech': 'J',\n",
       "     'root': 'ja',\n",
       "     'root_tokens': ['ja']}],\n",
       "   'end': 50,\n",
       "   'start': 48,\n",
       "   'text': 'ja'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 'te',\n",
       "     'form': 'pl g',\n",
       "     'lemma': 'loodusnähtus',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'loodus_nähtus',\n",
       "     'root_tokens': ['loodus', 'nähtus']}],\n",
       "   'end': 66,\n",
       "   'from_user_dict': True,\n",
       "   'start': 51,\n",
       "   'text': 'lóodusnähhtuste'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'sg g',\n",
       "     'lemma': 'kindel',\n",
       "     'partofspeech': 'A',\n",
       "     'root': 'kindel',\n",
       "     'root_tokens': ['kindel']}],\n",
       "   'end': 74,\n",
       "   'from_user_dict': True,\n",
       "   'start': 67,\n",
       "   'text': 'kinndla'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'sg g',\n",
       "     'lemma': 'vahekord',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'vahe_kord',\n",
       "     'root_tokens': ['vahe', 'kord']}],\n",
       "   'end': 84,\n",
       "   'start': 75,\n",
       "   'text': 'vahekorra'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '',\n",
       "     'form': '',\n",
       "     'lemma': '.',\n",
       "     'partofspeech': 'Z',\n",
       "     'root': '.',\n",
       "     'root_tokens': ['.']}],\n",
       "   'end': 85,\n",
       "   'start': 84,\n",
       "   'text': '.'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veendume, et muutused läksid läbi -- kuvame teksti / sõnastiku sisu:\n",
    "morph_analysed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sa => [('sina', 'P', 'sg n')]\n",
      "ajad => [('aeg', 'S', 'pl n'), ('ajama', 'V', 'd')]\n",
      "sássi => [('sassi', 'D', ''), ('sasi', 'S', 'adt')]\n",
      "inimmeste => [('inimene', 'S', 'pl g')]\n",
      "erinevad => [('erinema', 'V', 'vad'), ('erinev', 'A', 'pl n')]\n",
      "käsitlusviisid => [('käsitlusviis', 'S', 'pl n')]\n",
      "ja => [('ja', 'J', '')]\n",
      "lóodusnähhtuste => [('loodusnähtus', 'S', 'pl g')]\n",
      "kinndla => [('kindel', 'A', 'sg g')]\n",
      "vahekorra => [('vahekord', 'S', 'sg g')]\n",
      ". => [('.', 'Z', '')]\n"
     ]
    }
   ],
   "source": [
    "# Tulemused kompaktsel kujul:\n",
    "for word in morph_analysed.words:\n",
    "    print(word['text'],'=>',[(a['lemma'],a['partofspeech'],a['form']) for a in word['analysis']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viimase sammuna rakendame _lausepõhist / statistilist ühestamist_. Põhimõtteliselt on \"sügaval EstNLTK kõhus\" olemas eraldi meetod, mis tegelebki ainult lausepõhise ühestamisega. Meetod `estnltk.vabamorf.morf.disambiguate()` saab sisendiks ühe lause sisu (s.o järjendi, mis koosneb lause sõnu kirjeldavatest sõnastikest, iga sõna morf analüüsid võtme `'analysis'` all), ning tagastab \"ühestatud koopia\" sellest järjendist. Kuna sisend-järjendit ennast ühestamise käigus ei muudeta, siis peame muutuste sisseviimiseks tagastatud järjendist analüüsid välja noppima ning kirjutama algsed analüüsid uutega üle. Kõik kokku käib nii:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from estnltk.vabamorf.morf import disambiguate\n",
    "\n",
    "sentences = morph_analysed.divide('words', 'sentences')\n",
    "for sentence in sentences:\n",
    "    # 1) rakendame lause sõnade järjendil morf ühestamist\n",
    "    disambiguated = disambiguate(sentence)\n",
    "    # 2) viime muutused sisse:\n",
    "    #    asendame algsed analüüsid uute, ühestatud analüüsidega\n",
    "    for orig, new in zip(sentence, disambiguated):\n",
    "        orig['analysis'] = new['analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **NB!** Eelmises praktikumis kasutasite meetodit `split_by()` teksti tükeldamiseks, nüüd aga kasutame meetodit `divide()`. Kuigi need meetodid teevad näiliselt sama asja, on antud juhul nende erinevus väga oluline. `split_by()` tekitab teksti jagamisel uued `Text` objektid (mis sisaldavad koopiaid vana objekti mingitest alamosadest, nt lausetest), samas `divide()` tagastab meile konkreetsed alamosad vanast objektist (nt laused). Seega, kui rakendaksime ühestamist `split_by()` tulemustel, toimuks ühestamine küll koopia-objektidel, aga vana / terviklik tekst jääks ikkagi muutmata / ühestamata. Meetod `divide()` võimaldab aga muuta vana objekti. Rohkem saab lugeda `divide()` kohta [siit](https://estnltk.github.io/estnltk/1.4.1/tutorials/text.html#dividing-elements-by-layers) ja `split_by()` kohta [siit](https://estnltk.github.io/estnltk/1.4.1/tutorials/text.html#splitting-by-layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sa => [('sina', 'P', 'sg n')]\n",
      "ajad => [('aeg', 'S', 'pl n')]\n",
      "sássi => [('sassi', 'D', '')]\n",
      "inimmeste => [('inimene', 'S', 'pl g')]\n",
      "erinevad => [('erinev', 'A', 'pl n')]\n",
      "käsitlusviisid => [('käsitlusviis', 'S', 'pl n')]\n",
      "ja => [('ja', 'J', '')]\n",
      "lóodusnähhtuste => [('loodusnähtus', 'S', 'pl g')]\n",
      "kinndla => [('kindel', 'A', 'sg g')]\n",
      "vahekorra => [('vahekord', 'S', 'sg g')]\n",
      ". => [('.', 'Z', '')]\n"
     ]
    }
   ],
   "source": [
    "# Tulemused kompaktsel kujul:\n",
    "for word in morph_analysed.words:\n",
    "    print(word['text'],'=>',[(a['lemma'],a['partofspeech'],a['form']) for a in word['analysis']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kasutajasõnastiku (pool-)automaatne loomine\n",
    "\n",
    "Suure korpuse korral on kasutajasõnastiku loomine siiski väga töömahukas tegevus ning täieliku käsitööna mitte eriti mõeldav. Parem lähenemine on kirjakeelsete vastete leidmine vähemalt osaliselt automatiseerida. Esimese abinõuna võib siin proovida eelmises praktikumis tutvustatud automaatset õigekirjakorrektorit, mida võib ka rakendada tundmatutele sõnadele vastete leidmiseks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 3: Tundmatud sõnad (0,5 p)\n",
    "\n",
    "Looge programm, mis loeb failist `'netikeele_laused.txt'` laused (failis on iga lause eraldi real) ning teostab lausetel morf analüüsi (ilma oletamise, pärisnimede pakkumise ja ühestamiseta). Programm leiab, mitu % kõigist sõnadest jäid morf analüsaatorile tundmatuks (st sõnadele ei leitud analüüse), ning leiab 10 lauset, mis sisaldavad kõige rohkem tundmatuid sõnu.  Leitud 10 lauset ja nendes tundmatuks jäänud sõnad tuleks väljastada (sorteerituna \"tundmatute arvu järgi\" kahanevalt) ning ühtlasi salvestada ka kuhugi andmestruktuuri -- neid lauseid läheb tarvis ka järgmistes ülesannetes.\n",
    "\n",
    "  * Sõnade loendamisel võiks välja jätta 1-tähelised \"sõnad\", numbritest ja punktuatsioonist koosnevad sõnad;\n",
    "  * \"Tundmatute sõnade\" hulka ei tuleks lugeda punktuatsiooni;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 4: Õigekirjakontrollija soovitused (0,5 p)\n",
    "\n",
    "Analüüsige kümmet kõige rohkem tundmatuid sõnu sisaldavat lauset EstNLTK [õigekirjakontrollija](https://estnltk.github.io/estnltk/1.4.1/tutorials/text.html#correcting-spelling) abil ning leidke:\n",
    "\n",
    "   * mitmele %-le tundmatutest sõnadest pakutakse õigekirjakontrollija poolt vasteid;\n",
    "   * milline on keskmine soovituste arv (ehk siis: mitu vastet keskmiselt iga tundmatu sõna kohta soovitatakse);\n",
    "   \n",
    "Lisaks eelmainitud statistikale peaks programm ka laused ükshaaval väljastama ning kuvama iga lause all nii tundmatud sõnad kui ka neile pakutavad vasted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teisenduskaugus\n",
    "\n",
    "Eelmise ülesande tulemustest peaks selguma, et õigekirjakontrollija ei suuda siiski kõikidele tundmatuks jäänud netikeele sõnadele sobivaid vasteid pakkuda. Ent pakutavate vastete hulka võib suurendada, kui meil on olemas piisavalt mahukas kirjakeele korpus. Võime selle põhjal teha sõnaloendi, noppida loendist välja tundmatute sõnadega _sarnased_ sõnad ja pakkuda neid vasteteks.\n",
    "\n",
    "_Kuidas hinnata sõnade sarnasust?_ Siin tuleb appi teisenduskaugus (ingl _edit distance_). Sisuliselt mõõdab teisenduskaugus, mitu teisendust / muutust tuleb teha, et saada ühest sõnest teine. Tavaliselt lubatakse kolme tüüpi muutuseid: 1) ühe tähe kustutamine, 2) ühe tähe lisamine, 3) ühe tähe asendamine mingi teise tähega. Teisenduskaugus ütleb, mitu sellist muutust tuleb (minimaalselt) teha -- mida väiksem arv, seda sarnasemad kaks sõna on.\n",
    "\n",
    "Teisenduskauguse leidmist võib katsetada funktsiooni `nltk.metrics.distance.edit_distance` abil (funktsiooni sisaldav teek `nltk` peaks teil olema juba installitud, kuna see on üks `estnltk` eelduseid):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.metrics.distance import edit_distance\n",
    "\n",
    "edit_distance('pizza', 'pitsa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance('mõttetu', 'mõtetu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance('uit', 'uit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vt ka `nltk` teisenduskauguse funktsiooni [detailsemat kirjeldus](http://www.nltk.org/api/nltk.metrics.html#nltk.metrics.distance.edit_distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 5: Parem tundmatute sõnade tuvastamine (1,25 p)\n",
    "\n",
    "See ülesanne koosneb kahest osast:\n",
    "\n",
    "#### Ülesanne 5.A: Minu soovitaja (1 p)\n",
    "\n",
    "Looge funktsioon, mis saab sisendiks tundmatu sõna ning tagastab sellele kõige sarnasemad kirjakeele vasted. Funktsioon võiks osata pakkuda natukene rohkem vasteid kui EstNLTK õigekirjakorrektor. Seega, esimese sammuna võibki funktsioon kasutada  õigekirjakorrektorit vastete leidmiseks, aga kui korrektor midagi pakkuda ei oska, tuleks teisenduskauguse abil ise vasteid  otsida. Funktsioon tagastab sarnaste sõnade järjendi (ja tühijärjendi, kui vasteid üldse ei leitud). \n",
    "\n",
    "Teisenduskauguse abil võiks vasteid otsida ajakirjandustekstide sõnavarast (kataloogi `'aja_sloleht_1999_04_k'` tekstidest). Kui suures osas ajakirjendustekstide sõnavara tuleks arvestada (mida jätta ja mida võtta), jääb teie otsustada. Samuti jääb teie otsustada, kui palju ja millisel teisenduskaugusel vasteid tagastatakse (üldine põhimõte on, et mida vähem ja täpsemaid vasteid pakutakse, seda parem). Lisaks teisenduskaugusele võib kasutada mingeid lisaheuristikuid sobivate vastete väljanoppimiseks.\n",
    "\n",
    "  * **NB!** Kataloogi 'aja_sloleht_1999_04_k' tekstide sisselugemine ja nende põhjal sõnaloendi moodustamine peaks toimuma ainult üks kord -- kindlasti ei tohiks seda teha igal soovitaja-funktsiooni väljakutsel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ülesanne 5.B: Soovitaja rakendamine tundmatute tuvastamiseks (0,25 p)\n",
    "\n",
    "Rakendage oma soovitaja-funktsiooni kümnel kõige rohkem tundmatuid sõnu sisaldaval lausel (ülesannetest 3 ja 4). Vajadusel täiendage oma funktsiooni nii, et vähemalt 90% tundmatutest sõnadest saaksid soovitusi. Ülesande väljund peaks olema sama, mis ülesandes 4, ehk siis tuleks väljastada:\n",
    "\n",
    "   * mitmele %-le tundmatutest sõnadest pakutakse vasteid;\n",
    "   * milline on keskmine soovituste arv (ehk siis: mitu vastet keskmiselt iga tundmatu sõna kohta soovitatakse);\n",
    "   \n",
    "Lisaks peaks programm ka laused ükshaaval väljastama ning kuvama iga lause all nii tundmatud sõnad kui ka neile pakutavad vasted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soovitustest kasutajasõnastikuni\n",
    "\n",
    "Morfoloogilise analüsaatori kohandamist netikeele tekstide analüüsimiseks kirjeldab detailsemalt [see artikkel](https://www.etis.ee/File/DownloadPublic/ef492abe-ba06-4e86-9fee-a7e5cd44eeb6?name=Fail_ERYa7.07_Muischnek_pp111-127.pdf&type=application%2Fpdf). Üldine põhimõte on järgmine. Kirjakeelest erinevad ja haruldased sõnad peaksid olema kirjakeelsetest vormidest tuletatavad suhteliselt regulaarsete teisenduste abil. Ehk siis leitavad teisenduskauguse või veelgi spetsiifilisemate teisenduste kaudu; nende lisamine kasutajasõnastikku võiks toimuda suhteliselt automaatselt. Samas, kui sõnavorm pole tuletavav kirjakeelsest sõnast regulaarse teisenduse abil, peaks ta olema sageli kasutatav (\"et tema tähendus ja funktsioon kasutajatel meeles püsiks\") ja seega korpuse sõnasageduste uurimisel silma torkama. Sellised sõnavormid tuleks kasutajasõnastikku lisada siis käsitsi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giellatekno (GT) morfoloogilised kategooriad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siiani oleme vaadanud, kuidas parandada oma teksti morfoloogilist analüüsi nii, et see etteantud morfoloogiliste kategooriate süsteemis võimalikult korrektselt analüüsitud saaks. Võib aga juhtuda ka nii, et tekst on küll (piisavalt) korrektselt analüüsitud vaikimisi kasutatavate kategooriate järgi, ent see siiski millegipärast ei rahulda teksti töötlejat. Seetõttu on EstNLTK-s lisaks vaikimisi kasutatavale Filosofti süsteemile ka teine morfoloogiliste kategooriate süsteem: Giellatekno (GT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giellatekno morfoloogiliste kategooriate süsteemi saab EstNLTK-s kasutada järgnevalt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from estnltk.converters.gt_conversion import convert_to_gt\n",
    "from estnltk import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = Text('Mis siis, et kuuldavasti teevadki Poola torumehed nii Pariisis kui ka Brüsselis torud reaalselt korda.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paragraphs': [{'end': 102, 'start': 0}],\n",
       " 'sentences': [{'end': 102, 'start': 0}],\n",
       " 'text': 'Mis siis, et kuuldavasti teevadki Poola torumehed nii Pariisis kui ka Brüsselis torud reaalselt korda.',\n",
       " 'words': [{'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'pl n',\n",
       "     'lemma': 'mis',\n",
       "     'partofspeech': 'P',\n",
       "     'root': 'mis',\n",
       "     'root_tokens': ['mis']},\n",
       "    {'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'sg n',\n",
       "     'lemma': 'mis',\n",
       "     'partofspeech': 'P',\n",
       "     'root': 'mis',\n",
       "     'root_tokens': ['mis']}],\n",
       "   'end': 3,\n",
       "   'start': 0,\n",
       "   'text': 'Mis'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'siis',\n",
       "     'partofspeech': 'D',\n",
       "     'root': 'siis',\n",
       "     'root_tokens': ['siis']}],\n",
       "   'end': 8,\n",
       "   'start': 4,\n",
       "   'text': 'siis'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '',\n",
       "     'form': '',\n",
       "     'lemma': ',',\n",
       "     'partofspeech': 'Z',\n",
       "     'root': ',',\n",
       "     'root_tokens': [',']}],\n",
       "   'end': 9,\n",
       "   'start': 8,\n",
       "   'text': ','},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'et',\n",
       "     'partofspeech': 'J',\n",
       "     'root': 'et',\n",
       "     'root_tokens': ['et']}],\n",
       "   'end': 12,\n",
       "   'start': 10,\n",
       "   'text': 'et'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'kuuldavasti',\n",
       "     'partofspeech': 'D',\n",
       "     'root': 'kuuldavasti',\n",
       "     'root_tokens': ['kuuldavasti']}],\n",
       "   'end': 24,\n",
       "   'start': 13,\n",
       "   'text': 'kuuldavasti'},\n",
       "  {'analysis': [{'clitic': 'ki',\n",
       "     'ending': 'vad',\n",
       "     'form': 'vad',\n",
       "     'lemma': 'tegema',\n",
       "     'partofspeech': 'V',\n",
       "     'root': 'tege',\n",
       "     'root_tokens': ['tege']}],\n",
       "   'end': 33,\n",
       "   'start': 25,\n",
       "   'text': 'teevadki'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'sg g',\n",
       "     'lemma': 'Poola',\n",
       "     'partofspeech': 'H',\n",
       "     'root': 'Poola',\n",
       "     'root_tokens': ['Poola']}],\n",
       "   'end': 39,\n",
       "   'start': 34,\n",
       "   'text': 'Poola'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 'd',\n",
       "     'form': 'pl n',\n",
       "     'lemma': 'torumees',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'toru_mees',\n",
       "     'root_tokens': ['toru', 'mees']}],\n",
       "   'end': 49,\n",
       "   'start': 40,\n",
       "   'text': 'torumehed'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'nii',\n",
       "     'partofspeech': 'D',\n",
       "     'root': 'nii',\n",
       "     'root_tokens': ['nii']}],\n",
       "   'end': 53,\n",
       "   'start': 50,\n",
       "   'text': 'nii'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 's',\n",
       "     'form': 'sg in',\n",
       "     'lemma': 'Pariis',\n",
       "     'partofspeech': 'H',\n",
       "     'root': 'Pariis',\n",
       "     'root_tokens': ['Pariis']}],\n",
       "   'end': 62,\n",
       "   'start': 54,\n",
       "   'text': 'Pariisis'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'kui',\n",
       "     'partofspeech': 'D',\n",
       "     'root': 'kui',\n",
       "     'root_tokens': ['kui']},\n",
       "    {'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'kui',\n",
       "     'partofspeech': 'J',\n",
       "     'root': 'kui',\n",
       "     'root_tokens': ['kui']}],\n",
       "   'end': 66,\n",
       "   'start': 63,\n",
       "   'text': 'kui'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'ka',\n",
       "     'partofspeech': 'D',\n",
       "     'root': 'ka',\n",
       "     'root_tokens': ['ka']}],\n",
       "   'end': 69,\n",
       "   'start': 67,\n",
       "   'text': 'ka'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 's',\n",
       "     'form': 'sg in',\n",
       "     'lemma': 'Brüssel',\n",
       "     'partofspeech': 'H',\n",
       "     'root': 'Brüssel',\n",
       "     'root_tokens': ['Brüssel']}],\n",
       "   'end': 79,\n",
       "   'start': 70,\n",
       "   'text': 'Brüsselis'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': 'd',\n",
       "     'form': 'pl n',\n",
       "     'lemma': 'toru',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'toru',\n",
       "     'root_tokens': ['toru']}],\n",
       "   'end': 85,\n",
       "   'start': 80,\n",
       "   'text': 'torud'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'reaalselt',\n",
       "     'partofspeech': 'D',\n",
       "     'root': 'reaalselt',\n",
       "     'root_tokens': ['reaalselt']}],\n",
       "   'end': 95,\n",
       "   'start': 86,\n",
       "   'text': 'reaalselt'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'sg p',\n",
       "     'lemma': 'kord',\n",
       "     'partofspeech': 'S',\n",
       "     'root': 'kord',\n",
       "     'root_tokens': ['kord']}],\n",
       "   'end': 101,\n",
       "   'start': 96,\n",
       "   'text': 'korda'},\n",
       "  {'analysis': [{'clitic': '',\n",
       "     'ending': '',\n",
       "     'form': '',\n",
       "     'lemma': '.',\n",
       "     'partofspeech': 'Z',\n",
       "     'root': '.',\n",
       "     'root_tokens': ['.']}],\n",
       "   'end': 102,\n",
       "   'start': 101,\n",
       "   'text': '.'}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Märgendame tekstile peale Filosofti analüüsi\n",
    "text.tag_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Teisendame morfoloogilise analüüsi GT formaati - selleks luuakse uus kiht nimega 'gt_words\n",
    "text = convert_to_gt(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': 'Pl Nom',\n",
       "    'lemma': 'mis',\n",
       "    'partofspeech': 'P',\n",
       "    'root': 'mis',\n",
       "    'root_tokens': ['mis']},\n",
       "   {'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': 'Sg Nom',\n",
       "    'lemma': 'mis',\n",
       "    'partofspeech': 'P',\n",
       "    'root': 'mis',\n",
       "    'root_tokens': ['mis']}],\n",
       "  'end': 3,\n",
       "  'start': 0,\n",
       "  'text': 'Mis'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'siis',\n",
       "    'partofspeech': 'D',\n",
       "    'root': 'siis',\n",
       "    'root_tokens': ['siis']}],\n",
       "  'end': 8,\n",
       "  'start': 4,\n",
       "  'text': 'siis'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '',\n",
       "    'form': '',\n",
       "    'lemma': ',',\n",
       "    'partofspeech': 'Z',\n",
       "    'root': ',',\n",
       "    'root_tokens': [',']}],\n",
       "  'end': 9,\n",
       "  'start': 8,\n",
       "  'text': ','},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'et',\n",
       "    'partofspeech': 'J',\n",
       "    'root': 'et',\n",
       "    'root_tokens': ['et']}],\n",
       "  'end': 12,\n",
       "  'start': 10,\n",
       "  'text': 'et'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'kuuldavasti',\n",
       "    'partofspeech': 'D',\n",
       "    'root': 'kuuldavasti',\n",
       "    'root_tokens': ['kuuldavasti']}],\n",
       "  'end': 24,\n",
       "  'start': 13,\n",
       "  'text': 'kuuldavasti'},\n",
       " {'analysis': [{'clitic': 'ki',\n",
       "    'ending': 'vad',\n",
       "    'form': 'Pers Prs Ind Pl 3 Aff',\n",
       "    'lemma': 'tegema',\n",
       "    'partofspeech': 'V',\n",
       "    'root': 'tege',\n",
       "    'root_tokens': ['tege']}],\n",
       "  'end': 33,\n",
       "  'start': 25,\n",
       "  'text': 'teevadki'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': 'Sg Gen',\n",
       "    'lemma': 'Poola',\n",
       "    'partofspeech': 'H',\n",
       "    'root': 'Poola',\n",
       "    'root_tokens': ['Poola']}],\n",
       "  'end': 39,\n",
       "  'start': 34,\n",
       "  'text': 'Poola'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': 'd',\n",
       "    'form': 'Pl Nom',\n",
       "    'lemma': 'torumees',\n",
       "    'partofspeech': 'S',\n",
       "    'root': 'toru_mees',\n",
       "    'root_tokens': ['toru', 'mees']}],\n",
       "  'end': 49,\n",
       "  'start': 40,\n",
       "  'text': 'torumehed'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'nii',\n",
       "    'partofspeech': 'D',\n",
       "    'root': 'nii',\n",
       "    'root_tokens': ['nii']}],\n",
       "  'end': 53,\n",
       "  'start': 50,\n",
       "  'text': 'nii'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': 's',\n",
       "    'form': 'Sg Ine',\n",
       "    'lemma': 'Pariis',\n",
       "    'partofspeech': 'H',\n",
       "    'root': 'Pariis',\n",
       "    'root_tokens': ['Pariis']}],\n",
       "  'end': 62,\n",
       "  'start': 54,\n",
       "  'text': 'Pariisis'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'kui',\n",
       "    'partofspeech': 'D',\n",
       "    'root': 'kui',\n",
       "    'root_tokens': ['kui']},\n",
       "   {'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'kui',\n",
       "    'partofspeech': 'J',\n",
       "    'root': 'kui',\n",
       "    'root_tokens': ['kui']}],\n",
       "  'end': 66,\n",
       "  'start': 63,\n",
       "  'text': 'kui'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'ka',\n",
       "    'partofspeech': 'D',\n",
       "    'root': 'ka',\n",
       "    'root_tokens': ['ka']}],\n",
       "  'end': 69,\n",
       "  'start': 67,\n",
       "  'text': 'ka'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': 's',\n",
       "    'form': 'Sg Ine',\n",
       "    'lemma': 'Brüssel',\n",
       "    'partofspeech': 'H',\n",
       "    'root': 'Brüssel',\n",
       "    'root_tokens': ['Brüssel']}],\n",
       "  'end': 79,\n",
       "  'start': 70,\n",
       "  'text': 'Brüsselis'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': 'd',\n",
       "    'form': 'Pl Nom',\n",
       "    'lemma': 'toru',\n",
       "    'partofspeech': 'S',\n",
       "    'root': 'toru',\n",
       "    'root_tokens': ['toru']}],\n",
       "  'end': 85,\n",
       "  'start': 80,\n",
       "  'text': 'torud'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'reaalselt',\n",
       "    'partofspeech': 'D',\n",
       "    'root': 'reaalselt',\n",
       "    'root_tokens': ['reaalselt']}],\n",
       "  'end': 95,\n",
       "  'start': 86,\n",
       "  'text': 'reaalselt'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': 'Sg Par',\n",
       "    'lemma': 'kord',\n",
       "    'partofspeech': 'S',\n",
       "    'root': 'kord',\n",
       "    'root_tokens': ['kord']}],\n",
       "  'end': 101,\n",
       "  'start': 96,\n",
       "  'text': 'korda'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '',\n",
       "    'form': '',\n",
       "    'lemma': '.',\n",
       "    'partofspeech': 'Z',\n",
       "    'root': '.',\n",
       "    'root_tokens': ['.']}],\n",
       "  'end': 102,\n",
       "  'start': 101,\n",
       "  'text': '.'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['gt_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boonusülesanne (0,5p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutvuge giellatekno formaadis morfoloogilise analüüsiga. Selleks teisendage järgneva teksti analüüs GT kujule ning printige välja iga tekstisõna koos selle mõlemas formaadis morfoloogilise analüüsiga (*form*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Kaks telgipäeva, 12. ja 13. juunil Tallinnas Vabaduse väljakul läksid väga edukalt. Saime kogeda nii vihma kui ka päikest, mürtsus puhkpillimuusika, ajakirjanikud sagisid ringi ning mis peamine – telgid olid tulvil heategudest. Kas ka sina käisid? Kui ei, tule järgmine aasta, paremat võimalust ei tule.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vastake küsimustele:\n",
    "* Mis on suurim sisuline erinevus GT ja Filosofti analüüside vahel? Vihje: vaadake verbianalüüse\n",
    "* Kui lähtuda teksti morfoloogilise analüüsi täpsusest ja saagisest, siis millisel juhul oleks mõistlik kasutada GT kuju, millisel juhul Filosofti oma?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soovi korral rohkem infot verbi morfoloogiliste kategooriate esitamise võimaluste kohta [siit](http://kjk.eki.ee/download_pdf/582)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3.5.2]",
   "language": "python",
   "name": "conda-env-python3.5.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
