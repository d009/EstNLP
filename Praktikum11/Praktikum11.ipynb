{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1 style=\"color:blue\">Praktikum 11. </h1>\n",
    "<h3 style=\"color:blue\">Twitter'i säutsude analüüs. Info eraldamine. Suurte andmetega töötamine. Vikipeedia artiklite töötlus. PhraseTagger ja grammatikad</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tänases praktikumis tegeleme Twitteri säutsude ja Vikipeedia artiklite analüüsiga ning katsetame automaatset info eraldamist. Viimasega oleme vähesel määral kokku puutunud ka varasemates praktikumides, näiteks leides ajaväljendeid, nimeüksusi, sagedasemaid nimisõnafraase, elusolendeid erinevatest tekstidest jms. Siinses praktikumis käsitleme teemat aga süstemaatilisemalt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info eraldamine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informatsiooni saab eraldada nii struktureeritud andmetest kui ka vabatekstist. Lähtudes käesoleva aine eesmärkidest tegeleme siin just nimelt tekstiliste andmetega. Vabast (või poolstruktureeritud) tekstist info eraldamisel on eesmärgiks saada sealt kätte info niisugusel moel, et seda oleks võimalik esitada struktureeritud kujul, näiteks tabelina. Leitud infot kasutavad sõltuvalt eesmärkidest kas lõppkasutajad või teised süsteemid (otsingumootorid, andmebaasisüsteemid vms). \n",
    "\n",
    "Vabast tekstist info eraldamisega tehti algust juba 1970ndatel, laiemat kõlapinda on see leidnud aga alates 1990ndatest. Koos aina kasvavate (struktureerimata) infohulkadega muutub ka ülesanne aina päevakohasemaks. \n",
    "\n",
    "Info eraldamise põhiülesanneteks ongi näiteks nimeolemite tuvastamine, samaviiteliste üksuste tuvastamine ja relatsioonide leidmine. Nimeolemite tuvastamisega tegelesime juba 5. praktikumis: nägime, et eesti keele jaoks on loodud tööriist, mis tuvastab isikunimesid, asukohti ja organisatsioone. Nimeolemeid võib aga käsitleda ka laiemalt, näiteks võib siia alla lugeda ürituste, toodete, haiguste, ravimite vms huvipakkuva tuvastamise.\n",
    "\n",
    "Samaviiteliste üksuste tuvastamise puhul soovime leida tekstist sõnad/väljendid, mis tähistavad sama nähtust või objekti. Näiteks tekstis *Galaxy S4 teeb paremaid pilte kui nii mõnigi seebikarp. Telefon maksab küll rohkem, ent tal on ka rohkem funktsioone.* tähistavad \"Galaxy S4\" ja \"Telefon\" sama objekti. Samaviiteliste üksuste tuvastamise alamülesanne on asesõnade lahendamine. Üldkasutatavaid tööriistu eesti keelele selle jaoks loodud ei ole.\n",
    "\n",
    "Samuti ei ole üldkasutatavaid tööriistu relatsioonide ehk sõnadevaheliste seoste leidmiseks. \n",
    "\n",
    "Info eraldamiseks vabast tekstist kasutatakse nii reeglipõhiseid meetodeid kui ka masinõpet. Reeglipõhiste meetodite puhul kasutatakse käsitsi kirjutatud keelelisi mustreid. Need kipuvad olema väga domeenispetsiifilised: õiges valdkonnas võivad anda häid tulemusi, aga pole kohandatavad teisele valdkonnale. Käsitsi mustrite kirjutamine nõuab loomulikult palju inimtööjõudu, mis on reeglipõhise lähenemise üheks suurimaks miinuseks. Reeglipõhisel lähenemisel võib kasutada erinevaid mustrite kirjutamise viise, nt regulaaravaldisi ja/või grammatikaid. Regulaaravaldistega olete kõik kokku puutunud, grammatikate kirjutamiseks on EstNLTK-s vahendid olemas, millega täna põgusalt tutvust teeme. Grammatikate eeliseks on võimalus moodustada reegleid erinevates märgenduskihtides olevat infot või ka enda defineeritud märgenduskihte kasutades. Mõnevõrra võimalustevaesem, kuid see-eest lihtsam viis fraase eraldada on PhraseTagger. Näiteks, kui meenutate 4. praktikumist nimisõnafraaside eraldamise ülesannet, kus tuli kontrollida järjest asetsevate sõnade sõnaliiki ja vormi, siis seda oleks tegelikult kergem teha PhraseTaggeri abil.\n",
    "\n",
    "Masinõppepõhised meetodid informatsiooni eraldamisel lähtuvad kas eeldusest, et vaadeldavat ülesannet saab defineerida kui klassifitseerimisprobleemi, või on vaja identifitseerida mingit funktsiooni täitvaid tekstisegmente. Kuna masinõppesse me selles aines ei süvene, siis käsitleme ülesannetes ainult reeglipõhiseid meetodeid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suurte andmetega töötamisest\n",
    "Automaatsel infoeraldusel, aga ka enamikul muudel loomuliku keele automaattöötluse ülesannetel, on mõte vaid siis, kui andmeid on palju - rohkem, kui mõistliku ajaga käsitsi läbi jõuaks vaadata. Kui andmeid on piisavalt palju ja/või operatsioonid, mida nendega teha soovime, on piisavalt keerulised, võib aga ka automaattöötlusel ajakulu muutuda kas tüütult või ka teostamatult suureks. Ilmselt olete pidanud selle aine kodutööde lahendamisel mõnigi kord arvuti taga ootama. Kui ootama peab 20 minutit, on see tüütu, aga kui ooteajaks kujuneb näiteks 2 kuud või lausa 200 aastat? \n",
    "\n",
    "Seetõttu on oluline pöörata tähelepanu oma koodi efektiivsusele. Kuidas aga aru saada, mis koodis täpselt kaua aega võtab ning kui kaua skript veel jookseb?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mis mu koodis kaua aega võtab? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sellele aitab vastust leida *profileerimine*. Pythonis on selleks erinevaid teeke, nt *cProfile*, *line_profiler*. Notebookis on eriti mugav kasutada viimast, ehkki see vajab eraldi installimist (`conda install line_profiler`). *Line_profiler*'ile saab ette anda oma funktsiooni ning ta näitab iga rea kohta, kui kaua selle täitmiseks aega läks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kasutame Notebook magicut line_profileri laadimiseks\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktsioon, mida tahame profileerida\n",
    "def dumb_function(my_list, other_list):\n",
    "    other_list2 = set(other_list)\n",
    "    new_thing = []\n",
    "    for word in my_list:\n",
    "        for c in word:\n",
    "            c += 'a'\n",
    "            \n",
    "            # Kontrollime esinemist listis\n",
    "            if 'c' in other_list: \n",
    "                x = 1\n",
    "                \n",
    "            # Kontrollime esinemist setis    \n",
    "            if 'c' in other_list2: \n",
    "                x = 2\n",
    "                \n",
    "            # Kontrollime esinemist setis, \n",
    "            # teisendades listi igal sammul uuesti setiks    \n",
    "            if 'c' in set(other_list): \n",
    "                x = 3\n",
    "                \n",
    "            new_thing.append(c)    \n",
    "    return new_thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andmed, millel tahame funktsiooni testida\n",
    "# (soovitavalt mingi väiksem alamhulk oma andmetest, mille töötlemiseks ei kulu väga kaua)\n",
    "my_list = ['kana', 'koer', 'vitamiin', 'w4']\n",
    "other_list = ['ka', 'ke', 'ki', 'aa', 'ee', 'oo', 'ta', 'ia', 'ma', 'ra', 'ka', 'ke', 'ki', 'aa', 'ee', 'oo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jooksutame funktsiooni line_profileriga, et saada iga rea ajakulu\n",
    "%lprun -f dumb_function dumb_function(my_list, other_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näeme, vaadates veerge *Time*, *Per hit* ja *% Time*, läheb siin kiiremini elemendi esinemise kontrollimine setis, seda aga ainult siis, kui listi setiks teisendame ühe korra, mitte igal iteratsioonisammul uuesti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kui kaua mu kood veel jookseb?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui oleme koodi tööle pannud ning mingi aja oodanud, kuidas teada, kas töö saab varsti valmis või äkki lähebki 200 aastat, nagu enne sai hirmutatud? Lihtne, aga mitte väga ilus variant on tsüklis iga mingi aja tagant printida välja infot selle kohta, kui kaugele jõudnud oleme. Näiteks kasutades *enumerate()* funktsiooni:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n"
     ]
    }
   ],
   "source": [
    "for idx, number in enumerate(range(10000000)):\n",
    "    if idx%1000000 == 0: # prindib välja ainult iga 1 000 000-nda indeksi\n",
    "        print(idx)\n",
    "    number2 = number + 1 # siin on see, mida tegelikult tsüklis teha tahame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selle lähenemise miinuseks on veel see, et peame teadma, kui kiiresti umbes meie kood jooksma hakkab ehk iga mitme iteratsiooni tagant oleks mõistlik printida. **NB!** Kui lasete välja printida nt kõik 10 000 000 indeksit, siis suure tõenäosusega jookseb Notebook lihtsalt kokku. Seega, et mitte koormata arvuti ressursse liialt printimisega, tuleb selleks valida mõistlik intervall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sama funktsiooni täitmiseks on aga olemas ka eraldi teek *tqdm* (vaja installida - `conda install tqdm`), mille kasutamine tsüklis on lihtne, ilus ja mugav:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 10000000/10000000 [00:08<00:00, 1231744.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for number in tqdm(range(10000000)):\n",
    "    number2 = number +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mida teha, et mitte ilmaasjata aega raisata?\n",
    "Ühest küljest on oluline **koodi optimeerimine** - mitte teha ühte operatsiooni mitu korda, mitte teha aeganõudvaid operatsioone, kui neid saab asendada kiirematega jms. Vähem oluline pole aga ka **üldine töökorraldus**. \n",
    "\n",
    "Kui on tegu suuremate andmetega, tasub esmalt koodi **testida mingil väiksel alamulgal andmetest** ja vaadata, kas tulemus on selline, nagu loodetud - pole ju mõtet oodata 20 minutit, parandada koodis näpuviga, oodata jälle 20 minutit, parandada järgmine viga jne. \n",
    "\n",
    "Lisaks, kui mingi aeganõudev arvutus on ära tehtud ja tulemus kätte saadud, võib  vahepeal selle **tulemuse salvestada faili** - sel juhul ei pea nt notebooki/arvuti kokkujooksmise, muutujanime kogemata ülekirjutamise vms puhul uuesti otsast peale hakkama. Faili salvestamisel tasub muidugi mõelda sellele, mis kujul salvestada - sobivad näiteks pickle või json, mida on käsitletud eelmistes praktikumides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 1. Psüühikahäirete riskigruppi kuuluvate Twitteri-kasutajate tuvastamine (2p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB!** Tegemist on siiski vaid programmeerimisharjutusega, mille tulemuste põhjal ei tasu kindlasti tegelikult ühtegi Twitteri-kasutajat sildistama hakata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laias maailmas on tehtud mitmeid uuringuid selle kohta, kuivõrd on võimalik kasutaja sotsiaalmeediapostituste alusel tuvastada seda, kas ta kuulub psüühikahäirete (depressioon, bipolaarne häire, jms) riskigruppi. On leitud mitmeid nii keelelisi kui ka mittekeelelisi tunnuseid, mille abil niisuguseid kasutajaid tuvastada. Siin ülesandes proovime, kas ka eestikeelsete säutsude põhjal oleks võimalik midagi sarnast teha. Selleks on siin pakitud kaustas \"tweets\" ~175 000 eestikeelset Twitteri säutsu.\n",
    "\n",
    "**NB!** Kuna säutse on palju, siis võib nende töötlemine võtta aega, eriti, kui kasutatav arvuti aeglasepoolne on. Kui tundub, et oma kood on mõistlikult kirjutatud ning näib, et kõigi säutsude töötlemisele kuluks üle 30 minuti (selle ennustuse tegemiseks ei pea 30 min ära ootama - vt ülevaltpoolt juhiseid), siis võib kasutada omal valikul ka mingit väiksemat hulka säutsudest.\n",
    "\n",
    "Võtame eeskujuks [selles](https://www.aclweb.org/anthology/W14-3207.pdf) artiklis väljatoodud tunnused, mida on kasutanud mitmed autorid ja mis inglise keele peal usaldusväärseid tulemusi on andnud. Need keskenduvad psüühikahäiretega inimestele omastele sümptomitele nagu negatiivsus, vähene sotsiaalne kaasatus jne. Lähtudes eesti keele võimalustest ja vajadustest, kasutame siin ülesandes järgmisi tunnuseid:\n",
    "* postituse kellaaeg - psüühikahäiretega inimesi vaevab sageli unetus ja seetõttu postitavad nad tihti öösiti\n",
    "* teiste kasutajatega suhtlemine - psüühikahäiretega inimesed on sageli vähem sotsiaalselt kaasatud, Twitteris toimuvad aga n-ö vestlused just teise kasutaja kasutajanime mainimise teel\n",
    "* Esimese isiku sage kasutus - viidatud artiklis on leitud, et psüühikahäiretega inimesed kasutavad ingliskeelsetes postitustes rohkem 1. isiku asesõnu. Kuna eesti keeles võib isikut väljendada ka verbivormis, siis vaatleme nii 1. isikus asesõnu kui ka vastavaid verbivorme (kõigis aegades) \n",
    "* negatiivsete sõnade sage kasutus - kasutame EKI emotsioonileksikonis toodud negatiivseid sõnu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seega, püüame leida igale kasutajale nende tunnuste põhjal riskigruppi kuulumise skoori. Kui järjestame kasutajad skooride alusel, võime eeldada, et suurema skoori saanud kasutajad kuuluvad psüühikahäirete riskigruppi suurema tõenäosusega. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Andmed:**\n",
    "* säutsud - siin. Kui laadite alla ja pakite kausta lahti, leiate json-formaadis failid\n",
    "* emotsioonileksikon - fail *estonian-emotion-lexicon.csv*. Fail on Windowsi kodeeringus ('1257') ning eraldajaks ('delimiter') on semikoolon (;). Kuna kirjanduses ei ole leitud seost positiivsete sõnade ja psüühikahäirete esinemise/mitteesinemise vahel, siis kasutame failist ainult negatiivseid (miinusmärgiga skooriga) sõnu. **NB!** Failis on sõnavormid, mitte lemmad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Skoori arvutamine:**\n",
    "* Arvutame igale kasutajale eraldi skoorid unetuse, negatiivsuse, 1. isiku kasutuse ning teiste kasutajate mainimise kohta. **Lõpuks liidame 4 skoori kokku ning selle alusel järjestame tulemused.**\n",
    "* **Unetus:** iga postitus, mis on tehtud ajavahemikus 01:00 - 06:00 öösel, lisab skoorile ühe punkti. Jagada läbi kasutaja postituste arvuga. (St: kui kasutaja on teinud 20 postitust, millest 5 on tehtud vahemikus 01:00-06:00, siis on kasutaja unetuse skoor 5/20 = 0,4). Vaatame andmetest tunnust 'created_at'\n",
    "* **Sotsiaalne kaasatus:** iga vastus teisele kasutajale lisab skoorile ühe punkti. Jagada läbi kasutaja postituste arvuga. Vaatame andmetest tunnust 'in_reply_to_screen_name'. **NB!** Kuna sotsiaalne kaasatus on pöördtunnus - kõrgem väärtus tähendab väiksemat psüühikahäirete riski - , siis tuleks selle lõppskoorile lisada ette miinusmärk.\n",
    "* **1. isiku kasutus:** iga 1. isikus asesõna või verb lisab skoorile ühe punkti. Jagada läbi kasutaja postituste arvuga. Vaatame andmetest tunnust 'text'\n",
    "* **Negatiivsus:** iga leksikonis negatiivset skoori omav sõna postituses lisab skoorile nii palju punkte nagu emotsioonileksikonis skoorina antud on. Kuna soovime lõpus kõik skoorid kokku liita, tuleks siinkohal ka miinusmärgiga arvude asemel kasutada absoluutväärtusi. Jagada läbi kasutaja postituste arvuga. Vaatame andmetest tunnust 'text'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaadake peale paari kõige kõrgema ja kõige madalama skoori saanud kasutaja säutsudele. Kas tundub, et metoodikat oleks võimalik tulemuslikult rakendada ka eesti keele peal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vikipeedia töötlus EstNLTK 1.4-s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui soovime saada palju andmeid erinevate teemade kohta, siis üheks kasulikuks allikaks on kindlasti Vikipeedia. EstNLTK uues versioonis pole veel vahendeid eestikeelse Vikipeedia töötlemiseks, küll aga võimaldab seda EstNLTK 1.4. Seal on olemas töövahendid eestikeelse Vikipeedia allalaadimiseks ning xml-kujult json-kujule viimiseks (juhised [siin](https://estnltk.github.io/estnltk/1.4.1/tutorials/wikipedia.html#extracting-articles-from-xml-files)). \n",
    "Selleks on aga esmalt tarvis luua uus conda keskkond, mis kasutab Python 3.5 versiooni ning sellele installida EstNLTK 1.4. \n",
    "Tuleb aga arvestada, et eestikeelne Vikipeedia on päris suur ja seega kogu Vikipeedia töötlemine võtab kaua aega (\"kaua\" tähendab siinkohal seda, et sõltuvalt arvutist läheb mitmeid tunde või terve päev). \n",
    "\n",
    "**Siinses praktikumis pole vaja eelmist EstNLTKd installida ja Vikipeediat alla laadida, kasutame töötlemiseks juba eelnevalt kogutud ja json-kujule viidud väikest alamhulka Vikipeedia failidest.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 2. Isikute ja asukohtadega seotud informatsiooni ekstraheerimine tekstist (2,5p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oletame, et soovime luua andmebaasi selle kohta, millistes kohtades mingi kunstnik viibis ja milliseid stiile viljeles. Andmebaasi põhjal oleks võimalik lisaks konkreetsete kunstnike andmetele leida infot, missuguses asukohas mingit kunstistiili kõige enam viljeleti. \n",
    "\n",
    "Seega, **eesmärk** on ekstraheerida kunstnike Vikipeedia artiklitest informatsiooni nende:\n",
    "   * seotusest erinevate asukohtadega - kes kunstnikest millistes asukohtades (riigid, linnad, külad jne) sündis, elas, töötas, maalis jne.\n",
    "   * viljeletud kunstisuundadest\n",
    "   \n",
    "Selle saavutamiseks kasutame EstNLTK vahendeid kombineeritult reeglipõhise lähenemisega."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Andmed:** \n",
    "* Tekstid on pakituna kaustas *kunstnikud*. Kui kausta lahti pakite, leiate ~1500 json-formaadis Vikipeedia artiklit.\n",
    "* Kunstistiilide leksikon on failis *kunstivoolud.txt*. Enamiku kunstivoolude kohta leidub leksikonis enam kui 1 märksõna, mida tuleb väljundis käsitleda võrdsetena (impressionism = impressionist = impressionistlik)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loodava programmi abil:**\n",
    "* loetakse etteantud kaustast sisse failides olevas tekstid,\n",
    "* tuvastatakse tekstidest sellised osalaused, milles sisaldub:\n",
    "     - vähemalt üks asukohale viitav nimega üksus (LOC) \n",
    "     - JA/VÕI\n",
    "     - vähemalt üks kunstivoolule viitav märksõna (failist \"kunstivoolud.txt\")\n",
    "     \n",
    "**NB! Osalausete läbikäimisel tuleta meelde 9. praktikumi**\n",
    "     \n",
    "* kui tuvastatud osalauses leidub ka pärisnimele viitavaid nimega üksusi (PER), siis tuleks kontrollida, kas vähemalt mõnel neist on midagi ühist failinimes oleva kunstniku nimega (ees- või perekonnanimi - võime oletada, et kui Aado Vabbe failis räägitakse Aadost, siis on tegu ikka selle sama kunstnikuga, aga kui Viiraltist, siis ilmselt mitte). Kui tundub, et osalause räägib ainult mõnest teisest isikust, siis ärme sellest osalausest leitud asukohale ja/või kunstistiilidele tähelepanu pööra.\n",
    "* kui tuvastatud osalauses pärisnimele viitavaid üksusi üldse ei leidu, siis omistame leitud asukohad ja kunstivoolud kunstnikule, kelle nime leiame faili nimest\n",
    "* väljundiks peaks olema kaks json-formaadis faili - üks sisaldab iga kunstniku asukohti, teine iga kunstniku viljeldud kunstistiile. Kunstnike nimed on sellisel kujul nagu failinimedes.\n",
    "\n",
    "**NB2! Nimeolemite eraldamisel tuleb siingi arvestada, et töö võib olla ajamahukas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Millised asukohad on impressionistide seas kõige populaarsemad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraaside eraldamine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eelnevates ülesannetes eraldasime tekstidest informatsiooni üksteisest eraldiseisvaid üksusi vaadates – leidsime asesõnu, nimeüksusi, võrdlesime tekstisõnu etteantud leksikoniga. Mõnikord nõuab ülesanne aga üldisemat lähenemist, näiteks on vaja lähtuda teksti struktuurist. Kui tahame eraldada järjestikkuseid sõnu/tekstiosi hõlmavaid struktuure, saame seda teha **`PhraseTagger`**'i abil. PhraseTagger võimaldab kirjeldada mõne kihi atribuutidest koosnevaid mustreid ning märgendada tekstist neile vastavaid fraase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaatame näiteks, kuidas saaks tekstist eraldada lihtsaid [komparatiivtarindeid](https://et.wikipedia.org/wiki/Adjektiivne_v%C3%B5rdlustarind#Komparatiivtarind), täpsemalt juhtusid, kus omadussõna on keskvõrdes ning sellele järgneb sidesõna *kui* abil seotud võrdlusalus. Märgendame kihi, mida sisendina kasutada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Andres oli alguses pikem kui Jaan.  Nüüdseks on Jaan kasvanud isegi pikemaks kui Andresestki pikem Taavi.  Villu oli märksa lühem kui teised poisid ja ainult natuke suurekasvulisem kui õde Ann. Selles vanuses pole enam pikemaks aga Villul lootust kasvada.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Andres oli alguses pikem kui Jaan.  Nüüdseks on Jaan kasvanud isegi pikemaks kui Andresestki pikem Taavi.  Villu oli märksa lühem kui teised poisid ja ainult natuke suurekasvulisem kui õde Ann. Selles vanuses pole enam pikemaks aga Villul lootust kasvada.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "text = Text(\"Andres oli alguses pikem kui Jaan. \"\n",
    "           \" Nüüdseks on Jaan kasvanud isegi pikemaks kui Andresestki pikem Taavi. \"\n",
    "           \" Villu oli märksa lühem kui teised poisid ja ainult natuke suurekasvulisem kui õde Ann.\"\n",
    "           \" Selles vanuses pole enam pikemaks aga Villul lootust kasvada.\")\n",
    "\n",
    "text.tag_layer(['morph_analysis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loome PhraseTaggeri, mis tekitab kihi kindlas järjestuses sõnaliikide alusel. Vajalikud sõnaliikide järjestused anname taggerile sõnastike listina atribuudis `vocabulary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Andres oli alguses pikem kui Jaan.  Nüüdseks on Jaan kasvanud isegi pikemaks kui Andresestki pikem Taavi.  Villu oli märksa lühem kui teised poisid ja ainult natuke suurekasvulisem kui õde Ann. Selles vanuses pole enam pikemaks aga Villul lootust kasvada.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comparative_phrases</td>\n",
       "      <td>phrase</td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Andres oli alguses pikem kui Jaan.  Nüüdseks on Jaan kasvanud isegi pikemaks kui Andresestki pikem Taavi.  Villu oli märksa lühem kui teised poisid ja ainult natuke suurekasvulisem kui õde Ann. Selles vanuses pole enam pikemaks aga Villul lootust kasvada.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import PhraseTagger\n",
    "\n",
    "phrase_list = [{'phrase': ('C', 'J', 'S')},\n",
    "              {'phrase': ('C', 'J', 'P')},\n",
    "              {'phrase': ('C', 'J', 'H')},\n",
    "              {'phrase': ('H', 'C')},\n",
    "              {'phrase': ('P', 'C')},\n",
    "              {'phrase': ('S', 'C')}]\n",
    "\n",
    "phrase_tagger = PhraseTagger(output_layer='comparative_phrases',\n",
    "                             input_layer='morph_analysis',\n",
    "                             input_attribute='partofspeech',\n",
    "                             vocabulary=phrase_list,\n",
    "                             key='phrase',\n",
    "                             output_attributes=['phrase'])\n",
    "\n",
    "phrase_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PhraseTaggeri loomisel olulisemad atribuudid:\n",
    "\n",
    "`output_layer` - mis kihti leitavad fraasid lisame\n",
    "\n",
    "\n",
    "`input_layer` - sisendkiht, mille põhjal fraase leiame\n",
    "\n",
    "\n",
    "`input_attribute` - sisendkihi atribuut, mis on fraaside leidmise aluseks\n",
    "\n",
    "\n",
    "`vocabulary` - selle parameetriga saab ette anda nt (csv-)failinime, listi või Vocabulary-objekti, mis sisaldab mustreid, mida leida tahame, ja mille tagger võtab fraaside määramise aluseks\n",
    "\n",
    "\n",
    "`key` - vocabulary element, mis määrab leitava mustri\n",
    "\n",
    "\n",
    "`output_attributes` - list atribuutidest, mis tuleb väljundkihis esitada\n",
    "\n",
    "\n",
    "`decorator` - kahe argumendiga (span ja annotation) funktsioon, mis tagastab True, kui märgendus on korrektne, muul juhul False. Dekoraatori sees saab seada tingimusi, millele annotation peab vastama ja vajadusel saab sellele ka uusi atribuute lisada.\n",
    "\n",
    "`conflict_resolving_strategy` - konfliktilahendusstrateegia\n",
    "\n",
    "\n",
    "`priority_attribute` - *vocabulary*'s defineeritud prioriteeti tähistava atribuudi nimi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ülejäänud atribuutide kohta saab rohkem informatsiooni [siit](https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/taggers/phrase_tagger.ipynb).\n",
    "\n",
    "Vaatame nüüd saadud kihti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>comparative_phrases</td>\n",
       "      <td>phrase</td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['pikem', 'kui', 'Jaan']</td>\n",
       "      <td>('C', 'J', 'H')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['pikemaks', 'kui', 'Andresestki']</td>\n",
       "      <td>('C', 'J', 'H')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['lühem', 'kui', 'teised']</td>\n",
       "      <td>('C', 'J', 'P')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['suurekasvulisem', 'kui', 'õde']</td>\n",
       "      <td>('C', 'J', 'S')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['pikemaks', 'aga', 'Villul']</td>\n",
       "      <td>('C', 'J', 'H')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='comparative_phrases', attributes=('phrase',), spans=SL[EnvelopingSpan(['pikem', 'kui', 'Jaan'], [{'phrase': ('C', 'J', 'H')}]),\n",
       "EnvelopingSpan(['pikemaks', 'kui', 'Andresestki'], [{'phrase': ('C', 'J', 'H')}]),\n",
       "EnvelopingSpan(['lühem', 'kui', 'teised'], [{'phrase': ('C', 'J', 'P')}]),\n",
       "EnvelopingSpan(['suurekasvulisem', 'kui', 'õde'], [{'phrase': ('C', 'J', 'S')}]),\n",
       "EnvelopingSpan(['pikemaks', 'aga', 'Villul'], [{'phrase': ('C', 'J', 'H')}])])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.comparative_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Väljundist torkab silma kaks puudust: \n",
    "\n",
    "1) tuleb välja, et lisaks *kui*-tarindile võime tulemusse saada ka teiste, soovimatute sidesõnadega seotud fraase. Fraaside filtreerimiseks saab dekoraatorisse lisada tingimusi, mille põhjal fraase aktsepteerida või välja jätta. Samuti saab määrata kihile uusi atribuute ja nende väärtusi. \n",
    "\n",
    "Lahendame selle probleemi, luues dekoraatori, mis aktsepteerib fraase, mille sidesõnaks on *kui*, ja mustrile ('H', 'C') vastavaid fraase, mille puhul pärisnimi on seestütlevas käändes. Lisame kihile atribuudi, mis sisaldab võrdlusaluseks olevat tekstisõna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorator(span, annotation):\n",
    "    if len(span) == 2:\n",
    "        for anno in span[0].annotations:\n",
    "            # annotation.phrase kaudu saame kätte vaatlusaluse mustri\n",
    "            if anno.partofspeech == annotation.phrase[0] and 'el' in anno.form:\n",
    "                annotation['base_of_comparison'] = span[0].text\n",
    "                return True\n",
    "    \n",
    "    if span[1].text == 'kui':\n",
    "        annotation['base_of_comparison'] = span[2].text\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Teiseks on puudu järjestusele ('H', 'C') vastav fraas, kuigi tekstis vastab sellele *Andresestki pikem*. Probleem tekib lõigust *pikemaks kui Andresestki pikem*. Nagu näha, on siinkohal kattuvus mustrite ('C', 'J', 'H') ning ('H', 'C') vahel. Vaikimisi jätab PhraseTagger kattuvuste korral alles vaid pikema järjendi. Seda saame aga muuta.\n",
    "\n",
    "PhraseTagger kasutab kattuvate fraaside lahendamiseks kihi meetodit `resolve_conflicts`. Sellele saame kattuvustega tegelemiseks ette anda konfliktilahendusstrateegia ja soovi korral ka mustrite prioriteedid. Parameetriga `conflict_resolving_strategy` on võimalik kattuvusi lahendada järgmisi väärtusi ette andes:\n",
    "  - *ALL* - alles jäävad kõik vasted, võttes arvesse seatud prioriteete;\n",
    "  - *MAX* - alles jääb maksimaalse pikkusega vaste, võrdsete pikkuste puhul kõrgema prioriteediga vaste;\n",
    "  - *MIN* - alles jääb minimaalse pikkusega vaste, võrdsete pikkuste puhul kõrgema prioriteediga vaste.\n",
    "\n",
    "Seega, kui tahaksime, et loetletud oleksid kõik vasted, saame taggerit luues konfliktilahendusstrateegia ette anda, lisades `conflict_resolving_strategy='ALL'`, kuid arvesse peab võtma, et kattuvate Span'ide korral ei saaks me nt kasutada `layer.display()` meetodit kihi visualiseerimiseks. \n",
    "\n",
    "Oletame, et meil on vaja *pikemaks kui Andresestki pikem* lõigust kätte saada hoopis fraas *Andresestki pikem*. Kui me oleme täiesti kindlad, et esmajärjekorras on meil alati vaja kätte saada lühem vaste, saame valida konfliktilahendusstrateegia 'MIN'. \n",
    "\n",
    "Samas võib mõnikord tekkida olukordi, kui konflikt tekib kahe sama pika järjendi vahel või mõnel juhul tahame alles jätta pikemat, aga teisel juhul lühemat fraasi. Seesuguste olukordade lahendamiseks saame fraasidele määrata prioriteedid. PhraseTaggerit luues paneme need kirja *vocabulary*'sse: prioriteetsem fraas saab väiksema arvulise väärtuse. Kindlasti tuleb prioriteete kasutades määrata märgendajat luues ka atribuut `priority_attribute`, mis viitab, millise kihiatribuudi alt prioriteedi leiame.   \n",
    "\n",
    "Lisame nüüd *vocabulary*'sse prioriteedid ja katsetame konfliktilahendust, mis arvestab ainult etteantud prioriteete (st strateegiaks peab olema 'ALL'). Määrame ka dekoraatori:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loome uue taggeri, mis sisaldab dekoraatorit ja konfliktilahendust\n",
    "# output_attributes peab sisaldama ka dekoraatoris määratud atribuute\n",
    "\n",
    "phrase_tagger = PhraseTagger(output_layer='comparative_phrases',\n",
    "                             input_layer='morph_analysis',\n",
    "                             input_attribute='partofspeech',\n",
    "                            vocabulary=[{'phrase': ('C', 'J', 'S'), 'priority': 2},\n",
    "                                       {'phrase': ('C', 'J', 'P'), 'priority': 2},\n",
    "                                       {'phrase': ('C', 'J', 'H'), 'priority': 2},\n",
    "                                       {'phrase': ('H', 'C'), 'priority': 1},\n",
    "                                       {'phrase': ('P', 'C'), 'priority': 1},\n",
    "                                       {'phrase': ('S', 'C'), 'priority': 1}],\n",
    "                            key='phrase',\n",
    "                            decorator=decorator,\n",
    "                            conflict_resolving_strategy='ALL',\n",
    "                            priority_attribute='priority',\n",
    "                            output_attributes=['phrase', 'base_of_comparison'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>comparative_phrases</td>\n",
       "      <td>phrase</td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['pikem', 'kui', 'Jaan']</td>\n",
       "      <td>('C', 'J', 'H')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['pikemaks', 'kui', 'Andresestki']</td>\n",
       "      <td>('C', 'J', 'H')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['lühem', 'kui', 'teised']</td>\n",
       "      <td>('C', 'J', 'P')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['suurekasvulisem', 'kui', 'õde']</td>\n",
       "      <td>('C', 'J', 'S')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['pikemaks', 'aga', 'Villul']</td>\n",
       "      <td>('C', 'J', 'H')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='comparative_phrases', attributes=('phrase',), spans=SL[EnvelopingSpan(['pikem', 'kui', 'Jaan'], [{'phrase': ('C', 'J', 'H')}]),\n",
       "EnvelopingSpan(['pikemaks', 'kui', 'Andresestki'], [{'phrase': ('C', 'J', 'H')}]),\n",
       "EnvelopingSpan(['lühem', 'kui', 'teised'], [{'phrase': ('C', 'J', 'P')}]),\n",
       "EnvelopingSpan(['suurekasvulisem', 'kui', 'õde'], [{'phrase': ('C', 'J', 'S')}]),\n",
       "EnvelopingSpan(['pikemaks', 'aga', 'Villul'], [{'phrase': ('C', 'J', 'H')}])])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.pop_layer('comparative_phrases')  # eemaldame eelmise taggeriga saadud kihi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>comparative_phrases</td>\n",
       "      <td>phrase, base_of_comparison, priority</td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>phrase</th>\n",
       "      <th>base_of_comparison</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['pikem', 'kui', 'Jaan']</td>\n",
       "      <td>('C', 'J', 'H')</td>\n",
       "      <td>Jaan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Andresestki', 'pikem']</td>\n",
       "      <td>('H', 'C')</td>\n",
       "      <td>Andresestki</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['lühem', 'kui', 'teised']</td>\n",
       "      <td>('C', 'J', 'P')</td>\n",
       "      <td>teised</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['suurekasvulisem', 'kui', 'õde']</td>\n",
       "      <td>('C', 'J', 'S')</td>\n",
       "      <td>õde</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='comparative_phrases', attributes=('phrase', 'base_of_comparison', 'priority'), spans=SL[EnvelopingSpan(['pikem', 'kui', 'Jaan'], [{'phrase': ('C', 'J', 'H'), 'base_of_comparison': 'Jaan', 'priority': 2}]),\n",
       "EnvelopingSpan(['Andresestki', 'pikem'], [{'phrase': ('H', 'C'), 'base_of_comparison': 'Andresestki', 'priority': 1}]),\n",
       "EnvelopingSpan(['lühem', 'kui', 'teised'], [{'phrase': ('C', 'J', 'P'), 'base_of_comparison': 'teised', 'priority': 2}]),\n",
       "EnvelopingSpan(['suurekasvulisem', 'kui', 'õde'], [{'phrase': ('C', 'J', 'S'), 'base_of_comparison': 'õde', 'priority': 2}])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Märgendame kihi uuendatud taggeriga\n",
    "phrase_tagger.tag(text)\n",
    "text.comparative_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ülesanne 3. Nimisõnafraaside eraldamine (1p + 0,5 boonuspunkti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Püüdke kirjutada PhraseTagger, mis märgendab tekstis n-ö laiemas tähenduses nimisõnafraase: erinevalt keeleteadusest, ei ole info eraldamise seisukohast üldiselt vahet, kas tekstis on öeldud \"poes on hea teenindus\" või \"teenindus oli poes hea\" või hoopis \"poes teenindus hea\". Katsetage taggerit faili *hinnavaatlus.csv* tekstide peal. Märgenduse peaksid saama minimaalselt järgmised nädisstruktuurid:\n",
    "\n",
    "* suur õun\n",
    "* suur ja sinine õun\n",
    "* suur sinine õun\n",
    "* õun on suur\n",
    "* õun suur\n",
    "* õun on suur ja sinine\n",
    "\n",
    "Seejuures sõnad 'õun', 'suur' ja 'sinine' peaksid olema üldistatud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Märgendatavale kihile lisage ka atribuut, mis sisaldab järjendit normaliseeritud fraasist: viige leitud fraasid kujule \"suur õun\" e omadussõna, millele järgneb nimisõna. Kui leidub mitu omadussõna, tehke igast eraldi fraas (\"suur ja sinine õun\" -> [\"suur õun\", \"sinine õun\"]), kusjuures fraas peaks olema algvormis. Mitmeste analüüside puhul jälgige, et algvorm oleks korrektne (\"tehtud töö\", mitte \"tegema töö\").\n",
    "\n",
    "**0,5 boonuspunkti** saab teenida fraaside täpsema filtreerimisega. Uuri väljundist, milliseid ebatäpsusi näed ning paranda taggerit nii, et see likvideeriks mõne vigadest (kirjelda, milliseid vigu parandasid). Vihje: alustuseks võiks mõelda näiteks, mis on (süsteemselt) valesti lausetes *Olen Tartu **esindustest ostnud** probleemivabalt* või *Õnneks sai mul üks **tuttav garantiiga** aidata*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lisamaterjal: Grammatikad EstNLTK-s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PhraseTaggerist keerukam, kuid mõnevõrra võimalusterohkem on kontekstivaba grammatika kirjutamine. Selle jaoks on EstNLTK-s klassid Grammar ja GrammarParsingTagger.\n",
    "\n",
    "Grammatikate puhul defineerime ära n-ö ehitusplokid, millest meie soovitavad üksused koosnevad, ning reeglid, kuidas plokid omavahel kombineeruvad. Loodud grammatika anname ette GrammarParsingTaggerile, mis märgendab teksti grammatikast lähtudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loome näiteks grammatika, mis märgendab primitiivseid omadussõnafraase (selle ülesande jaoks on olemas ka spetsiaalne [AdjectivePhraseTagger](https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/taggers/adjective_phrase_tagger.ipynb), kuid õppimise mõttes proovime ise üht luua).\n",
    "\n",
    "Tahame märgendada järgmisi konstruktsioone:\n",
    " - suur\n",
    " - suur ja ilus\n",
    " - ilus suur\n",
    " - suurem\n",
    " - suurem ja ilusam\n",
    " \n",
    "Alustuseks loome Grammar-objekti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.finite_grammar import Grammar, Rule\n",
    "from estnltk.taggers import GrammarParsingTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = Grammar(start_symbols=['ADJECTIVE_CHAIN'],\n",
    "                  depth_limit=float('inf'), # vaikimisi\n",
    "                  width_limit=float('inf'), # vaikimisi\n",
    "                  legal_attributes=['comparison_degree', 'pattern']\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Start_symbol`-iga määrame, millisele reeglile vastavaid järjendeid tahame väljundisse. Kasutades üht algussümbolit, saame lihtsama ja paremini hoomatava mudeli.\n",
    "Parameetri `legal_attributes` alla tuleb märkida dekoraatoriga lisatavad atribuudid (sellest tuleb peagi juttu).\n",
    "\n",
    "Nüüd on vaja grammatikasse reegleid lisada. Reegel koosneb vasakust ja paremast poolest, kus vasakul pool on üks mitteterminaal ja paremal seda määravad terminaalid (siinse näite puhul sõnaliigimärgendid) või mitteterminaalid. Pooled on üksteisega asendatavad. Erinevalt PhraseTaggerist saab grammatikareeglites teha rohkem üldistusi. Näiteks kui oleme reeglitega juba määranud, et omadussõnana käsitleme ükskõik millist omadussõna võrdlusastet, ei pea me fraasi defineerimiseks enam kirjutama eraldi reegleid nii algvõrdes kui ka keskvõrdes omadussõnale.\n",
    "\n",
    "Selleks, et täpsustada, millised reeglitele leitavad vasted väljundisse sobivad, saame igale reeglile määrata validaatori. Samuti on võimalik reeglile lisada dekoraator, mis võimaldab väljundkihi atribuutite väärtustada.\n",
    "\n",
    "Kirjutame reeglid, mis käsitlevad nii alg- kui ka keskvõrret ühtmoodi ning aktsepteerivad määrsõna nende ees. Lisame reeglitele dekoraatori, mis lisab kihiatribuudi alla võrdlusastme (esimese omadussõna järgi) ning mustri, mille järgi vaste leitud on. Reeglile, mis eraldab sidesõnaga seotud omadussõnu, lisame validaatori, mis kontrollib, kas omadussõnad ühilduvad vormis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorator(nodes):\n",
    "    degree = ''\n",
    "    \n",
    "    # Muster, mille põhjal vaste on leitud\n",
    "    pattern = ' '.join([node.name for node in nodes])\n",
    "    \n",
    "    # Lisame mustri esimesele elemendile vastava terminaali järgi võrdlusastme\n",
    "    if nodes[0].terminals[0].name == 'A':\n",
    "        degree = 'positive'\n",
    "    elif nodes[0].terminals[0].name == 'C':\n",
    "        degree = 'comparative'\n",
    "\n",
    "    return {'comparison_degree': degree,\n",
    "            'pattern': pattern}\n",
    "\n",
    "def validator(nodes):\n",
    "    adj1 = nodes[0].terminals[0].attributes['form']  # terminals alt saame kätte vajaliku vormi\n",
    "    adj2 = nodes[2].terminals[0].attributes['form']\n",
    "    if adj1 == adj2:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADJECTIVE võib tähistada määramatut hulka järjestikusi algvõrdes omadussõnu\n",
    "grammar.add_rule('ADJECTIVE', 'MSEQ(A)', group='g0', decorator=decorator)  \n",
    "\n",
    "# ADJECTIVE võib tähistada määramatut hulka järjestikusi keskvõrdes omadussõnu\n",
    "grammar.add_rule('ADJECTIVE', 'MSEQ(C)', group='g0', decorator=decorator)\n",
    "\n",
    "# ADJECTIVE_CHAIN võib olla ADJECTIVE või kaks sidesõnaga seotud ADJECTIVE'i\n",
    "grammar.add_rule('ADJECTIVE_CHAIN', 'ADJECTIVE', group='g0', priority=3, decorator=decorator)\n",
    "grammar.add_rule('ADJECTIVE_CHAIN', 'ADJECTIVE J ADJECTIVE', group='g0', priority=1, validator=validator, decorator=decorator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui teame, et meie mustris võib olla (teadmata arv) korduvaid osi, saame seda edasi anda lisades selle MSEQ- või SEQ-reeglite abil. MSEQ-reegliga saab määrata korduvad tekstiosad, nii et tagastatakse pikim võimalik variant, samamoodi kasutatav SEQ-reegel tagastab kõik võimalikud variandid. Kuna fraasides võib esineda erinimelisi täiendeid, mida ei eraldata komaga, ja meid huvitavad kõik neist, saamegi kirjutada reegli MSEQ(A), mis tuvastab _**suur punane** õhupall_ omadussõnad ühe üksusena.\n",
    "Dekoraatori kasutamisel tuleb vajadusel MSEQ- ja SEQ-reegleid eksplitsiitselt käsitleda.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Vahemärkus:</b> MSEQ tekitab eraldi grupi, mis juskui ei konkureeri tavaliste prioriteetide alusel, tekitades väljundisse soovimatuid vasteid. Kui see on oluline, tuleb dekoraatoris prioriteedid üle kirjutada ja hiljem kihi kattuvused <i>resolve_conflicts</i>-funktsiooniga lahendada. Vt näidet altpoolt.\n",
    "</div>\n",
    "\n",
    "Kuna meie jaoks ei ole oluline, mis võrdlusastmes omadussõnaga tegu on, saime kirjutada üldistava reegli, millega määrame nii algvõrded (A) kui ka keskvõrded (C) mitteterminaali 'ADJECTIVE' alla.\n",
    "'ADJECTIVE_CHAIN' reeglite vasted on need, mis jõuavad väljundisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Grammar:\n",
       "\tstart: ADJECTIVE_CHAIN\n",
       "\tterminals: J, MSEQ(A), MSEQ(C)\n",
       "\tnonterminals: ADJECTIVE, ADJECTIVE_CHAIN\n",
       "\tlegal attributes: frozenset({'pattern', 'comparison_degree'})\n",
       "\tdepth_limit: inf\n",
       "\twidth_limit: inf\n",
       "Rules:\n",
       "\tADJECTIVE -> MSEQ(A)\t: 0, val: default_validator, dec: decorator, scoring: default_scoring\n",
       "\tADJECTIVE -> MSEQ(C)\t: 0, val: default_validator, dec: decorator, scoring: default_scoring\n",
       "\tADJECTIVE_CHAIN -> ADJECTIVE\t: 3, val: default_validator, dec: decorator, scoring: default_scoring\n",
       "\tADJECTIVE_CHAIN -> ADJECTIVE J ADJECTIVE\t: 1, val: validator, dec: decorator, scoring: default_scoring"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nüüd, kui grammatika on tehtud, peame tekstile vastava märgenduse lisamiseks tekitama GrammarParsingTaggeri. Loomisel peame määrama kasutatava grammatika. Samuti on vaja määrata, mis nimega kihti ja millist selle atribuuti sisendina kasutame. Muidugi kirjeldame ka väljundkihi ja -atribuudid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_tagger = GrammarParsingTagger(grammar=grammar,\n",
    "                                      name_attribute='partofspeech', # vaikimisi 'grammar_symbol'\n",
    "                                      layer_of_tokens='morph_analysis',\n",
    "                                      attributes=('comparison_degree', 'pattern'),\n",
    "                                      output_layer='adjectives',\n",
    "                                      output_ambiguous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaatame, kuidas grammatika tekstil töötab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Text('Eriti isuäratavad ja maitsvad saavad koogid antonovkast.'\n",
    "' Kõige magusamad õunasordid jätkem lihtsalt maiustamiseks.'\n",
    "' Nendest ei pruugi saada nii häid mahlaseid kooke kui hapukatest õuntest.').tag_layer(['morph_analysis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>adjectives</td>\n",
       "      <td>comparison_degree, pattern</td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>comparison_degree</th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['isuäratavad', 'ja', 'maitsvad', 'saavad']</td>\n",
       "      <td>positive</td>\n",
       "      <td>ADJECTIVE J ADJECTIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['magusamad']</td>\n",
       "      <td>comparative</td>\n",
       "      <td>ADJECTIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['häid', 'mahlaseid']</td>\n",
       "      <td>positive</td>\n",
       "      <td>ADJECTIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['hapukatest']</td>\n",
       "      <td>positive</td>\n",
       "      <td>ADJECTIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='adjectives', attributes=('comparison_degree', 'pattern'), spans=SL[EnvelopingSpan(['isuäratavad', 'ja', 'maitsvad', 'saavad'], [{'comparison_degree': 'positive', 'pattern': 'ADJECTIVE J ADJECTIVE'}]),\n",
       "EnvelopingSpan(['magusamad'], [{'comparison_degree': 'comparative', 'pattern': 'ADJECTIVE'}]),\n",
       "EnvelopingSpan(['häid', 'mahlaseid'], [{'comparison_degree': 'positive', 'pattern': 'ADJECTIVE'}]),\n",
       "EnvelopingSpan(['hapukatest'], [{'comparison_degree': 'positive', 'pattern': 'ADJECTIVE'}])])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_tagger.tag(text)\n",
    "text.adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Praegusel juhul vaatlesime väga lihtsakoelise grammatika loomist, tuginedes *morph_analysis* kihile. Kui aga oskame ise Taggereid luua, nagu 9. praktikumis õppisime, saame oluliselt laiendada ka grammatikate kasutamist.\n",
    "Rohkem informatsiooni grammatikate loomise ja kasutamise kohta leiad [siit](https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/finite_grammar/introduction_to_finite_grammar.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSEQ-prioriteedi seadmine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eespool leidus väide, et MSEQ-reegel tekitab eraldi grupi, mis võib teatud juhtudel, hoolimata reegli prioriteetidest, tekitada väljundisse soovimatuid vasteid. Järgnevalt vaatame ühte sellise probleemi tekkimist ja lahendamist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kirjutame veel lihtsama grammatika kui enne: meid huvitavad vaid algvormis omadussõnad, mis võivad esineda ühekaupa, mitmekaupa järjest või sidesõnaga eraldatult kahekaupa. Seame prioriteedid nii, et kattuvuste korral jääks alles sidesõnaga ühendatud omadussõnad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_2 = Grammar(start_symbols=['ADJECTIVE_CHAIN'])\n",
    "grammar_2.add_rule('ADJECTIVE_CHAIN', 'A J A', group='g0', priority=3)\n",
    "grammar_2.add_rule('ADJECTIVE_CHAIN', 'MSEQ(A)', group='g0', priority=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_tagger = GrammarParsingTagger(grammar=grammar_2,\n",
    "                                      name_attribute='partofspeech',\n",
    "                                      layer_of_tokens='morph_analysis',\n",
    "                                      output_layer='adjectives_2',\n",
    "                                      output_ambiguous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>adjectives_2</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['isuäratavad']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['isuäratavad', 'ja', 'maitsvad']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['maitsvad', 'saavad']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['häid', 'mahlaseid']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['hapukatest']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='adjectives_2', attributes=(), spans=SL[EnvelopingSpan(['isuäratavad'], [{}]),\n",
       "EnvelopingSpan(['isuäratavad', 'ja', 'maitsvad'], [{}]),\n",
       "EnvelopingSpan(['maitsvad', 'saavad'], [{}]),\n",
       "EnvelopingSpan(['häid', 'mahlaseid'], [{}]),\n",
       "EnvelopingSpan(['hapukatest'], [{}])])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_tagger.tag(text)\n",
    "text.adjectives_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Näeme, et MSEQ(A) reegli vasted on aktsepteeritud ka juhtudel, kui prioriteedi alusel oleks pidanud eelistama teist reeglit, st järjendid ['isuäratavad'] ja ['maitsvad', 'saavad'] on üleliigsed. Sellel puhul pole teha muud, kui lisada MSEQ-reeglile parameeter `scoring`, mis peab olema suurem kui 0, et kõik vastavused jõuaksid kindlasti väljundisse. Seejärel tuleb dekoraatoris prioriteedid atribuutidena üle määrata ning viimaks `resolve_conflicts`-meetodiga soovimatud märgendused eemaldada. Vaatame, kuidas see käib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorator(nodes):\n",
    "    degree = ''\n",
    "    pattern = ' '.join([node.name for node in nodes])\n",
    "    \n",
    "    #  Esiteks määrame dekoraatoris taaskord prioriteedid:\n",
    "    priority = 0\n",
    "    if pattern == 'MSEQ(A)':\n",
    "        priority = 2\n",
    "    elif pattern == 'A J A':\n",
    "        priority = 1\n",
    "\n",
    "    return {'pattern': pattern,\n",
    "            'priority': priority}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_2 = Grammar(start_symbols=['ADJECTIVE_CHAIN'], legal_attributes=['priority', 'pattern'])\n",
    "grammar_2.add_rule('ADJECTIVE_CHAIN', 'A J A', group='g0', priority=1, decorator=decorator)\n",
    "\n",
    "# Lisame MSEQ-reeglile parameetri \"scoring\"\n",
    "grammar_2.add_rule('ADJECTIVE_CHAIN', 'MSEQ(A)', group='g0', priority=2, decorator=decorator, scoring=lambda node: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_tagger = GrammarParsingTagger(grammar=grammar_2,\n",
    "                                      name_attribute='partofspeech',\n",
    "                                      layer_of_tokens='morph_analysis',\n",
    "                                      attributes=('pattern', 'priority'),\n",
    "                                      output_layer='adjectives_3',\n",
    "                                      output_ambiguous=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>adjectives_3</td>\n",
       "      <td>pattern, priority</td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>pattern</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['isuäratavad']</td>\n",
       "      <td>MSEQ(A)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['isuäratavad', 'ja', 'maitsvad']</td>\n",
       "      <td>A J A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['maitsvad', 'saavad']</td>\n",
       "      <td>MSEQ(A)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['häid', 'mahlaseid']</td>\n",
       "      <td>MSEQ(A)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['hapukatest']</td>\n",
       "      <td>MSEQ(A)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='adjectives_3', attributes=('pattern', 'priority'), spans=SL[EnvelopingSpan(['isuäratavad'], [{'pattern': 'MSEQ(A)', 'priority': 2}]),\n",
       "EnvelopingSpan(['isuäratavad', 'ja', 'maitsvad'], [{'pattern': 'A J A', 'priority': 1}]),\n",
       "EnvelopingSpan(['maitsvad', 'saavad'], [{'pattern': 'MSEQ(A)', 'priority': 2}]),\n",
       "EnvelopingSpan(['häid', 'mahlaseid'], [{'pattern': 'MSEQ(A)', 'priority': 2}]),\n",
       "EnvelopingSpan(['hapukatest'], [{'pattern': 'MSEQ(A)', 'priority': 2}])])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_tagger.tag(text)\n",
    "text.adjectives_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tulemus on sama, mis `grammar_2` kasutades, kuid nüüd tuleb kasuks dekoraatoris tekitatud atribuut *priority*. \n",
    "Kasutame sedasama `resolve_conflicts`-meetodit, mida mäletatavasti kasutas ka PhraseTagger oma \"kõhus\", et kattuvusi lahendada. Nii saame dekoraatoris tekitatud parameetrite kaudu konfliktidest jagu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>adjectives_3</td>\n",
       "      <td>pattern, priority</td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>pattern</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['isuäratavad', 'ja', 'maitsvad']</td>\n",
       "      <td>A J A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['häid', 'mahlaseid']</td>\n",
       "      <td>MSEQ(A)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['hapukatest']</td>\n",
       "      <td>MSEQ(A)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='adjectives_3', attributes=('pattern', 'priority'), spans=SL[EnvelopingSpan(['isuäratavad', 'ja', 'maitsvad'], [{'pattern': 'A J A', 'priority': 1}]),\n",
       "EnvelopingSpan(['häid', 'mahlaseid'], [{'pattern': 'MSEQ(A)', 'priority': 2}]),\n",
       "EnvelopingSpan(['hapukatest'], [{'pattern': 'MSEQ(A)', 'priority': 2}])])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.layer_operations import resolve_conflicts\n",
    "\n",
    "# Viimaseks lahendame konfliktid meetodiga resolve_conflicts\n",
    "resolve_conflicts(text.adjectives_3,  # tekstikiht, mida lahendatakse                 \n",
    "                  conflict_resolving_strategy='ALL',\n",
    "                  priority_attribute='priority',\n",
    "                  status=None,\n",
    "                  keep_equal=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uuesti kihti vaadates näeme, et üleliigsed vasted on nüüd tõepoolest kaotatud reegli (A J A) kasuks."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}