{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EstNLTK 1.6 baastarkused\n",
    "\n",
    "Käesoleva abimaterjal annab ülevaate EstNLTK 1.6 programeerimisliidesest.\n",
    "Eelkõige on see mõeldud lisalugemiseks neile, kel on tarvis EstNLTK andmestruktuuridest ja üldisest toimeloogikast rohkem teada saada, ning neile, kes tahavad ise programmatiliselt lisada märgenduskihte ja märgendajaid.\n",
    "Konkreetseid lingvistilise analüüsi (nt morfoloogia või süntaksi) tööriistu siin ei süvitsi käsitleta -- nende kohta leiab detailset infot praktikumimaterjalidest ning [EstNLTK inglisekeelsetest juhendmaterjalidest](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sisukord**\n",
    "<!-- MAKE TOC HERE -->\n",
    "\n",
    "<ul> \n",
    " <li><a href=\"#1.-Tekst-koos-märgendustega:-Text-klass\">1. Tekst koos märgendustega: Text klass</a></li>\n",
    "  <ul><li><a href=\"#1.1-Teksti-metaandmed\">1.1 Teksti metaandmed</a></li>\n",
    "  <li><a href=\"#1.2-Märgenduskihtide-lisamine-ja-eemaldamine\">1.2 Märgenduskihtide lisamine ja eemaldamine</a></li>\n",
    "   <ul><li><a href=\"#1.2.1-Meetod-tag_layer\">1.2.1 Meetod tag_layer</a></li>\n",
    "   <li><a href=\"#1.2.2-Millised-kihte-saab-tag_layer-abil-tekitada?-DEFAULT_RESOLVER\">1.2.2 Millised kihte saab tag_layer abil tekitada? DEFAULT_RESOLVER</a></li>\n",
    "   <li><a href=\"#1.2.3-Märgendajate-importimine-estnltk.taggers-kaudu.-Märgendajate-otserakendamine-(meetod-tag)\">1.2.3 Märgendajate importimine estnltk.taggers kaudu. Märgendajate otserakendamine (meetod tag)</a></li>\n",
    "   <li><a href=\"#1.2.4-Tööahelas-olevate-märgendajate-muutmine-(make_resolver)\">1.2.4 Tööahelas olevate märgendajate muutmine (make_resolver)</a></li>\n",
    "   <li><a href=\"#1.2.5-Märgenduskihi-eemaldamine\">1.2.5 Märgenduskihi eemaldamine</a></li>\n",
    "  </ul><li><a href=\"#1.3-Märgenduskihist-väljavõtete-tegemine.-Itereerimine-üle-märgenduste\">1.3 Märgenduskihist väljavõtete tegemine. Itereerimine üle märgenduste</a></li>\n",
    "   <ul><li><a href=\"#1.3.1-Märgenduse-asukoht-ja-vastav-tekstilõik:-Span-ja-EnvelopingSpan\">1.3.1 Märgenduse asukoht ja vastav tekstilõik: Span ja EnvelopingSpan</a></li>\n",
    "   <li><a href=\"#1.3.2-Märgenduse-infosisu:-Annotation\">1.3.2 Märgenduse infosisu: Annotation</a></li>\n",
    "   <li><a href=\"#1.3.3-Märgendustest-väljavõtete-tegemine\">1.3.3 Märgendustest väljavõtete tegemine</a></li>\n",
    "   <li><a href=\"#1.3.4-Mitmest-märgenduskihist-väljavõtete-tegemine:-kombineeritud-itereerimine\">1.3.4 Mitmest märgenduskihist väljavõtete tegemine: kombineeritud itereerimine</a></li>\n",
    "   <li><a href=\"#1.3.5-Kihi-märgenduste-agregeerimine:-Layer.groupby-ja-Layer.rolling\">1.3.5 Kihi märgenduste agregeerimine: Layer.groupby ja Layer.rolling</a></li>\n",
    "  </ul><li><a href=\"#1.4-Teksti-tükeldamine:-extract_sections-ja-split_by\">1.4 Teksti tükeldamine: extract_sections ja split_by</a></li>\n",
    "  <li><a href=\"#1.5-Viiteid-detailsematele-abimaterjalidele\">1.5 Viiteid detailsematele abimaterjalidele</a></li>\n",
    " </ul><li><a href=\"#2.-Layer-klass-ja-märgendajate-(Tagger-/-Retagger)-loomine\">2. Layer klass ja märgendajate (Tagger / Retagger) loomine</a></li>\n",
    "  <ul><li><a href=\"#2.1-Layer-klass\">2.1 Layer klass</a></li>\n",
    "   <ul><li><a href=\"#2.1.1-Oma-märgenduskihi-loomine:-lihtne-näide\">2.1.1 Oma märgenduskihi loomine: lihtne näide</a></li>\n",
    "   <li><a href=\"#2.1.2-Kihi-metaandmed\">2.1.2 Kihi metaandmed</a></li>\n",
    "   <li><a href=\"#2.1.3-Kihi-loomisel-muudetavad-parameetrid\">2.1.3 Kihi loomisel muudetavad parameetrid</a></li>\n",
    "   <li><a href=\"#2.1.4-Eri-tüüpi-kihtide-loomine-(näited)\">2.1.4 Eri tüüpi kihtide loomine (näited)</a></li>\n",
    "    <ul><li><a href=\"#Lihtkiht-koos-atribuutidega\">Lihtkiht koos atribuutidega</a></li>\n",
    "    <li><a href=\"#Mitmene-kiht\">Mitmene kiht</a></li>\n",
    "    <li><a href=\"#Mitmene-alamkiht\">Mitmene alamkiht</a></li>\n",
    "    <li><a href=\"#Ümbriskiht\">Ümbriskiht</a></li>\n",
    "   </ul><li><a href=\"#2.1.5-Kokkuvõtvalt:-kihi-märgenduste-lisamine,-muutmine-ja-eemaldamine\">2.1.5 Kokkuvõtvalt: kihi märgenduste lisamine, muutmine ja eemaldamine</a></li>\n",
    "   <li><a href=\"#2.1.6-Kihist-koopia-tegemine\">2.1.6 Kihist koopia tegemine</a></li>\n",
    "   <li><a href=\"#2.1.7-Kihtidevaheliste-sõltuvuste-muutmine-(-flatten-ja-rebase-)\">2.1.7 Kihtidevaheliste sõltuvuste muutmine ( flatten ja rebase )</a></li>\n",
    "  </ul><li><a href=\"#2.2-Märgendajad-/-Ümbermärgendajad\">2.2 Märgendajad / Ümbermärgendajad</a></li>\n",
    "   <ul><li><a href=\"#2.2.1-Tagger-(kihi-looja)\">2.2.1 Tagger (kihi looja)</a></li>\n",
    "   <li><a href=\"#2.2.2-Retagger-(kihi-muutja)\">2.2.2 Retagger (kihi muutja)</a></li>\n",
    "</ul></ul></ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Tekst koos märgendustega: `Text` klass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Text` klass on EstNLTK keskne komponent. \n",
    "See sisaldab analüüsitavat teksti, teksti metaandmeid ning analüüsi käigus loodavaid lingvistilisi märgenduskihte.\n",
    "Näide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.')\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atribuudi `text` kaudu saab algse teksti uuesti sõnena kätte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Algne tekst pole muudetav</i></h4> \n",
    "<br>\n",
    "EstNTLK disain järgib põhimõtet, et algne tekst pole muudetav. Seega, kui vaja teha algses tekstis (sõnes) muutuseid, tuleb muudetud sõne jaoks tekitada uus <code>Text</code> objekt.\n",
    "<br>\n",
    "<i>Remark:</i> Kuigi teksti otseselt muuta ei saa, on teatud juhtudel võimalik teha seda kaudselt, märgenduste muutmise läbi. Näiteks saab <i>sõnu normaliseerida</i>: lisada mittekirjakeelsele sõnale kirjakeelseid normaliseeringuid -- nii, et lingvistiline analüüs ei toetu mitte mittekirjakeelsele vormile, vaid normaliseeritud sõnavariantidele. Selle kohta vt lähemalt <a href=\"https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/nlp_pipeline/B_03_segmentation_words.ipynb\">siit</a>.\n",
    "\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Teksti metaandmed\n",
    "\n",
    "Teksti metaandmed on salvestatud sõnastiku kujul ning neile pääseb ligi atribuudi `meta` kaudu. Näide:\n",
    "\n",
    "```python\n",
    "# metaandmete omistamine\n",
    "text.meta = {'author': 'Tundmatu', 'date': 2015}\n",
    "# metaandmete ükshaaval lisamine\n",
    "text.meta['origin'] = 'tsitaadid.ee'\n",
    "text.meta['url'] = 'https://tsitaadid.ee/quote/576/14'\n",
    "```\n",
    "\n",
    "Vaikimisi pole loodaval `Text` objektil metaandmeid -- need tuleb lisada kasutajal. \n",
    "Siiski [korpuse importimise funktsioonid](https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/corpus_processing/importing_text_objects_from_corpora.ipynb) tagastavad tekstid koos metaandmetega (kui korpuses on metaandmed olemas).\n",
    "\n",
    "Kui on kavas andmeid serialiseerida / salvestada Postgres andmebaasi, siis peavad `meta` väärtused kasutama ainult andmetüüpe `str`, `int`, `float` ja `datetime`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Märgenduskihtide lisamine ja eemaldamine\n",
    "\n",
    "_Märgenduskiht_ ( _layer_ ) koondab endas tekstis äramärgitud asukohti ( _span_ ) ning neile lisatud märgendusinfot ( _annotations_ ). \n",
    "Iga kiht fikseerib kindlad atribuudid, millega märgendusinfot edasi antakse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Meetod `tag_layer`\n",
    "\n",
    "Meetodi `tag_layer` abil lisatakse `Text`-ile märgenduskihid, rakendades selleks [EstNLTK tööahelas](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/nlp_pipeline) olevaid märgendajaid. Näide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tag_layer(['tokens', 'words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui märgenduskiht `'tokens'` välja arvata, siis enamik teisi kihte omab **sõltuvusi**: neid ei saa tekitada enne, kui on loodud sõltuvuskihid.\n",
    "Meetod `tag_layer` haldab sõltuvusi automaatselt ja tekitab kõik vajaminevad kihid.\n",
    "Eelmises näites: lisaks `'tokens'` ja `'words'` kihile tekitati ka `'compound_tokens'` kiht, kuna `'words'` kihi loomine nõuab seda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui `tag_layer` kutsutakse välja ilma kihte täpsustava sisendargumendita, siis on vaikeväärtuseks `['morph_analysis', 'sentences']` -- tekivad vastavad kihid koos nende sõltuvustega:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tag_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB! Kui kutsuda `tag_layer` välja tekstil, kus on juba nõutud kihid olemas, siis kihtide uuendamist või ülekirjutamist ei toimu. Kui on soov kihti uuendada (nt teostada morfoloogilist analüüsi teiste sätetega), siis tuleb kõigepealt vana kiht eemaldada (vt allpool) ning alles seejärel märgendada kiht uuesti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Meetod <code>analyse</code></i></h4> \n",
    "<br>\n",
    "EstNTLK-s leidub ka alternatiivne viis <code>Text</code> objektile märgenduste lisamiseks: meetod <code>analyse</code>.\n",
    "Näiteks, <code>text.analyse('segmentation')</code> lisab tekstile sõnestuskihid (<code>'compound_tokens', 'words', 'sentences', 'paragraphs'</code>) ning <code>text.analyse('morphology')</code> lisab sõnestuskihid koos <code>'morph_analysis'</code> kihiga.\n",
    "Meetod <code>analyse</code> proovib tulemust optimiseerida nii, et kustutab märgendamiste lõpus maha kihid <code>'tokens'</code> ja <code>'compound_tokens'</code>, kuna pärast kihi <code>'words'</code> loomist pole seda tavaliselt enam tarvis.\n",
    "Sisuliselt toimub aga meetodi <code>analyse</code> \"kõhus\" meetodi <code>tag_layer</code> rakendamine, seega edasipidi keskendume siin materjalis meetodile <code>tag_layer</code>.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Millised kihte saab `tag_layer` abil tekitada? `DEFAULT_RESOLVER`\n",
    "\n",
    "Milliseid kihte saab üldse meetodi `tag_layer` abil tekitada, sõltub sellest, milliseid märgendajaid on parajasti tööahelas.\n",
    "Vaikimisi rakendatavate märgendajate kohta annab infot `DEFAULT_RESOLVER`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>layer</th>\n",
       "      <th>attributes</th>\n",
       "      <th>depends_on</th>\n",
       "      <th>configuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>TokensTagger</td>\n",
       "      <td>tokens</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "      <td>[apply_punct_postfixes=True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CompoundTokenTagger</td>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>(tokens,)</td>\n",
       "      <td>[custom_abbreviations=(), ignored_words=set(), tag_numbers=True, tag_units=True, tag_email_and_www=True, tag_emoticons=True, tag_xml=True, tag_initials=True, tag_abbreviations=True, tag_case_endings=True, tag_hyphenations=True, use_custom_abbreviations=False, do_not_join_on_strings=('\\n\\n',)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WordTagger</td>\n",
       "      <td>words</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>(tokens, compound_tokens)</td>\n",
       "      <td>[make_ambiguous=True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SentenceTokenizer</td>\n",
       "      <td>sentences</td>\n",
       "      <td>()</td>\n",
       "      <td>(words, compound_tokens)</td>\n",
       "      <td>[base_sentence_tokenizer=&lt;nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x0000027DB8933860&gt;, fix_paragraph_endings=True, fix_compound_tokens=True, fix_numeric=True, fix_parentheses=True, fix_double_quotes=True, fix_inner_title_punct=True, fix_repeated_ending_punct=True, fix_double_quotes_based_on_counts=False, use_emoticons_as_endings=True, record_fix_types=False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>VabamorfTagger</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>(words, sentences, compound_tokens)</td>\n",
       "      <td>[guess=True, propername=True, disambiguate=True, compound=True, phonetic=False, slang_lex=False, postanalysis_tagger=PostMorphAnalysisTagger(('compound_tokens', 'morph_analysis')-&gt;morph_analysis)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>VabamorfEstCatConverter</td>\n",
       "      <td>morph_analysis_est</td>\n",
       "      <td>(normaliseeritud_sõne, algvorm, lõpp, sõnaliik, vormi_nimetus, kliitik)</td>\n",
       "      <td>(morph_analysis,)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ClauseSegmenter</td>\n",
       "      <td>clauses</td>\n",
       "      <td>(clause_type,)</td>\n",
       "      <td>(words, sentences, morph_analysis)</td>\n",
       "      <td>[ignore_missing_commas=False, use_normalized_word_form=True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MorphExtendedTagger</td>\n",
       "      <td>morph_extended</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, punctuation_type, pronoun_type, letter_case, fin, verb_extension_suffix, subcat)</td>\n",
       "      <td>(morph_analysis,)</td>\n",
       "      <td>[punctuation_type_retagger=PunctuationTypeRetagger(('morph_extended',)-&gt;morph_extended), morph_to_syntax_morph_retagger=MorphToSyntaxMorphRetagger(('morph_analysis',)-&gt;morph_extended), pronoun_type_retagger=PronounTypeRetagger(('morph_extended',)-&gt;morph_extended), letter_case_retagger=LetterCaseRetagger(('morph_extended',)-&gt;morph_extended), remove_adposition_analyses_retagger=RemoveAdpositionAnalysesRetagger(('morph_extended',)-&gt;morph_extended), finite_form_retagger=FiniteFormRetagger(('morph_extended',)-&gt;morph_extended), verb_extension_suffix_retagger=VerbExtensionSuffixRetagger(('morph_extended',)-&gt;morph_extended), subcat_retagger=SubcatRetagger(('morph_extended',)-&gt;morph_extended)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ParagraphTokenizer</td>\n",
       "      <td>paragraphs</td>\n",
       "      <td>()</td>\n",
       "      <td>(sentences,)</td>\n",
       "      <td>[regex=\\s*\\n\\n, paragraph_tokenizer=RegexpTokenizer(pattern='\\\\s*\\n\\n', gaps=True, discard_empty=True, flags=&lt;RegexFlag.UNICODE|DOTALL|MULTILINE: 56&gt;)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.resolve_layer_dag.Taggers at 0x27db905ef28>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "from estnltk.resolve_layer_dag import DEFAULT_RESOLVER\n",
    "DEFAULT_RESOLVER.taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tööahelas olevate märgendajate konfiguratsiooni saab vajadusel muuta, sellest allpool detailsemalt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Märgendajate importimine `estnltk.taggers` kaudu. Märgendajate otserakendamine (meetod `tag`)\n",
    "\n",
    "`DEFAULT_RESOLVER` ei sisalda kõiki EstNLTK-s olemasolevaid märgendajaid.\n",
    "Põhjus selles, et osad märgendajad on rakendamiseks spetsiifilistest kontekstides (nt märgenduste võrdlemisel), osad märgendajad nõuavad spetsiifilisi ressursse (nt suuri mudeleid, mis tuleb veebist alla tõmmata) ja osad tegelevad spetsiifiliste tekstianalüüsi probleemidega (nt kuupäevade tuvastamisega meditsiinitekstides).\n",
    "Siiski on enamus märgendajaid kättesaadavad [`estnltk.taggers`](https://github.com/estnltk/estnltk/blob/version_1.6/estnltk/taggers/__init__.py) kaudu, seega saab neid sealt importida ja rakendada vastavalt vajadusele.\n",
    "\n",
    "\n",
    "Näide: kuigi [verbiahelate märgendus](https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/taggers/verb_chain_detector.ipynb) pole tööahelas, saame selle tekitamiseks importida märgendaja `VerbChainDetector`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags main verbs and their extensions (verb chains) in clauses. ( v1.4.1 )\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>VerbChainDetector</td>\n",
       "      <td>verb_chains</td>\n",
       "      <td>('pattern', 'roots', 'word_ids', 'mood', 'polarity', 'tense', 'voice', 'remaining_verbs')</td>\n",
       "      <td>('words', 'sentences', 'morph_analysis', 'clauses')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>add_morph_attr</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>add_analysis_ids_attr</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expand2ndTime</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakOnPunctuation</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>removeSingleAraEi</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "VerbChainDetector(input_layers=('words', 'sentences', 'morph_analysis', 'clauses'), output_layer=verb_chains, output_attributes=('pattern', 'roots', 'word_ids', 'mood', 'polarity', 'tense', 'voice', 'remaining_verbs'), add_morph_attr=False, add_analysis_ids_attr=False, expand2ndTime=False, breakOnPunctuation=False, removeSingleAraEi=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import VerbChainDetector\n",
    "verb_chain_tagger = VerbChainDetector()\n",
    "verb_chain_tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enne imporditud märgendaja rakendamist tuleb hoolitseda selle eest, et sisendtekstil oleks olemas kõik vajaminevad sõltuvuskihid ( _input layers_ ), kuna märgendaja ise automaatselt sõltuvuskihte tekstile ei lisa -- nende puudumisel tuleb veateade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lisame tekstile puuduoleva sõltuvuskihi\n",
    "text.tag_layer('clauses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui sõltuvuskihid on lisatud, kutsume välja märgendaja meetodi `tag`, mis tekitabki märgenduskihi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>verb_chains</td>\n",
       "      <td>pattern, roots, word_ids, mood, polarity, tense, voice, remaining_verbs</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rakendame märgendajat tekstil\n",
    "verb_chain_tagger.tag( text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Täiendavad viited:\n",
    "\n",
    "🔗 Sissejuhatus EstNLTK baastööahelasse: https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/nlp_pipeline/A_01_short_introduction_and_tutorial_for_linguists.ipynb\n",
    "\n",
    "🔗 Tööahela märgendajad: https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/nlp_pipeline\n",
    "\n",
    "🔗 Muud märgendajad: https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Märgendajad (<b><code>Tagger</code></b>) vs ümbermärgendajad</i> (<b><code>Retagger</code></b>)</h4> \n",
    "<br>\n",
    "Osad EstNTLK märgendajad loovad uusi kihte, osad aga kirjutavad ümber (parandavad) olemasolevaid kihte. \n",
    "Kui tegemist on kihti ümberkirjutava märgendajaga (<b><code>Retagger</code></b>), siis tuleb enne selle rakendamist veenduda, et ümberkirjutatav kiht (<code>output_layer</code>) on tekstil juba olemas ning märgendaja rakendamine käib siis meetodi <code>retag( text )</code> kaudu.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Märgenduskihi nime muutmine</i></h4> \n",
    "<br>\n",
    "Kui importida märgendaja <code>estnltk.taggers</code>-i kaudu, siis saab ka muuta loodava märgenduskihi nime. See käib tavaliselt konstruktori argumendi <code>output_layer</code> abil, nt verbiahelate tuvastaja puhul:\n",
    "<pre>\n",
    "from estnltk.taggers import VerbChainDetector\n",
    "verb_chain_tagger = VerbChainDetector(output_layer='my_verb_chains')\n",
    "</pre>\n",
    "Märgenduskihitide nimede muutmine on vajalik tööriistade erinevate konfiguratsioonide testimisel, samuti tööriistade täiustamisel.\n",
    "Nt, kui nimetada märgenduskihid vastavalt tööriista versioonile (a la <code>'verb_chains_v1'</code>, <code>'verb_chains_v2'</code> jne), siis saab neid ka võrrelda omavahel.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Tööahelas olevate märgendajate muutmine (`make_resolver`)\n",
    "\n",
    "EstNLTK baastööahela tekitamine (märgendajate initsialiseerimine ja lisamine ahelasse) käib `make_resolver`-i abil.\n",
    "\n",
    "Kõige lihtsam viis tööahela muutmiseks on luua `make_resolver`-iga baastööahelast koopia ja muuta seda vastavalt oma vajadustele.\n",
    "Näide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.resolve_layer_dag import make_resolver\n",
    "\n",
    "my_resolver = make_resolver()  # Loome baastööahela koopia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seejärel saab meetodi `update` abil uuendada tööahelas olevaid märgendajaid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loome uue morf märgendaja, millel on ühestamine ja oletamised välja lülitatud\n",
    "from estnltk.taggers import VabamorfTagger\n",
    "vabamorf_tagger = VabamorfTagger( disambiguate=False, guess=False, propername=False )\n",
    "\n",
    "# Asendame tööahelas oleva morf märgendaja uuega\n",
    "my_resolver.update( vabamorf_tagger )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muudetud tööahela rakendamiseks tuleb meetodi `tag_layer` väljakutsumisel täpsustada, millist `resolver`-it kasutame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "      <th>_ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Metsawahi</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hobusele</td>\n",
       "      <td>hobusele</td>\n",
       "      <td>hobune</td>\n",
       "      <td>hobune</td>\n",
       "      <td>['hobune']</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>om</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>['uus']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laut</td>\n",
       "      <td>laut</td>\n",
       "      <td>laut</td>\n",
       "      <td>laut</td>\n",
       "      <td>['laut']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ehitet</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech', '_ignore'), spans=SL[Span('Metsawahi', [{'normalized_text': None, 'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None, '_ignore': False}]),\n",
       "Span('hobusele', [{'normalized_text': 'hobusele', 'lemma': 'hobune', 'root': 'hobune', 'root_tokens': ['hobune'], 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'S', '_ignore': False}]),\n",
       "Span('om', [{'normalized_text': None, 'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None, '_ignore': False}]),\n",
       "Span('uus', [{'normalized_text': 'uus', 'lemma': 'uus', 'root': 'uus', 'root_tokens': ['uus'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A', '_ignore': False}]),\n",
       "Span('laut', [{'normalized_text': 'laut', 'lemma': 'laut', 'root': 'laut', 'root_tokens': ['laut'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S', '_ignore': False}]),\n",
       "Span('ehitet', [{'normalized_text': None, 'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None, '_ignore': False}]),\n",
       "Span('.', [{'normalized_text': None, 'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None, '_ignore': False}])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Metsawahi hobusele om uus laut ehitet.')\n",
    "text.tag_layer('morph_analysis', resolver=my_resolver)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eelmises näites: kuna tundmatute sõnade oletamine lülitati morfoloogilisest analüüsist välja (`guess=False`), siis said kõik vana kirjaviisiga sõnad ( _Metsawahi , om , ehitet_ ) tühjad analüüsid (kõik atribuudiväärtused `None`).\n",
    "Seega õnnestus morf analüüsi parameetrite muutmisega tuvastada sõnavormid, mida tänapäeva eesti kirjakeel ei tunne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i><code>make_resolver</code> ja morfoloogilise analüüsi parameetrid</i></h4> \n",
    "<br>\n",
    "Kuna EstNTLK lingvistilise analüüsi keskne komponent on morfoloogiline märgendaja, siis on võimalik <code>make_resolver</code>-i abil ka otse muuta morfoloogilise analüüsi parameetreid <code>disambiguate</code>, <code>guess</code>, <code>propername</code> jm.\n",
    "Selle kohta on detailsemalt juttu juhendmaterjalis <a href=\"https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/nlp_pipeline/A_01_short_introduction_and_tutorial_for_linguists.ipynb\">A_01_short_introduction_and_tutorial_for_linguists.ipynb</a>.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 Märgenduskihi eemaldamine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Märgenduskihi eemaldamiseks on meetod `pop_layer`, mis eemaldab kihi ning tagastab selle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound_tokens', 'sentences', 'tokens', 'words'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eemaldame morfoloogilise märgenduse kihi\n",
    "text.pop_layer('morph_analysis')\n",
    "\n",
    "# Veendume, et kihti enam pole\n",
    "text.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NB!_ Kui `Text` objektil leidub kihte, mis on eemaldatavast kihist sõltuvad, siis eemaldatakse ka need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Märkus vanemate versioonide kohta</i></h4> \n",
    "<br>\n",
    "EstNTLK versioonides 1.6.0b - 1.6.5b käis märgenduskihi eemaldamine käsu <code>del</code> abil, nt:\n",
    "<pre>\n",
    ">> del text.morph_analysis\n",
    "</pre>\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Märgenduskihist väljavõtete tegemine. Itereerimine üle märgenduste\n",
    "\n",
    "EstNLTK-s on kaks viisi `Text` objektilt märgenduskihi küsimiseks: \n",
    "\n",
    "* indeksi (sõne) järgi:\n",
    "`text['tokens']`\n",
    "* atribuudi järgi:\n",
    "`text.tokens`\n",
    "\n",
    "Tulemuste poolest on mõlemad viisid võrdsed: tagastatakse `Layer` objekt, mis on sisuliselt järjend _märgendustest_.\n",
    "Näide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ma</td>\n",
       "      <td>Ma</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>['mina']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>['ei']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>neg</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hooli</td>\n",
       "      <td>hooli</td>\n",
       "      <td>hoolima</td>\n",
       "      <td>hooli</td>\n",
       "      <td>['hooli']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juveelidest</td>\n",
       "      <td>juveelidest</td>\n",
       "      <td>juveel</td>\n",
       "      <td>juveel</td>\n",
       "      <td>['juveel']</td>\n",
       "      <td>dest</td>\n",
       "      <td></td>\n",
       "      <td>pl el</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mulle</td>\n",
       "      <td>Mulle</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>['mina']</td>\n",
       "      <td>lle</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meeldivad</td>\n",
       "      <td>meeldivad</td>\n",
       "      <td>meeldima</td>\n",
       "      <td>meeldi</td>\n",
       "      <td>['meeldi']</td>\n",
       "      <td>vad</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lilled</td>\n",
       "      <td>lilled</td>\n",
       "      <td>lill</td>\n",
       "      <td>lill</td>\n",
       "      <td>['lill']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Ma', [{'normalized_text': 'Ma', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "Span('ei', [{'normalized_text': 'ei', 'lemma': 'ei', 'root': 'ei', 'root_tokens': ['ei'], 'ending': '0', 'clitic': '', 'form': 'neg', 'partofspeech': 'V'}]),\n",
       "Span('hooli', [{'normalized_text': 'hooli', 'lemma': 'hoolima', 'root': 'hooli', 'root_tokens': ['hooli'], 'ending': '0', 'clitic': '', 'form': 'o', 'partofspeech': 'V'}]),\n",
       "Span('juveelidest', [{'normalized_text': 'juveelidest', 'lemma': 'juveel', 'root': 'juveel', 'root_tokens': ['juveel'], 'ending': 'dest', 'clitic': '', 'form': 'pl el', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Mulle', [{'normalized_text': 'Mulle', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': 'lle', 'clitic': '', 'form': 'sg all', 'partofspeech': 'P'}]),\n",
       "Span('meeldivad', [{'normalized_text': 'meeldivad', 'lemma': 'meeldima', 'root': 'meeldi', 'root_tokens': ['meeldi'], 'ending': 'vad', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "Span('lilled', [{'normalized_text': 'lilled', 'lemma': 'lill', 'root': 'lill', 'root_tokens': ['lill'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loome teksti koos sõnade, lausete ja morfoloogilise märgendusega\n",
    "from estnltk import Text\n",
    "text = Text('Ma ei hooli juveelidest. Mulle meeldivad lilled.')\n",
    "text.tag_layer(['words', 'sentences', 'morph_analysis'])\n",
    "\n",
    "# Küsime morfoloogiliste märgenduste kihi\n",
    "text['morph_analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Märgenduse asukoht ja vastav tekstilõik: `Span` ja `EnvelopingSpan`\n",
    "\n",
    "_Märgendus_ koosneb tavajuhul `Span`-ist, mis määrab märgenduse asukoha tekstis, ning `Annotation` objektidest, mis määravad märgenduse sisu ehk millist infot märgendus kannab. Näide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Ma</span></span></td>\n",
       "      <td>Ma</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>[&#x27;mina&#x27;]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('Ma', [{'normalized_text': 'Ma', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Küsime morfoloogilise märgenduse kihist esimese elemendi\n",
    "text['morph_analysis'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui tegemist on **ümbriskihiga** ( _enveloping layer_ ), on märgendus defineeritud mingi teise märgenduskihi elementide järjendina. Sellisel juhul kirjeldab märgenduse asukohta `EnvelopingSpan`.\n",
    "Näiteks, lausemärgendus on defineeritud nende sõnade kaudu, mida lause sisaldab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>EnvelopingSpan</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Ma</span> <span style=\"text-decoration: underline;\">ei</span> <span style=\"text-decoration: underline;\">hooli</span> <span style=\"text-decoration: underline;\">juveelidest</span><span style=\"text-decoration: underline;\">.</span></span></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "EnvelopingSpan(['Ma', 'ei', 'hooli', 'juveelidest', '.'], [{}])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esimese lause sisu (sõnade järjend)\n",
    "text['sentences'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Märgenduse infosisust ehk `Annotation` objektidest tuleb detailsemalt juttu allpool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iga märgendus on varustatud atribuutidega `start`, `end` ja `text`, mis kirjeldavad selle asukohta algses tekstis ning vastavat sõnet.\n",
    "Atribuut `start` sisaldab märgenduse algusindeksit tekstis, atribuut `end` aga lõppindeksit.\n",
    "Atribuut `text` sisaldab tekstilõiku, mida märgendus katab.\n",
    "Näited:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][0].start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][0].end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ma'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Millisel kujul on atribuudis `text` olev tekstilõik, see sõltub kihi tüübist. \n",
    "Kui tegemist on ümbriskihiga ( _enveloping layer_ ), siis peitub atribuudi all sõnede järjend.\n",
    "Näiteks: lausete kiht ümbritseb sõnade kihti ning seega annab lausete atribuut `text` järjendi sõnade kihi `text` väärtustest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ma', 'ei', 'hooli', 'juveelidest', '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esimese lause \"text\"\n",
    "text['sentences'][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui on vaja saada kätte ümbriskihi elementi sõne kujul, siis selle saab kätte `enclosing_text` abil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ma ei hooli juveelidest.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esimesele lausele vastav sõne\n",
    "text['sentences'][0].enclosing_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sarnaselt lausete kihile on ümbriskihid veel nt kihid `'clauses'`, `'compound_tokens'` ja `'paragraphs'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Hoiatus: <code>enclosing_text</code> ja lünkadega märgendused</i></h4> \n",
    "<br>\n",
    "Atribuut <code>enclosing_text</code> annab sisuliselt välja märgenduse indeksite <code>start</code> ja <code>end</code> vahele jääva sõne.\n",
    "See kehtib isegi siis, kui märgenduses on lüngad, st märgendus ei sisalda kõiki ümbritsetava kihi elemente vahemikus <code>start</code> ja <code>end</code>.\n",
    "Seega tuleb olla ettevaatlik <code>enclosing_text</code> kasutamisega nt märgenduskihi <code>'clauses'</code> puhul: kuna sealsed märgendused võivad sisaldada ka lünkasid, ei anna <code>enclosing_text</code> täpselt edasi märgenduse ulatust.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Märgenduste asukohapõhine võrdlemine</i> (<code>estnltk.layer.span_operations</code>) </h4> \n",
    "<br>\n",
    "EstNLTK-s on olemas ka funktsioonid <code>Span</code>-ide süstemaatiliseks asukohapõhiseks võrdlemiseks. Näiteks:\n",
    "<ul> \n",
    " <li> <code>conflict(span_x, span_y)</code> teeb kindlaks, kas <code>span_x</code> ja <code>span_y</code> on positsioonide poolest osaliselt või täielikult ülekattuvad;</li>\n",
    " <li> <code>nested(span_x, span_y)</code> kontrollib, kas emb-kumb märgendustest on teise märgenduse sees;</li>\n",
    " <li> <code>equal(span_x, span_y)</code> kontrollib märgenduste täielikku võrdsust;</li>\n",
    "</ul>\n",
    "    \n",
    "🔗 Võrdlusfunktsioone on veel, kõigi funktsioonide kohta vaata detailsemalt lähtekoodist: <a href=\"https://github.com/estnltk/estnltk/blob/version_1.6/estnltk/layer/span_operations.py\">https://github.com/estnltk/estnltk/blob/version_1.6/estnltk/layer/span_operations.py</a>\n",
    "    \n",
    "NB! Need funktsioonid võrdlevad märgendusi vaid asukohapõhiselt ning ei arvesta <code>Annotation</code> objektides olevat märgendussisu.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Märgenduse infosisu: `Annotation`\n",
    "\n",
    "Märgenduse infosisu -- nt morfoloogilise analüüsi puhul informatsioon lemma, sõnaliigi ja vormitunnuste kohta -- sisaldub `Annotation` objektis.\n",
    "Sisu kättesaamiseks on `Span` ja `EnvelopingSpan` objektidel atribuut `annotations`, mis annab järjendi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Annotation('Ma', {'normalized_text': 'Ma', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['morph_analysis'][0].annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Annotation` objekt on sarnane _sõnastikuga_ : selles on defineeritud märgenduskihi **atribuudid** ja neile vastavad **väärtused**.\n",
    "Seega on võimalik ka atribuudinime järgi väärtust küsida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mina'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Küsime esimesest märgendusest 'lemma' väärtuse\n",
    "annotation = text['morph_analysis'][0].annotations[0]\n",
    "annotation['lemma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui on aga tarvis korraga paljudest märgendusest atribuudiväärtuseid kätte saada, siis muutub eeltoodud küsimisviis kohmakaks. \n",
    "Seepärast sisaldab EstNLTK ka märksa mugavamaid viise märgendustest väljavõtete tegemiseks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Märgendustest väljavõtete tegemine\n",
    "\n",
    "Nagu tavalisest järjendist, saab ka märgenduskihist võtta välja märgendusi **indeksite vahemiku** abil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mulle</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meeldivad</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lilled</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Mulle', [{'normalized_form': None}]),\n",
       "Span('meeldivad', [{'normalized_form': None}]),\n",
       "Span('lilled', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][5:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saab **välja selekteerida** ainult spetsiifilite indeksitega märgendused, nt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>juveelidest</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lilled</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('juveelidest', [{'normalized_form': None}]),\n",
       "Span('lilled', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][[3,7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`lambda` funktsiooni** abil saab võtta välja kindlatele tingimustele vastavad märgendused.\n",
    "\n",
    "Näiteks, võtame välja ainult sõnad, mille pikkus on 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ma</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Ma', [{'normalized_form': None}]),\n",
       "Span('ei', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][ lambda span: len(span.text) == 2 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeksite järgi `Span`-ide väljavõtmist saab kombineerida spetsiifiliste atribuutide väljavõtmisega. \n",
    "Sellisel juhul pole väljavõtte tulemuseks enam märgenduskiht, vaid `AttributeList` (kui valiti üks atribuut) või `AttributeTupleList` (kui valiti mitu atribuuti). \n",
    "Kui kiht on omakorda veel mitmene, on tulemuseks vastavalt kas `AmbiguousAttributeList` või `AmbiguousAttributeTupleList`.\n",
    "\n",
    "Näiteks võime sellist kombineeritud väljavõtmist rakendada morfoloogilise märgenduse peal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeList([['P'], ['V'], ['V'], ['S']], ('partofspeech',))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Võtame välja 4 esimese sõna sõnaliigid\n",
    "text.morph_analysis[0:4, 'partofspeech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeTupleList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mina</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ei</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>hoolima</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>juveel</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeTupleList([[['mina', 'P']], [['ei', 'V']], [['hoolima', 'V']], [['juveel', 'S']]], ('lemma', 'partofspeech'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Võtame välja 4 esimese sõna lemmad ja sõnaliigid\n",
    "text.morph_analysis[0:4, ['lemma','partofspeech']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeksitele leidub ka alternatiivne viis märgendusatribuutide kättesaamiseks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>meeldima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeList([['mina'], ['meeldima'], ['lill'], ['.']], ('lemma',))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sõnade lemmad atribuudi abil\n",
    "text.morph_analysis[5:].lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui kiht omab ülemkihti, siis saab selle atribuudid kätte ka ülemkihi kaudu.\n",
    "Näiteks, sõnade kihi kaudu saab kätte lemmad morf märgenduste kihist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>meeldima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeList([['mina'], ['meeldima'], ['lill'], ['.']], ('lemma',))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sõnade lemmad atribuudi abil, ülemkihi kaudu\n",
    "text.words[5:].lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Märkus mitmesuse kohta</i></h4> \n",
    "<br>\n",
    "Nimetus <code>AmbiguousAttributeList</code> Notebooki väljundis annab märku, on tegemist väljavõttega mitmesest märgenduskihist.\n",
    "Tuletame meelde, et objektide <code>Span</code> ja <code>EnvelopingSpan</code> atribuudi <code>annotations</code> kaudu antakse meile järjend, mitte üksik väärtus. Seega antakse ka atribuutide väärtused tegelikult järjendina.\n",
    "Näiteks:\n",
    "<pre>\n",
    ">> text.words[5].lemma\n",
    "['mina']\n",
    ">> text.words[5].partofspeech\n",
    "['P']\n",
    "</pre>\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4 Mitmest märgenduskihist väljavõtete tegemine: kombineeritud itereerimine\n",
    "\n",
    "Sageli on vaja kombineerida mitmest kihist pärit infot. \n",
    "Näiteks on siin morfoloogilisest märgendusest väljavõtete tegemine ühe lause piires.\n",
    "Kuna lausete kiht ümbritseb sõnade kihti ning morfoloogilise analüüsi kiht toetub sõnade kihile, siis saamegi itereerida üle lausete ja nendes olevate sõnade ning võtta välja iga sõna morfoloogilised märgendused:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lause: Ma ei hooli juveelidest.\n",
      "  Lemma:  mina \t\tsõnaliik: P\n",
      "  Lemma:  ei \t\tsõnaliik: V\n",
      "  Lemma:  hoolima \t\tsõnaliik: V\n",
      "  Lemma:  juveel \t\tsõnaliik: S\n",
      "  Lemma:  . \t\tsõnaliik: Z\n",
      "\n",
      "Lause: Mulle meeldivad lilled.\n",
      "  Lemma:  mina \t\tsõnaliik: P\n",
      "  Lemma:  meeldima \t\tsõnaliik: V\n",
      "  Lemma:  lill \t\tsõnaliik: S\n",
      "  Lemma:  . \t\tsõnaliik: Z\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in text.sentences:\n",
    "    print('Lause:', sentence.enclosing_text)\n",
    "    for word in sentence:\n",
    "        print( '  Lemma: ', word.morph_analysis.lemma[0], \\\n",
    "               '\\t\\tsõnaliik:', word.morph_analysis.partofspeech[0] )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.5 Kihi märgenduste agregeerimine: `Layer.groupby` ja `Layer.rolling`\n",
    "\n",
    "EstNLTK märgenduskihil on olemas meetodid, mis võimaldavad teha agregeerivaid väljavõtteid: märgendusi grupeerida ning jadastada (moodustada _n_-gramme).\n",
    "\n",
    "Meetod `groupby` võimaldab märgendusi **grupeerida atribuutide või ümbriskihtide järgi**.\n",
    "Näiteks, võime morfoloogilisi märgendusi grupeerida sõnaliikide alusel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = text.morph_analysis.groupby(['partofspeech'], return_type='spans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meetodi `count` abil saab kätte sõnaliikide sagedused:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('P',): 2, ('V',): 3, ('S',): 2, ('Z',): 2}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.count "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saab võtta välja kõik mingisse gruppi kuuluvad märgendused. \n",
    "Näiteks, võtame välja kõik verbid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Span('ei', [{'normalized_text': 'ei', 'lemma': 'ei', 'root': 'ei', 'root_tokens': ['ei'], 'ending': '0', 'clitic': '', 'form': 'neg', 'partofspeech': 'V'}]),\n",
       " Span('hooli', [{'normalized_text': 'hooli', 'lemma': 'hoolima', 'root': 'hooli', 'root_tokens': ['hooli'], 'ending': '0', 'clitic': '', 'form': 'o', 'partofspeech': 'V'}]),\n",
       " Span('meeldivad', [{'normalized_text': 'meeldivad', 'lemma': 'meeldima', 'root': 'meeldi', 'root_tokens': ['meeldi'], 'ending': 'vad', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.groups[('V',)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grupeerida on võimalik ka ümbriskihtide ( _enveloping layer_ ) alusel.\n",
    "Näiteks, grupeerime morfoloogilised analüüsid lausete järgi ning väljastame iga lause sõnad ja sõnaliigid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ma', 'ei', 'hooli', 'juveelidest', '.']\n",
      "    Ma \t ['P']\n",
      "    ei \t ['V']\n",
      "    hooli \t ['V']\n",
      "    juveelidest \t ['S']\n",
      "    . \t ['Z']\n",
      "['Mulle', 'meeldivad', 'lilled', '.']\n",
      "    Mulle \t ['P']\n",
      "    meeldivad \t ['V']\n",
      "    lilled \t ['S']\n",
      "    . \t ['Z']\n"
     ]
    }
   ],
   "source": [
    "for sentence_spanlist in text.morph_analysis.groupby( text.sentences ):\n",
    "    print(sentence_spanlist.text)\n",
    "    for morph_span in sentence_spanlist:\n",
    "        print('   ',morph_span.text,'\\t',morph_span.partofspeech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meetod `rolling` võimaldab **märgendusi järjestikku grupeerida**. \n",
    "Näiteks, võime moodustada morfoloogilise märgenduse pealt trigrammid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ma', 'ei', 'hooli'] => ['mina'] ['ei'] ['hoolima']\n",
      "['ei', 'hooli', 'juveelidest'] => ['ei'] ['hoolima'] ['juveel']\n",
      "['hooli', 'juveelidest', '.'] => ['hoolima'] ['juveel'] ['.']\n",
      "['juveelidest', '.', 'Mulle'] => ['juveel'] ['.'] ['mina']\n",
      "['.', 'Mulle', 'meeldivad'] => ['.'] ['mina'] ['meeldima']\n",
      "['Mulle', 'meeldivad', 'lilled'] => ['mina'] ['meeldima'] ['lill']\n",
      "['meeldivad', 'lilled', '.'] => ['meeldima'] ['lill'] ['.']\n"
     ]
    }
   ],
   "source": [
    "for spans in text.morph_analysis.rolling( window=3 ):\n",
    "    print(spans.text, '=>', spans[0].lemma, spans[1].lemma, spans[2].lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meetodi rakendamisel saab teha veel täpsustusi: saab määratleda ümbriskihi, mille raames n-grammid moodustatakse, ning saab määratleda minimaalse n-grammi pikkuse (mis rakendub piirisituatsioonides, nt teksti alguses ja lõpus)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 Meetodite `groupby` ja `rolling` kasutuse kohta detailsemalt: https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/system/layer_operations.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Teksti tükeldamine: `extract_sections` ja `split_by`\n",
    "\n",
    "Funktsiooni `extract_sections` abil on võimalik `Text` objekt **tükeldada indeksite järgi väiksemateks osadeks**.\n",
    "Näide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(text='juveelidest.'), Text(text='Mulle meeldivad')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.layer_operations import extract_sections\n",
    "\n",
    "sections = extract_sections(text, sections=[(12, 24), (25,40)])\n",
    "sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tulemuseks on samuti `Text` objektid ning vaikimisi püütakse säilitada ka kõiki märgenduskihte -- eeldusel, et märgendused mahuvad täielikult eraldatud osade sisse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">juveelidest.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='juveelidest.')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eelmises näites eemaldati tükeldamisel lausete märgendused, kuna kumbki eraldatud osadest ei mahutanud terviklauseid. \n",
    "Parameetri `trim_overlapping=True` kaasaandmisel `extract_sections`-ile jääksid aga laused alles: need lõigatakse lihtsalt lühemaks, vastavalt tükeldamisel etteantud indeksitele."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktsiooni `split_by` abil on võimalik `Text` objekti **tükeldada märgenduskihtide järgi väiksemateks osadeks**.\n",
    "Näiteks, võime teksti jagada lausete järgi väiksemateks `Text` objektideks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(text='Ma ei hooli juveelidest.'), Text(text='Mulle meeldivad lilled.')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.layer_operations import split_by\n",
    "\n",
    "sentence_texts = split_by(text, 'sentences')\n",
    "sentence_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ma ei hooli juveelidest.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ma ei hooli juveelidest.')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erinevalt funktsioonist `extract_sections` jätab `split_by` alles vaid märgenduskihi, mille järgi toimus teksti tükeldamine ning  sellega sõltuvusseoseidpidi ühendatud kihid.\n",
    "Nt, eelmises näites jäi alles `'morph_analysis'` kiht, kuna selle ülemus on `'words'` ning `'sentences'` on omakorda `'words'` kihi ümbriskiht, aga eemaldati kihid `'tokens'` ja `'compound_tokens'`, kuna need pole `'sentences'` kihiga seotud ei ümbriskihi ega ülem/alamkihi seoste kaudu.\n",
    "Vajadusel saab siiski nõuda ka kõigi kihtide allesjätmist, selle kohta vt lähemalt funktsiooni dokumentatsioonist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 `extract_sections` ja `split_by` kasutuse kohta annab detailsemat infot: https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/system/layer_operations.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Hoiatus: lünkadega märgendused ja <code>split_by</code> </i></h4> \n",
    "<br>\n",
    "Kui on tegemist ümbriskihiga (<i>enveloping layer</i>), mis sisaldab lünkasid -- st mittejärjestikkuseid lõikusid märgendusest, siis <code>split_by</code> võtab välja ja moodustab <code>Text</code> objektid ainult terviklikest tekstilõikudest, k.a lünkades olev tekstisisu.\n",
    "Seetõttu ei ole soovitav <code>split_by</code>-i kasutamine nt lünkasid sisaldaval <code>'clauses'</code> kihil, kuna tulemused ei järgi täpselt osalausete piire.\n",
    "Kihi <code>'clauses'</code> puhul on soovitav kasutada kas tavalist itereerimist:\n",
    "<pre>\n",
    "for clause in text.clauses:\n",
    "    for word in clause:\n",
    "        print(word.text)\n",
    "</pre>\n",
    "või siis grupeerimist <code>groupby</code> abil:\n",
    "<pre>\n",
    "for clause_spans in text.words.groupby( text.clauses ):\n",
    "    for word in clause_spans:\n",
    "        print(word.text)\n",
    "</pre>\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Viiteid detailsematele abimaterjalidele\n",
    "\n",
    "* Põhikontseptsioonid:\n",
    "    * Rohkem lugemist: [estnltk_basic_concepts.ipynb](https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/system/estnltk_basic_concepts.ipynb)\n",
    "    * Operatsioonid kihtidel: [layer_operations.ipynb](https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/system/layer_operations.ipynb)\n",
    "\n",
    "\n",
    "* Lingvistilise analüüsi tööahel ja märgendajad:\n",
    "    * Sissejuhatus baastööahelasse: [A_01_short_introduction_and_tutorial_for_linguists.ipynb](https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/nlp_pipeline/A_01_short_introduction_and_tutorial_for_linguists.ipynb)\n",
    "    \n",
    "    * [nlp_pipeline](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/nlp_pipeline) -- tööahela märgendajad: \n",
    "       _teksti sõnestamine/lausestamine/segmenteerimine_ , _morfoloogiline analüüs ja ühestamine_ , _õigekirjakontroll_ , _süntaksi eeltöötlus_ ;\n",
    "    \n",
    "    * [syntax](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/syntax) -- süntaktiline analüüs;\n",
    "    \n",
    "    * [hfst](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/hfst) -- HFST morfoloogiline analüüs;\n",
    "    \n",
    "    * [finite_grammar](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/finite_grammar) -- reeglipõhise faktieralduse tööriistad / grammatikad ;\n",
    "\n",
    "    * [taggers](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/taggers) -- lisamärgendajad. _infoeralduse komponendid: nimeüksuste tuvastaja , ajaväljendite tuvastaja , verbiahelate tuvastaja ; tehisnärvivõrkudel põhinev morfoloogiline ühestamine_ ; _süsteemisisesed märgendajad_ ;\n",
    "    \n",
    "    * [miscellaneous](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/miscellaneous) -- morfoloogiline süntees ja silbitamine;\n",
    "    \n",
    "    * [wordnet](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/wordnet) -- Eesti wordnet'i liides;\n",
    "\n",
    "\n",
    "* Töö korpustega ( [corpus_processing](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/corpus_processing) ):\n",
    "\n",
    "    * Eelsõnestatud teksti sisselugemine: [restoring_pretokenized_text.ipynb](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/corpus_processing/restoring_pretokenized_text.ipynb) \n",
    "\n",
    "    * Andmete import suurkorpustest (Koondkorpus, etTenTen, ühendkorpus): [importing_text_objects_from_corpora.ipynb](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/corpus_processing/importing_text_objects_from_corpora.ipynb) \n",
    "\n",
    "\n",
    "* Erinevate formaatide lugemine/kirjutamine/teisendamine ( [converters](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/converters) ):\n",
    "\n",
    "    * CONLL formaadist importimine [converters/conll_importer.ipynb](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/converters/conll_importer.ipynb)\n",
    "    * _dict_ importimine/eksportimine [converters/dict_exporter_importer.ipynb](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/converters/dict_exporter_importer.ipynb) \n",
    "    * JSON importimine/eksportimine [converters/json_exporter_importer.ipynb](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/converters/json_exporter_importer.ipynb) \n",
    "    * TCF importimine/eksportimine [converters/TCF_exporter_importer.ipynb](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/converters/TCF_exporter_importer.ipynb) \n",
    "    * Eksportimine TextA-sse [converters/texta_exporter.ipynb](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/converters/texta_exporter.ipynb) \n",
    "\n",
    "\n",
    "* Märgenduste visualiseerimine:\n",
    "    * https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/visualisation\n",
    "\n",
    "\n",
    "* Postgres andmebaasiliidese kasutamine ( [storage](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/storage) ):\n",
    "    * _Text_ objektide salvestamine andmebaasi: [storage/storing_text_objects_in_postgres.ipynb](https://github.com/estnltk/estnltk/tree/version_1.6/tutorials/storage/storing_text_objects_in_postgres.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. `Layer` klass ja märgendajate (`Tagger` / `Retagger`) loomine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 `Layer` klass\n",
    "\n",
    "### 2.1.1 Oma märgenduskihi loomine: lihtne näide\n",
    "\n",
    "`Layer` klass sisaldab teksti märgenduskihti ja selle metaandmeid. Kasutaja poolt vaadatuna on tegemist märgenduste järjendiga. _Märgendus_ koosneb asukohamäärangust (`Span` või `EnvelopingSpan`) ning märgendusinfost (`Annotation` objekt(id)).\n",
    "\n",
    "Näide lihtkihi loomisest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>my_words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Tere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maailm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='my_words', attributes=(), spans=SL[Span('Tere', [{}]),\n",
       "Span('maailm', [{}])])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text, Layer\n",
    "\n",
    "text = Text('Tere, maailm!')\n",
    "\n",
    "# Loome uue lihtkihi ja seome selle tekstiga\n",
    "layer = Layer('my_words', text_object=text)\n",
    "\n",
    "# Lisame kihile märgendusi (asukohtade järgi)\n",
    "layer.add_annotation( (0, 4) )\n",
    "layer.add_annotation( (6, 12) )\n",
    "\n",
    "layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näha, saime tulemuseks ainult märgendatud tekstilõigud: mingeid atribuudiväärtustusi meie märgendused ei sisalda.\n",
    "Tehniliselt: kuna me kihi loomisel ei määranud kihile atribuute, siis meetod `add_annotation` tekitas märgendustesse ilma infosisuta `Annotation` objektid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eelmises näites tekitasime ühesuunalise seose `Layer`-i ja `Text`-i vahele: `Layer` teab oma `Text` objekti, aga `Text` veel kihti ei tunne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tere, maailm!</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tere, maailm!')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seega on meil tegemist eraldatud kihiga ( _detached layer_ ).\n",
    "Selleks, et **siduda kiht `Text` objektiga**, tuleb kasutada meetodit `add_layer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tere, maailm!</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>my_words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tere, maailm!')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Riputame kihi teksti külge\n",
    "text.add_layer( layer )\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Kihi metaandmed\n",
    "\n",
    "Sarnaselt `Text` objektile on ka märgenduskihi metaandmed sõnastikuna kättesaadavad ja muudetavad atribuudi `meta` kaudu. Näide:\n",
    "\n",
    "```python\n",
    "# metaandmete omistamine\n",
    "layer.meta['date_created'] = '2019-12-18'\n",
    "layer.meta['avg_word_len'] = 0.0\n",
    "```\n",
    "\n",
    "`meta` atribuudi võtmete alla talletatavad väärtused peaksid kasutama ainult andmetüüpe `str`, `int`, `float` ja `datetime`, kuna muude andmetüüpide puhul ei ole garanteeritud andmete serialiseeritavus / andmebaasi salvestatavus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Kihi loomisel muudetavad parameetrid\n",
    "\n",
    "`Layer` objekti loomisel saab täpsustada järgmised parameetrid:\n",
    "\n",
    " * `name` -- kihi nimi (sõne). Välistatud kihinimed: `text` ning kihinimed, mida kasutavad EstNLTK tööahela märgendajad (vt täpsemalt: _1.2.2. Millised kihte saab tag_layer abil tekitada? DEFAULT\\_RESOLVER_ );\n",
    " \n",
    " \n",
    " * `attributes` -- järjend kihi märgenduste atribuutide nimedega. Need atribuudid saavad olema kõigil kihi `Annotation` objektidel.  Välistatud atribuudinimed: `start`, `end` ja `text`;\n",
    "\n",
    "\n",
    " * `text_object` -- kihiga seotud `Text` objekt. Kui `Text` objekt on sidumata, pole võimalik uurida märgenduste tekstisisu (`text` ja `enclosing_text`);\n",
    " \n",
    " \n",
    " * `parent` -- ülemkihi nimi (sõne). Kui ülemkiht puudub (ning pole tegu ümbriskihiga), lisatakse märgendused otse algtekstile, aga ülemkihi olemasolul saab märgendusi lisada ainult ülemkihi märgenduste peale (st samadele asukohtadele);\n",
    " \n",
    " \n",
    " * `enveloping` -- ümbritsetava kihi nimi (sõne). Kui ümbritsetav kiht on määratud, siis tuleb märgenduste lisamisel täpsustada järjend ümbritsetava kihi märgenduste asukohtadest, mida antud kiht katab;\n",
    " \n",
    " \n",
    " * `ambiguous` -- kas kiht on mitmene (tõeväärtus). Kui kiht on mitmene, siis saab ühe asukohaga siduda mitu `Annotation` objekti;\n",
    " \n",
    " \n",
    " * `default_values` -- märgenduse atribuutide väikeväärtused (sõnastik).\n",
    " \n",
    " \n",
    " Allpool toome detailsemad näited eri tüüpi kihtide loomisest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Eri tüüpi kihtide loomine (näited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lihtkiht koos atribuutidega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words_with_translations</td>\n",
       "      <td>fin, eng</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>fin</th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Tere</td>\n",
       "      <td>Hei</td>\n",
       "      <td>Hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maailm</td>\n",
       "      <td>maailma</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words_with_translations', attributes=('fin', 'eng'), spans=SL[Span('Tere', [{'fin': 'Hei', 'eng': 'Hello'}]),\n",
       "Span('maailm', [{'fin': 'maailma', 'eng': 'World'}])])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Näidistekst\n",
    "text = Text('Tere, maailm!')\n",
    "\n",
    "# Loome kahe atribuudiga kihi\n",
    "layer = Layer(name='words_with_translations',\n",
    "              text_object=text,\n",
    "              attributes=['fin', 'eng'] )\n",
    "\n",
    "# Lisame kihile märgendusi:\n",
    "# 1) atribuutide määramine parameetritena\n",
    "layer.add_annotation( (0, 4), fin='Hei', eng='Hello' )\n",
    "# 2) atribuutide etteandmine sõnastikuna\n",
    "layer.add_annotation( (6, 12), **{'fin':'maailma', 'eng':'World'} )\n",
    "\n",
    "# Seome kihi teksti külge\n",
    "text.add_layer( layer )\n",
    "\n",
    "text.words_with_translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mitmene kiht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words_with_translations</td>\n",
       "      <td>translated_text, lang</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Tere</td>\n",
       "      <td>Hei</td>\n",
       "      <td>fin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Hello</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maailm</td>\n",
       "      <td>maailma</td>\n",
       "      <td>fin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>World</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words_with_translations', attributes=('translated_text', 'lang'), spans=SL[Span('Tere', [{'translated_text': 'Hei', 'lang': 'fin'}, {'translated_text': 'Hello', 'lang': 'eng'}]),\n",
       "Span('maailm', [{'translated_text': 'maailma', 'lang': 'fin'}, {'translated_text': 'World', 'lang': 'eng'}])])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Näidistekst\n",
    "text = Text('Tere, maailm!')\n",
    "\n",
    "# Loome kahe atribuudiga kihi\n",
    "layer = Layer(name='words_with_translations',\n",
    "              text_object=text,\n",
    "              attributes=['translated_text', 'lang'],\n",
    "              ambiguous=True)\n",
    "\n",
    "# Lisame kihile märgendusi (asukoht + atribuudiväärtustused)\n",
    "# 1) atribuutide määramine parameetritena\n",
    "layer.add_annotation( (0, 4), translated_text='Hei', lang='fin' )\n",
    "layer.add_annotation( (0, 4), translated_text='Hello', lang='eng' )\n",
    "# 2) atribuutide etteandmine sõnastikuna\n",
    "layer.add_annotation( (6, 12), **{'translated_text':'maailma', 'lang':'fin'} )\n",
    "layer.add_annotation( (6, 12), **{'translated_text':'World', 'lang':'eng'} )\n",
    "\n",
    "# Seome kihi teksti külge\n",
    "text.add_layer( layer )\n",
    "\n",
    "text.words_with_translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mitmene alamkiht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words_with_translations</td>\n",
       "      <td>translated_text, lang</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Tere</td>\n",
       "      <td>Hei</td>\n",
       "      <td>fin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Hello</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maailm</td>\n",
       "      <td>maailma</td>\n",
       "      <td>fin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>World</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words_with_translations', attributes=('translated_text', 'lang'), spans=SL[Span('Tere', [{'translated_text': 'Hei', 'lang': 'fin'}, {'translated_text': 'Hello', 'lang': 'eng'}]),\n",
       "Span('maailm', [{'translated_text': 'maailma', 'lang': 'fin'}, {'translated_text': 'World', 'lang': 'eng'}])])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text, Layer, Annotation, Span\n",
    "\n",
    "# Näidistekst koos sõnade märgenduskihiga\n",
    "text = Text('Tere, maailm!').tag_layer('words')\n",
    "\n",
    "# Loome kahe atribuudiga sõnade kihi alamkihi\n",
    "layer = Layer(name='words_with_translations',\n",
    "              text_object=text,\n",
    "              attributes=['translated_text', 'lang'],\n",
    "              parent='words',\n",
    "              ambiguous=True)\n",
    "\n",
    "for word in text.words:\n",
    "    # Loome uue Span-i, mis baseerub ülemkihi Span-il\n",
    "    new_span = Span(base_span=word.base_span, layer=layer)\n",
    "    if (new_span.start, new_span.end) == (0, 4):\n",
    "        # 1) märgenduse atribuutide määramine parameetritena\n",
    "        new_span.add_annotation( Annotation(new_span, translated_text='Hei', lang='fin') )\n",
    "        new_span.add_annotation( Annotation(new_span, translated_text='Hello', lang='eng') )\n",
    "        layer.add_span(new_span)\n",
    "    if (new_span.start, new_span.end) == (6, 12):\n",
    "        # 2) märgenduse atribuutide etteandmine sõnastikuna\n",
    "        new_span.add_annotation( Annotation(new_span, **{'translated_text':'maailma', 'lang':'fin'} ) )\n",
    "        new_span.add_annotation( Annotation(new_span, **{'translated_text':'World', 'lang':'eng'} ) )\n",
    "        layer.add_span(new_span)\n",
    "\n",
    "# Seome kihi teksti külge\n",
    "text.add_layer( layer )\n",
    "\n",
    "text['words_with_translations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ümbriskiht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>phrase_translations</td>\n",
       "      <td>translated_text, lang</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Tere', ',', 'maailm', '!']</td>\n",
       "      <td>Hello, World!</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Kuidas', 'läheb', '?']</td>\n",
       "      <td>How are you?</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='phrase_translations', attributes=('translated_text', 'lang'), spans=SL[EnvelopingSpan(['Tere', ',', 'maailm', '!'], [{'translated_text': 'Hello, World!', 'lang': 'eng'}]),\n",
       "EnvelopingSpan(['Kuidas', 'läheb', '?'], [{'translated_text': 'How are you?', 'lang': 'eng'}])])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import EnvelopingBaseSpan\n",
    "from estnltk import Text, Layer, Annotation, EnvelopingSpan\n",
    "\n",
    "# Näidistekst koos sõnade märgenduskihiga\n",
    "text = Text('Tere, maailm! Kuidas läheb?').tag_layer('words')\n",
    "\n",
    "# Loome kahe atribuudiga sõnade kihti ümbritseva kihi\n",
    "layer = Layer(name='phrase_translations',\n",
    "              text_object=text,\n",
    "              attributes=['translated_text', 'lang'],\n",
    "              enveloping='words')\n",
    "\n",
    "# Lisame esimest 4 sõna katva märgenduse\n",
    "base_span_1 = EnvelopingBaseSpan([s.base_span for s in text.words[0:4]])\n",
    "new_span = EnvelopingSpan(base_span_1, layer=layer)\n",
    "new_span.add_annotation( Annotation(new_span, translated_text='Hello, World!', lang='eng') )\n",
    "layer.add_span(new_span)\n",
    "\n",
    "# Lisame viimast 3 sõna katva märgenduse\n",
    "base_span_2 = EnvelopingBaseSpan([text.words[4].base_span, text.words[5].base_span, text.words[6].base_span] )\n",
    "new_span = EnvelopingSpan(base_span_2, layer=layer)\n",
    "new_span.add_annotation( Annotation(new_span, translated_text='How are you?', lang='eng') )\n",
    "layer.add_span(new_span)\n",
    "\n",
    "# Seome kihi teksti külge\n",
    "text.add_layer( layer )\n",
    "\n",
    "text.phrase_translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 Märgenduskihtide loomise kohta vt veel:\n",
    "    https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/system/low_level_layer_operations.ipynb\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Kokkuvõtvalt: kihi märgenduste lisamine, muutmine ja eemaldamine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Span` ja `EnvelopingSpan` võimaldavad:\n",
    "\n",
    "  1. muuta märgendusi: `span.annotations[i][attr_j] = ...`;\n",
    "  2. lisada uusi märgendusi: `span.add_annotation( annotation_object )`;\n",
    "  3. eemaldada märgendused: `span.clear_annotations()`;\n",
    "  \n",
    "`Layer` võimaldab:\n",
    "\n",
    "  1. lisada märgendusi: \n",
    "     * `layer.add_annotation( base_span, **attributes )`\n",
    "     * `layer.add_span( span: Span )`\n",
    "  2. kustutada märgendusi: \n",
    "     * `layer.remove_span( span: Span )` (objekti järgi)\n",
    "     * `del layer[i]` (indeksi järgi) \n",
    "  3. muuta märgendusi:\n",
    "     * `layer[i].annotations[j][attr_k] = ...` (indeksite järgi) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Disainipõhimõte: märgendusi tekitavad ja muudavad märgendajad</i></h4> \n",
    "<br>\n",
    "EstNLTK järgib disainipõhimõtet, et märgenduskihtide loomine ja muutmine toimub märgendajate sees. \n",
    "See tagab, et loodavad kihid on valiidse struktuuriga, kuna märgendajate sees toimub kihtide järelkontroll.\n",
    "Märgendajate loomise ja kasutamise kohta vt detailsemalt ptk 2.2.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Märgenduste lisamise, muutmise ja eemaldamise reeglid</i></h4> \n",
    "<br>\n",
    "<ul>\n",
    "    <li>Kihil ei tohi kunagi olla mitut täpselt ühesuguse asukohaga märgendust (aga osaliselt kattuva asukohaga märgendused on lubatud);</li>\n",
    "    <li>Iga kihil olev <code>Span</code> / <code>EnvelopingSpan</code> peab sisaldama vähemalt üht <code>Annotation</code> objekti (kuigi see võib olla ka tühi, nagu sõnestusmärgenduse puhul);</li>\n",
    "    <li>Mistahes liiki kihile ei saa lisada mitut täpselt samade atribuudiväärtustega <code>Annotation</code>-it -- duplikaatide puhul jäetakse alles vaid üks <code>Annotation</code>;</li>\n",
    "</ul>\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Operatsioonid märgenduste filtreerimiseks</i></h4> \n",
    "<br>\n",
    "Moodul <code>estnltk.layer_operations</code> sisaldab funktsioone, mis võimaldavad märgendusi filtreerida:\n",
    "<ul>\n",
    "    <li><code>keep_annotations</code> -- jätab alles vaid märgendused, mis sisaldavad etteantud atribuudiväärtustusi;</li>\n",
    "    <li><code>drop_annotations</code> -- eemaldab märgendused, mis sisaldavad etteantud atribuudiväärtustusi;</li>\n",
    "    <li><code>apply_filter</code> -- rakendab kihil kasutaja poolt loodud filtreerimisfunktsiooni -- jätab alles vaid funktsiooni rahuldavad märgendused;</li>\n",
    "</ul>\n",
    "<br>\n",
    "🔗 Funktsioonide kasutusjuhised ja näited leiab siit: <a href=\"https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/system/layer_operations.ipynb\">layer_operations.ipynb</a> (<i>Filter annotations</i>).\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.6 Kihist koopia tegemine\n",
    "\n",
    "Meetodi `copy` abil saab teha kihist koopia. Näide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words_in_eng</td>\n",
       "      <td>translated_text, lang</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Tere</td>\n",
       "      <td>Hello</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words_in_eng', attributes=('translated_text', 'lang'), spans=SL[Span('Tere', [{'translated_text': 'Hello', 'lang': 'eng'}])])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Näidistekst\n",
    "text = Text('Tere!')\n",
    "\n",
    "# Loome kahe atribuudiga kihi\n",
    "layer = Layer(name='words_in_fin',\n",
    "              text_object=text,\n",
    "              attributes=['translated_text', 'lang'] )\n",
    "\n",
    "layer.add_annotation( (0, 4), **{'translated_text':'Hei', 'lang':'fin'} )\n",
    "\n",
    "# Teeme kihist koopia\n",
    "layer_2 = layer.copy()\n",
    "layer_2.name = 'words_in_eng'\n",
    "\n",
    "# Muudame koopia märgendusi\n",
    "layer_2[0].annotations[0]['translated_text'] = 'Hello'\n",
    "layer_2[0].annotations[0]['lang'] = 'eng'\n",
    "\n",
    "# Seome kihi teksti külge\n",
    "text.add_layer( layer )\n",
    "text.add_layer( layer_2 )\n",
    "\n",
    "text.words_in_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.7 Kihtidevaheliste sõltuvuste muutmine ( `flatten` ja `rebase` )\n",
    "\n",
    "Funktsioon `flatten` nullib kihi sõltuvused ja **teeb kihist lihtkihi** (ehk siis kihi, mis pole ümbriskiht, alamkiht ega ka mitmene kiht):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>flat_sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Tere, maailm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kuidas läheb?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='flat_sentences', attributes=(), spans=SL[Span('Tere, maailm!', [{}]),\n",
       "Span('Kuidas läheb?', [{}])])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.layer_operations import flatten\n",
    "\n",
    "# Lisame lausete märgenduskihi\n",
    "text = Text('Tere, maailm! Kuidas läheb?').tag_layer('sentences')\n",
    "# Tekitame lausete kihist lihtkihi\n",
    "flat_sentences = flatten(text['sentences'], 'flat_sentences')\n",
    "# Lisame tekstile lausete lihtkihi\n",
    "text.add_layer( flat_sentences )\n",
    "text.flat_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kuna algne lausete kiht on sõltuv sõnade kihist, siis sõnade kihi eemaldamisel kaob ka lausete kiht.\n",
    "Lausete kihist tehtud lihtkiht jääb aga alles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tere, maailm! Kuidas läheb?</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>flat_sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tere, maailm! Kuidas läheb?')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.pop_layer( 'words' )\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktsioon `rebase` **tõstab alamkihi sõltuvuse ümber** ühelt ülemkihilt teisele. Näiteks, kiht `'morph_analysis'` sõltub `'words'` kihist ja kiht `'gt_morph_analysis'` omakorda `'morph_analysis'` kihist, seega saame kihi `'gt_morph_analysis'` sõltuvuse tõsta ümber `'words'` kihile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tere, maailm! Kuidas läheb?</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gt_morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tere, maailm! Kuidas läheb?')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.layer_operations import rebase\n",
    "from estnltk.taggers import GTMorphConverter\n",
    "\n",
    "# Lisame tekstile morfoloogilise märgenduse ja osalaused\n",
    "text = Text('Tere, maailm! Kuidas läheb?').tag_layer(['morph_analysis', 'clauses'])\n",
    "# Lisame GT kategooriatega morf märgenduse\n",
    "GTMorphConverter().tag(text)\n",
    "\n",
    "# Teeme 'gt_morph_analysis' sõltuvuse ümber 'words' kihi peale\n",
    "rebase(text, 'gt_morph_analysis', 'words')\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misjärel saab ülemkihi `'morph_analysis'` üldse eemaldada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tere, maailm! Kuidas läheb?</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gt_morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tere, maailm! Kuidas läheb?')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.pop_layer( 'morph_analysis' )\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 Rohkem infot/näiteid `flatten` ja `rebase` kohta leiab siit: https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/system/layer_operations.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Märgendajad / Ümbermärgendajad\n",
    "\n",
    "### 2.2.1 `Tagger` (kihi looja)\n",
    "\n",
    "Märgendaja abil luuakse uusi kihte. \n",
    "Märgendaja tegemine samm-haaval:\n",
    "  1. Loo `estnltk.taggers.Tagger` klassi alamklass;\n",
    "  2. Lisa kõik märgendaja konfiguratsiooni parameetrid klassimuutujasse `conf_param` (muutuja tüüp `Sequence[str]`);  \n",
    "        Ainult selles loendis olevaid parameetreid tohib märgendaja alla salvestada. Kui parameetri nime ees on alakriips (`_`), siis loetakse see sisemiseks parameetriks ning märgendaja konfiguratsiooni kuvamisel seda ei näidata;\n",
    "  3. Lisa väljundkihi nimi klassimuutujasse `output_layer`(tüüp `str`);\n",
    "  4. Lisa kõik väljundkihi atribuutide nimed muutujasse `output_attributes`(tüüp `Sequence[str]`);\n",
    "  5. Lisa kõik kihid, mida on vaja väljundkihi loomiseks, muutujasse `input_layers`(tüüp `Sequence[str]`);\n",
    "  6. Loo konstruktor `__init__`, kus pannakse lõplikult paika parameetrite `conf_param`, `output_layer`, `output_attributes`,  `input_layers` ning teiste konfiguratsiooniparameetrite väärtused.\n",
    "       Märgendaja konfiguratsioon peaks olema täielikult määratud konstruktoris, väljaspool konstruktorit selle muutmist toimuda ei tohiks. (Kui kasutajal on vaja muuta konfiguratsiooni, peaks ta tekitada uue märgendaja uue konfiguratsiooniga);\n",
    "  7. Loo meetod `_make_layer(self, raw_text: str, layers: Mapping[str, Layer], status: dict=None) -> Layer`, milles tekitatakse (vastavalt märgendaja konfiguratsioonile) uus `Layer` objekt ning tagastatakse see;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lihtsustatud näide: loome märgendaja, mis märgendab toiduretseptides koguseid (nt _1 tl_ , _200 g_ , _2 dl_ ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text, Layer\n",
    "from estnltk.taggers import Tagger\n",
    "\n",
    "class QuantityTokensTagger(Tagger):\n",
    "    \"\"\"Tags tokens that make up quantity expressions.\"\"\" \n",
    "    conf_param = ['quantity_lemmas']\n",
    "    \n",
    "    def __init__(self, # output_layer name can be changed:\n",
    "                       output_layer='quantity_tokens',\n",
    "                       # input layer name can be changed:\n",
    "                       input_morph_analysis_layer='morph_analysis',\n",
    "                       # quantity lemmas can be changed:\n",
    "                       quantity_lemmas=['tk', 'tl', 'dl', 'kg', 'g']):\n",
    "        # Set input/output layers\n",
    "        self.input_layers = [input_morph_analysis_layer]\n",
    "        self.output_layer = output_layer\n",
    "        self.output_attributes = ['token_type']\n",
    "        # Set other configuration parameters\n",
    "        self.quantity_lemmas = set(quantity_lemmas)\n",
    "    \n",
    "    def _make_layer(self, text, layers, status):\n",
    "        # Create new layer based on the configuration\n",
    "        layer = Layer(name=self.output_layer, attributes=self.output_attributes, text_object=text)\n",
    "        for span in layers[ self.input_layers[0] ]: # Iterate over 'morph_analysis' (first input layer)\n",
    "            for annotation in span.annotations:\n",
    "                if annotation['lemma'] in self.quantity_lemmas:\n",
    "                    # Mark units\n",
    "                    layer.add_annotation(span.base_span, token_type='UNIT')\n",
    "                    break\n",
    "                if annotation['lemma'].replace('.','',1).isdigit():\n",
    "                    # Mark numbers\n",
    "                    layer.add_annotation(span.base_span, token_type='NUMBER')\n",
    "                    break\n",
    "        # Return created layer\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testime märgendajat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags tokens that make up quantity expressions.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>QuantityTokensTagger</td>\n",
       "      <td>quantity_tokens</td>\n",
       "      <td>('token_type',)</td>\n",
       "      <td>('morph_analysis',)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>quantity_lemmas</th>\n",
       "      <td>{'tl', 'dl', 'kg', 'g', 'tk'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "QuantityTokensTagger(input_layers=('morph_analysis',), output_layer=quantity_tokens, output_attributes=('token_type',), quantity_lemmas={'tl', 'dl', 'kg', 'g', 'tk'})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "quantities_tagger = QuantityTokensTagger()\n",
    "quantities_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var elements = document.getElementsByClassName(\"overlapping-span\")\n",
       "for (let i = 0; i < elements.length; i++){\n",
       "    elements.item(i).addEventListener(\"click\",function() {show_conflicting_spans(elements.item(i));})}\n",
       "\n",
       "function show_conflicting_spans(span_element) {\n",
       "    let spantable = document.createElement('div')\n",
       "    spantable.classList.add('tables')\n",
       "\n",
       "    // Prepare the contents of the span table\n",
       "    data = span_element.getAttribute(\"span_info\")\n",
       "    data = data.split(\",\")\n",
       "    var spancontent = '<table>'\n",
       "    for (let row of data) {\n",
       "        spancontent+='<tr><td>'\n",
       "        spancontent+=row\n",
       "        spancontent+='</td></tr>'\n",
       "    }\n",
       "    spancontent += '</table>'\n",
       "    spantable.innerHTML = spancontent\n",
       "    span_element.parentElement.appendChild(spantable)\n",
       "\n",
       "    // Increase the size of the cell so the tables would fit\n",
       "    spantable.parentElement.style.height = Math.max(Number(spantable.parentElement.style.height.substring(0,spantable.parentElement.style.height.length-2)),span_element.offsetTop+90)+ 'px'\n",
       "    // Position the table directly below the corresponding text\n",
       "    spantable.style.left = span_element.getBoundingClientRect().left-spantable.parentElement.parentElement.getBoundingClientRect().left + 'px'\n",
       "    spantable.style.top = span_element.getBoundingClientRect().top-spantable.parentElement.parentElement.getBoundingClientRect().top+20+ 'px'\n",
       "\n",
       "    // Remove the table when clicked on again\n",
       "    spantable.addEventListener('click', function () {\n",
       "        let element = this.parentElement\n",
       "        element.removeChild(this)\n",
       "    })\n",
       "}\n",
       "</script><style>\n",
       ".span {\n",
       "    background-color: yellow;\n",
       "}\n",
       "\n",
       ".overlapping-span {\n",
       "    background-color: red;\n",
       "}\n",
       "\n",
       ".spanline {\n",
       "    background-color: blue;\n",
       "    position: relative;\n",
       "    height: 3px;\n",
       "    margin-left: 0px;\n",
       "}\n",
       "\n",
       ".tables {\n",
       "    position: absolute;\n",
       "    width: fit-content;\n",
       "    width: -moz-fit-content;\n",
       "    border: 1px solid black;\n",
       "}\n",
       "\n",
       ".maintext{0} {\n",
       "    position: relative;\n",
       "}\n",
       "\n",
       ".tables tbody tr:nth-child(even) {\n",
       "    background-color: lightgray;\n",
       "}\n",
       "\n",
       ".tables tbody tr:nth-child(odd) {\n",
       "    background-color: beige;\n",
       "}\n",
       "\n",
       ".tables tbody tr:hover {\n",
       "    background-color: ivory;\n",
       "}\n",
       "</style><br><span style=background:yellow; \">200</span> <span style=background:yellow; \">g</span> tumedat 70% šokolaadi (Fairtrade)<br><span style=background:yellow; \">200</span> <span style=background:yellow; \">g</span> võid<br><span style=background:yellow; \">100</span> <span style=background:yellow; \">g</span> hakitud kreeka pähkleid<br><span style=background:yellow; \">0.5</span> <span style=background:yellow; \">tl</span> soola<br><span style=background:yellow; \">0.5</span> <span style=background:yellow; \">tl</span> vanilliekstrakti<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>quantity_tokens</td>\n",
       "      <td>token_type</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>token_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>g</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>g</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>g</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tl</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tl</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='quantity_tokens', attributes=('token_type',), spans=SL[Span('200', [{'token_type': 'NUMBER'}]),\n",
       "Span('g', [{'token_type': 'UNIT'}]),\n",
       "Span('200', [{'token_type': 'NUMBER'}]),\n",
       "Span('g', [{'token_type': 'UNIT'}]),\n",
       "Span('100', [{'token_type': 'NUMBER'}]),\n",
       "Span('g', [{'token_type': 'UNIT'}]),\n",
       "Span('0.5', [{'token_type': 'NUMBER'}]),\n",
       "Span('tl', [{'token_type': 'UNIT'}]),\n",
       "Span('0.5', [{'token_type': 'NUMBER'}]),\n",
       "Span('tl', [{'token_type': 'UNIT'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loome näidisteksti koos vajaminevate sisendkihtidega\n",
    "text = Text('''\n",
    "200 g tumedat 70% šokolaadi (Fairtrade)\n",
    "200 g võid\n",
    "100 g hakitud kreeka pähkleid\n",
    "0.5 tl soola\n",
    "0.5 tl vanilliekstrakti\n",
    "''')\n",
    "text.tag_layer('morph_analysis')\n",
    "\n",
    "# Rakendame märgendajat\n",
    "quantities_tagger.tag( text )\n",
    "\n",
    "# Visualiseerime tulemused\n",
    "text.quantity_tokens.display()\n",
    "display( text.quantity_tokens )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Rohkem detaile</i></h4> \n",
    "<br>\n",
    "<ul>\n",
    "    <li>Sisuliselt on <code>Tagger</code>-il kolm meetodit, mis haldavad kihi loomist:\n",
    "        <ul>\n",
    "            <li><code>tag(text: Text, status: dict)</code> -- luuakse ja lisatakse kiht etteantud <code>Text</code> objektile. Lõppkasutajale mõeldud meetod, mida märgendajate arendajad reeglina muuta / üle kirjutada ei tohiks;</li>\n",
    "            <li><code>make_layer(text: Text, layers: MutableMapping[str, Layer], status: dict)</code> -- luuakse ja tagastatakse loodud kiht ilma seda <code>Text</code> objektiga sidumata. Vajalik Postgres andmebaasiliidesele: meetodi abil saab tekitada eraldatud kihi (<i>detached layer</i>), mis on andmebaasis <code>Text</code> objektist eraldi. Märgendajate arendajad reeglina seda meetodit muuta / üle kirjutada ei tohiks;</li>\n",
    "            <li><code>_make_layer(text: Text, layers: MutableMapping[str, Layer] = None, status: dict = None)</code> -- märgenduskihi loomine ja tagastamine: implementatsioon. Märgendajate arendajad peaksid muutma just seda meetodit;</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><i>Kihi loomise staatus</i>: kihi loomise meetoditele saab parameetriks anda sõnastiku <code>status</code>, kuhu märgendaja võib sõnumeid salvestada (nt selle kohta, kas kihi loomine õnnestus);</li>\n",
    "    <li><i>Valideerimine</i>: meetodis <code>make_layer(...)</code> toimub märgendaja sisendi- ja väljundi valideerimine. Enne kihi loomist kontrollitakse, et on olemas kõik vajalikud sisendkihid (<code>input_layers</code>) ning pärast kihi loomist kontrollitakse, et väljundkiht (<code>output_layer</code>) on olemas ning et kõigil märgendustel on väljundatribuudid (<code>output_attributes</code>);</li>\n",
    "    <li><i>Muudetavad kihtide nimed</i>: on soovitatav, et sisend- ja väljundkihtide nimed oleksid märgendajas muudetavad: 1) konstruktori parameetrite abil peaks olema võimalik muuta <code>input_layers</code> ja <code>output_layer</code> väärtuseid; 2) meetodis <code>_make_layer(...)</code> peaks eksplitsiitsete kihinimede asemel kasutada kihinimede muutujaid  <code>input_layers</code> ja <code>output_layer</code>. Kui kihinimed on muudetavad, on võimalik võrrelda märgendaja eri versioonide väljundeid;</li>\n",
    "</ul>\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 Märgendaja loomise kohta vt veel: https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/taggers/base_tagger.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 `Retagger` (kihi muutja)\n",
    "\n",
    "Ümbermärgendaja muudab / parandab olemasolevat kihti.\n",
    "Ümbermärgendaja on `Retagger` klassi alamklass, millel on määratud atribuudid:\n",
    "\n",
    "   * `conf_param` -- list legaalsetest parameetrinimedest (sõnede list);\n",
    "   * `output_layer` -- muudetava kihi nimi (sõne);\n",
    "   * `output_attributes` -- list muudetava kihi atribuutide nimedega (sõnede list);\n",
    "   * `input_layers` -- list muutmiseks vajalikest sisendkihtidest (sõnede list); NB! peaks sisaldama ka kihti `output_layer`;\n",
    "\n",
    "ning implementeeritud meetodid:\n",
    "\n",
    "   * `__init__` -- konstruktor, kus pannakse lõplikult paika parameetrite `conf_param`, `output_layer`, `output_attributes`,  `input_layers` ning teiste legaalsete parameetrite väärtused, mis moodustavad konfiguratsiooni;\n",
    "   * `_change_layer(...)` -- meetod, mis muudab (vastavalt märgendaja konfiguratsioonile) kihti `output_layer` ning ei tagasta midagi;\n",
    "\n",
    "`Retagger`-i ülesehitus on suuresti analoogne `Tagger`-i omale. \n",
    "Ka `Retagger`-is haldavad kihi muutmist 3 meetodit: `_change_layer(...)` (kihi muutmise loogika implementatsioon), `change_layer(...)` (andmebaasiliidese jaoks vajalik meetod) ning  `retag(...)` (lõppkasutajale mõeldud meetod)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lihtsustatud näide ümbermärgendajast: sõnade normaliseerija, mis lisab spetsiifilistele vana kirjakeele sõnadele ( nt _om_ ja _ehitet_ ) normaliseeritud vormid ning märgib iga sõna puhul ära, kas see sai normaliseeritud või mitte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text, Layer, Annotation\n",
    "from estnltk.taggers import Retagger\n",
    "\n",
    "class DummyWordNormalizer( Retagger ):\n",
    "    \"\"\"A dummy word normalizer that can normalize only some specific words of Old Estonian.\"\"\" \n",
    "    conf_param = ['lexicon']\n",
    "    \n",
    "    def __init__(self, # Name of the layer can be changed:\n",
    "                       output_layer = 'words'):\n",
    "        # Set input/output layers\n",
    "        self.input_layers = [output_layer]\n",
    "        self.output_layer = output_layer\n",
    "        self.output_attributes = ['normalized_form', 'is_normalized']\n",
    "        # Set other configuration parameters\n",
    "        self.lexicon = {'metsawahi':'metsavahi', 'ehitet':'ehitatud', 'om':'on'}\n",
    "    \n",
    "    def _change_layer(self, text, layers, status):\n",
    "        # Get changeble layer\n",
    "        changeble_layer = layers[self.output_layer]\n",
    "        # Add new attribute to the layer\n",
    "        changeble_layer.attributes += (self.output_attributes[-1], )\n",
    "        # Iterate over words and add new normalizations\n",
    "        for span in changeble_layer:\n",
    "            # Get current normalized forms of the word\n",
    "            current_norm_forms = [a['normalized_form'] for a in span.annotations]\n",
    "            if current_norm_forms == [None]:\n",
    "                current_norm_forms = [span.text]\n",
    "            # Try to replace current normalized forms with forms from the lexicon\n",
    "            new_forms = []\n",
    "            change_status = []\n",
    "            for cur_form in current_norm_forms:\n",
    "                if cur_form.lower() in self.lexicon:\n",
    "                    new_forms.append(self.lexicon[cur_form.lower()])\n",
    "                    change_status.append(True)\n",
    "                else:\n",
    "                    new_forms.append(cur_form)\n",
    "                    change_status.append(False)\n",
    "            # Clear existing annotations and add new ones that have 1 extra attribute\n",
    "            span.clear_annotations()\n",
    "            for form_id, new_form in enumerate( new_forms ):\n",
    "                span.add_annotation( Annotation(span, normalized_form=new_form, \n",
    "                                                      is_normalized=change_status[form_id]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testime ümbermärgendajat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>DummyWordNormalizer(Retagger)</h4>\n",
       "A dummy word normalizer that can normalize only some specific words of Old Estonian.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>DummyWordNormalizer</td>\n",
       "      <td>words</td>\n",
       "      <td>('normalized_form', 'is_normalized')</td>\n",
       "      <td>('words',)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lexicon</th>\n",
       "      <td>{'metsawahi': 'metsavahi', 'ehitet': 'ehitatud', 'om': 'on'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DummyWordNormalizer(lexicon={'metsawahi': 'metsavahi', 'ehitet': 'ehitatud', 'om': 'on'})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "word_normalizer = DummyWordNormalizer()\n",
    "word_normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Metsawahi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hobusele</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>om</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uus</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laut</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ehitet</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Metsawahi', [{'normalized_form': None}]),\n",
       "Span('hobusele', [{'normalized_form': None}]),\n",
       "Span('om', [{'normalized_form': None}]),\n",
       "Span('uus', [{'normalized_form': None}]),\n",
       "Span('laut', [{'normalized_form': None}]),\n",
       "Span('ehitet', [{'normalized_form': None}]),\n",
       "Span('.', [{'normalized_form': None}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form, is_normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "      <th>is_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Metsawahi</td>\n",
       "      <td>metsavahi</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hobusele</td>\n",
       "      <td>hobusele</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>om</td>\n",
       "      <td>on</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laut</td>\n",
       "      <td>laut</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ehitet</td>\n",
       "      <td>ehitatud</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form', 'is_normalized'), spans=SL[Span('Metsawahi', [{'normalized_form': 'metsavahi', 'is_normalized': True}]),\n",
       "Span('hobusele', [{'normalized_form': 'hobusele', 'is_normalized': False}]),\n",
       "Span('om', [{'normalized_form': 'on', 'is_normalized': True}]),\n",
       "Span('uus', [{'normalized_form': 'uus', 'is_normalized': False}]),\n",
       "Span('laut', [{'normalized_form': 'laut', 'is_normalized': False}]),\n",
       "Span('ehitet', [{'normalized_form': 'ehitatud', 'is_normalized': True}]),\n",
       "Span('.', [{'normalized_form': '.', 'is_normalized': False}])])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loome näidisteksti koos vajaminevate sisendkihtidega\n",
    "from estnltk import Text\n",
    "text = Text('Metsawahi hobusele om uus laut ehitet.')\n",
    "text.tag_layer('words')\n",
    "# Kuvame vana kihi\n",
    "display(text.words)\n",
    "\n",
    "# Rakendame ümbermärgendajat\n",
    "word_normalizer.retag(text)\n",
    "\n",
    "# Kuvame muudetud kihi\n",
    "text.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 Ümbermärgendaja loomise kohta vt veel: https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/taggers/base_tagger.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
