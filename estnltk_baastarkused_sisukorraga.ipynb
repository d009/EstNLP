{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EstNLTK 1.7 baastarkused\n",
    "\n",
    "Käesoleva abimaterjal annab ülevaate EstNLTK 1.7 programeerimisliidesest.\n",
    "Eelkõige on see mõeldud lisalugemiseks neile, kel on tarvis EstNLTK andmestruktuuridest ja üldisest toimeloogikast rohkem teada saada ning ise luua märgenduskihte ja märgendajaid.\n",
    "Konkreetseid lingvistilise analüüsi (nt morfoloogia või süntaksi) tööriistu siin ei süvitsi käsitleta -- nende kohta leiab detailset infot praktikumimaterjalidest ning <a href=\"#1.5-Viiteid-detailsematele-abimaterjalidele-(ingl-k)\">EstNLTK inglisekeelsetest juhendmaterjalidest</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sisukord**\n",
    "<!-- MAKE TOC HERE -->\n",
    "\n",
    "<ul> <li><a href=\"#EstNLTK-1.7-baastarkused\">EstNLTK 1.7 baastarkused</a></li>\n",
    " <li><a href=\"#1.-Tekst-koos-märgendustega:-Text-klass\">1. Tekst koos märgendustega: Text klass</a></li>\n",
    "  <ul><li><a href=\"#1.1-Teksti-metaandmed\">1.1 Teksti metaandmed</a></li>\n",
    "  <li><a href=\"#1.2-Märgenduskihtide-lisamine-ja-eemaldamine\">1.2 Märgenduskihtide lisamine ja eemaldamine</a></li>\n",
    "   <ul><li><a href=\"#1.2.1-Meetod-tag_layer\">1.2.1 Meetod tag_layer</a></li>\n",
    "   <li><a href=\"#1.2.2-Millised-kihte-saab-tag_layer-abil-tekitada?-DEFAULT_RESOLVER\">1.2.2 Millised kihte saab tag_layer abil tekitada? DEFAULT_RESOLVER</a></li>\n",
    "   <li><a href=\"#1.2.3-Märgendajate-importimine-estnltk.taggers-kaudu.-Märgendajate-otserakendamine-(meetod-tag)\">1.2.3 Märgendajate importimine estnltk.taggers kaudu. Märgendajate otserakendamine (meetod tag)</a></li>\n",
    "   <li><a href=\"#1.2.4-Tööahelas-olevate-märgendajate-muutmine-(make_resolver)\">1.2.4 Tööahelas olevate märgendajate muutmine (make_resolver)</a></li>\n",
    "   <li><a href=\"#1.2.5-Märgenduskihi-eemaldamine\">1.2.5 Märgenduskihi eemaldamine</a></li>\n",
    "  </ul><li><a href=\"#1.3-Märgenduskihist-väljavõtete-tegemine.-Itereerimine-üle-märgenduste\">1.3 Märgenduskihist väljavõtete tegemine. Itereerimine üle märgenduste</a></li>\n",
    "   <ul><li><a href=\"#1.3.1-Märgenduse-asukoht-ja-vastav-tekstilõik:-Span-ja-EnvelopingSpan\">1.3.1 Märgenduse asukoht ja vastav tekstilõik: Span ja EnvelopingSpan</a></li>\n",
    "   <li><a href=\"#1.3.2-Märgenduse-infosisu:-Annotation\">1.3.2 Märgenduse infosisu: Annotation</a></li>\n",
    "   <li><a href=\"#1.3.3-Märgendustest-väljavõtete-tegemine\">1.3.3 Märgendustest väljavõtete tegemine</a></li>\n",
    "   <li><a href=\"#1.3.4-Mitmest-märgenduskihist-väljavõtete-tegemine:-kombineeritud-itereerimine\">1.3.4 Mitmest märgenduskihist väljavõtete tegemine: kombineeritud itereerimine</a></li>\n",
    "   <li><a href=\"#1.3.5-Kihi-märgenduste-agregeerimine:-Layer.groupby-ja-Layer.rolling\">1.3.5 Kihi märgenduste agregeerimine: Layer.groupby ja Layer.rolling</a></li>\n",
    "  </ul><li><a href=\"#1.4-Teksti-tükeldamine:-extract_sections-ja-split_by\">1.4 Teksti tükeldamine: extract_sections ja split_by</a></li>\n",
    "  <li><a href=\"#1.5-Viiteid-detailsematele-abimaterjalidele-(ingl-k)\">1.5 Viiteid detailsematele abimaterjalidele (ingl k)</a></li>\n",
    " </ul><li><a href=\"#2.-Layer-klass-ja-märgendajate-(Tagger-/-Retagger)-loomine\">2. Layer klass ja märgendajate (Tagger / Retagger) loomine</a></li>\n",
    "  <ul><li><a href=\"#2.1-Layer-klass\">2.1 Layer klass</a></li>\n",
    "   <ul><li><a href=\"#2.1.1-Oma-märgenduskihi-loomine:-lihtne-näide\">2.1.1 Oma märgenduskihi loomine: lihtne näide</a></li>\n",
    "   <li><a href=\"#2.1.2-Kihi-metaandmed\">2.1.2 Kihi metaandmed</a></li>\n",
    "   <li><a href=\"#2.1.3-Kihi-loomisel-muudetavad-parameetrid\">2.1.3 Kihi loomisel muudetavad parameetrid</a></li>\n",
    "   <li><a href=\"#2.1.4-Eri-tüüpi-kihtide-loomine-(näited)\">2.1.4 Eri tüüpi kihtide loomine (näited)</a></li>\n",
    "    <ul><li><a href=\"#Lihtkiht-koos-atribuutidega\">Lihtkiht koos atribuutidega</a></li>\n",
    "    <li><a href=\"#Mitmene-kiht\">Mitmene kiht</a></li>\n",
    "    <li><a href=\"#Mitmene-alamkiht\">Mitmene alamkiht</a></li>\n",
    "    <li><a href=\"#Ümbriskiht\">Ümbriskiht</a></li>\n",
    "   </ul><li><a href=\"#2.1.5-Kokkuvõtvalt:-kihi-märgenduste-lisamine,-muutmine-ja-eemaldamine\">2.1.5 Kokkuvõtvalt: kihi märgenduste lisamine, muutmine ja eemaldamine</a></li>\n",
    "   <li><a href=\"#2.1.6-Kihtidevaheliste-sõltuvuste-muutmine-(-flatten-ja-rebase-)\">2.1.6 Kihtidevaheliste sõltuvuste muutmine ( flatten ja rebase )</a></li>\n",
    "  </ul><li><a href=\"#2.2-Märgendajad-/-Ümbermärgendajad\">2.2 Märgendajad / Ümbermärgendajad</a></li>\n",
    "   <ul><li><a href=\"#2.2.1-Tagger-(kihi-looja)\">2.2.1 Tagger (kihi looja)</a></li>\n",
    "   <li><a href=\"#2.2.2-Retagger-(kihi-muutja)\">2.2.2 Retagger (kihi muutja)</a></li>\n",
    "</ul></ul></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Tekst koos märgendustega: `Text` klass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Text` klass on EstNLTK keskne komponent. \n",
    "See sisaldab analüüsitavat teksti, teksti metaandmeid ning analüüsi käigus loodavaid lingvistilisi märgenduskihte.\n",
    "Näide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.')\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atribuudi `text` kaudu saab algse teksti uuesti sõnena kätte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<h4><i>Algne tekst pole muudetav</i></h4> \n",
    "<br>\n",
    "EstNTLK disain järgib põhimõtet, et algne tekst pole muudetav. Seega, kui vaja teha algses tekstis (sõnes) muutuseid, tuleb muudetud sõne jaoks tekitada uus <code>Text</code> objekt.\n",
    "<br>\n",
    "<i>Remark:</i> Kuigi teksti otseselt muuta ei saa, on teatud juhtudel võimalik teha seda kaudselt, märgenduste muutmise läbi. Näiteks saab <i>sõnu normaliseerida</i>: lisada mittekirjakeelsele sõnale kirjakeelseid normaliseeringuid -- nii, et lingvistiline analüüs ei toetu mitte mittekirjakeelsele vormile, vaid normaliseeritud sõnavariantidele. Selle kohta vt lähemalt <a href=\"https://github.com/estnltk/estnltk/blob/main/tutorials/nlp_pipeline/A_text_segmentation/03_words.ipynb\">siit</a>.\n",
    "\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Teksti metaandmed\n",
    "\n",
    "Teksti metaandmed on salvestatud sõnastiku kujul ning neile pääseb ligi atribuudi `meta` kaudu. Näide:\n",
    "\n",
    "```python\n",
    "# metaandmete omistamine\n",
    "text.meta = {'author': 'Tundmatu', 'date': 2015}\n",
    "# metaandmete ükshaaval lisamine\n",
    "text.meta['origin'] = 'tsitaadid.ee'\n",
    "text.meta['url'] = 'https://tsitaadid.ee/quote/576/14'\n",
    "```\n",
    "\n",
    "Vaikimisi pole loodaval `Text` objektil metaandmeid -- need tuleb lisada kasutajal. \n",
    "Siiski [korpuse importimise funktsioonid](https://github.com/estnltk/estnltk/blob/main/tutorials/corpus_processing/importing_text_objects_from_corpora.ipynb) tagastavad tekstid koos metaandmetega (kui korpuses on metaandmed olemas).\n",
    "\n",
    "Kui on kavas andmeid serialiseerida / salvestada Postgres andmebaasi, siis peavad `meta` väärtused kasutama ainult andmetüüpe `str`, `int`, `float` ja `datetime`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Märgenduskihtide lisamine ja eemaldamine\n",
    "\n",
    "_Märgenduskiht_ ( _layer_ ) koondab endas tekstis äramärgitud asukohti ( _span_ ) ning neile lisatud märgendusinfot ( _annotations_ ). \n",
    "Iga kiht fikseerib kindlad atribuudid, millega märgendusinfot edasi antakse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Meetod `tag_layer`\n",
    "\n",
    "Meetodi `tag_layer` abil lisatakse `Text`-ile märgenduskihid, rakendades selleks EstNLTK tööahelas olevaid märgendajaid. Näide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tag_layer(['tokens', 'words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui märgenduskiht `'tokens'` välja arvata, siis enamik teisi kihte omab **sõltuvusi**: neid ei saa tekitada enne, kui on loodud sõltuvuskihid.\n",
    "Meetod `tag_layer` haldab sõltuvusi automaatselt ja tekitab kõik vajaminevad kihid.\n",
    "Eelmises näites: lisaks `'tokens'` ja `'words'` kihile tekitati ka `'compound_tokens'` kiht, kuna `'words'` kihi loomine nõuab seda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui `tag_layer` kutsutakse välja ilma kihte täpsustava sisendargumendita, siis on vaikeväärtuseks `['morph_analysis', 'sentences']` -- tekivad vastavad kihid koos nende sõltuvustega:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tag_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB! Kui kutsuda `tag_layer` välja tekstil, kus on juba nõutud kihid olemas, siis kihtide uuendamist või ülekirjutamist ei toimu. Kui on soov kihti uuendada (nt teostada morfoloogilist analüüsi teiste sätetega), siis tuleb kõigepealt vana kiht eemaldada (vt allpool) ning alles seejärel märgendada kiht uuesti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mida `tag_layer` tagastab? Tagastatavaks väärtuseks on see sama `Text` objekt, millel `tag_layer` välja kutsuti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = text.tag_layer()\n",
    "assert text == new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Millised kihte saab `tag_layer` abil tekitada? `DEFAULT_RESOLVER`\n",
    "\n",
    "Meetod `tag_layer` oskab kihte luua tänu klassile `LayerResolver`, mis kirjeldab võimalikke kihte, kihtide sõltuvusi ja nende loomiseks kasutatavaid märgendajaid. \n",
    "Ehk teisiti öeldes – nn tööahelat.\n",
    "\n",
    "Vaikimisi kasutatavale tööahelale pääseb ligi `Text` klassi atribuudi `layer_resolver` abil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>LayerResolver</h4>\n",
       "<br>Default layers: <b>morph_analysis, sentences</b>\n",
       "</br><h4>TaggersRegistry</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer</th>\n",
       "      <th>depends_on</th>\n",
       "      <th>tagger_name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "      <td>TokensTagger</td>\n",
       "      <td>Preprocessing for word segmentation: segments text into tokens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>[tokens]</td>\n",
       "      <td>CompoundTokenTagger</td>\n",
       "      <td>Preprocessing for word segmentation: joins tokens into compound tokens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>[tokens, compound_tokens]</td>\n",
       "      <td>WordTagger</td>\n",
       "      <td>Segments text into words.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td>[compound_tokens, words]</td>\n",
       "      <td>SentenceTokenizer</td>\n",
       "      <td>Segments text into sentences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paragraphs</td>\n",
       "      <td>[sentences]</td>\n",
       "      <td>ParagraphTokenizer</td>\n",
       "      <td>Segments text into paragraphs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>[compound_tokens, words, sentences]</td>\n",
       "      <td>VabamorfTagger</td>\n",
       "      <td>Tags morphological analysis with Vabamorf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>[words, sentences, morph_analysis]</td>\n",
       "      <td>ClauseSegmenter</td>\n",
       "      <td>Segments sentences into clauses. (requires Java)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis_est</td>\n",
       "      <td>[morph_analysis]</td>\n",
       "      <td>VabamorfEstCatConverter</td>\n",
       "      <td>Translates category names of Vabamorf's morphological analyses into Estonian (for educational purposes).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_extended</td>\n",
       "      <td>[morph_analysis]</td>\n",
       "      <td>MorphExtendedTagger</td>\n",
       "      <td>Converts Vabamorf's morphological analyses to syntax preprocessing (CG3) format.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gt_morph_analysis</td>\n",
       "      <td>[words, sentences, morph_analysis, clauses]</td>\n",
       "      <td>GTMorphConverter</td>\n",
       "      <td>Converts Vabamorf's morphological analyses to giellatekno's (GT) format.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>[morph_analysis, words, sentences]</td>\n",
       "      <td>NerTagger</td>\n",
       "      <td>Detects named entities: person, location and organization names.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>timexes</td>\n",
       "      <td>[]</td>\n",
       "      <td>TimexTagger</td>\n",
       "      <td>Detects temporal expressions and normalizes to corresponding dates, times, durations and recurrences. (requires Java)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>address_parts</td>\n",
       "      <td>[words]</td>\n",
       "      <td>AddressPartTagger</td>\n",
       "      <td>Preprocessing for address detection.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addresses</td>\n",
       "      <td>[address_parts]</td>\n",
       "      <td>AddressGrammarTagger</td>\n",
       "      <td>Detects addresses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maltparser_conll_morph</td>\n",
       "      <td>[sentences, morph_analysis]</td>\n",
       "      <td>ConllMorphTagger</td>\n",
       "      <td>Preprocessing for MaltParser based syntactic analysis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maltparser_syntax</td>\n",
       "      <td>[words, sentences, maltparser_conll_morph]</td>\n",
       "      <td>MaltParserTagger</td>\n",
       "      <td>Tags dependency syntactic analysis with MaltParser. (requires Java)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>verb_chains</td>\n",
       "      <td>[words, sentences, morph_analysis, clauses]</td>\n",
       "      <td>VerbChainDetector</td>\n",
       "      <td>Tags main verbs and their extensions (verb chains) in clauses. (experimental)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>np_chunks</td>\n",
       "      <td>[words, sentences, morph_analysis, maltparser_syntax]</td>\n",
       "      <td>NounPhraseChunker</td>\n",
       "      <td>Tags noun phrase chunks in sentences. (experimental)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "LayerResolver(default_layers=['morph_analysis', 'sentences'])\n",
       "TaggersRegistry\n",
       "layer               depends_on                    tagger_name          description                   \n",
       "=====               ==========                    ===========          ===========                   \n",
       "\n",
       "tokens              []                            TokensTagger         Preprocessing for word        \n",
       "                                                                       segmentation: segments text   \n",
       "                                                                       into tokens.                  \n",
       "\n",
       "compound_tokens     ['tokens']                    CompoundTokenTagger  Preprocessing for word        \n",
       "                                                                       segmentation: joins tokens    \n",
       "                                                                       into compound tokens.         \n",
       "\n",
       "words               ['tokens',                    WordTagger           Segments text into words.     \n",
       "                    'compound_tokens']                                                               \n",
       "\n",
       "sentences           ['compound_tokens', 'words']  SentenceTokenizer    Segments text into            \n",
       "                                                                       sentences.                    \n",
       "\n",
       "paragraphs          ['sentences']                 ParagraphTokenizer   Segments text into            \n",
       "                                                                       paragraphs.                   \n",
       "\n",
       "morph_analysis      ['compound_tokens', 'words',  VabamorfTagger       Tags morphological analysis   \n",
       "                    'sentences']                                       with Vabamorf.                \n",
       "\n",
       "clauses             ['words', 'sentences',        ClauseSegmenter      Segments sentences into       \n",
       "                    'morph_analysis']                                  clauses. (requires Java)      \n",
       "\n",
       "morph_analysis_est  ['morph_analysis']            VabamorfEstCatConve  Translates category names of  \n",
       "                                                  rter                 Vabamorf's morphological      \n",
       "                                                                       analyses into Estonian (for   \n",
       "                                                                       educational purposes).        \n",
       "\n",
       "morph_extended      ['morph_analysis']            MorphExtendedTagger  Converts Vabamorf's           \n",
       "                                                                       morphological analyses to     \n",
       "                                                                       syntax preprocessing (CG3)    \n",
       "                                                                       format.                       \n",
       "\n",
       "gt_morph_analysis   ['words', 'sentences',        GTMorphConverter     Converts Vabamorf's           \n",
       "                    'morph_analysis', 'clauses']                       morphological analyses to     \n",
       "                                                                       giellatekno's (GT) format.    \n",
       "\n",
       "ner                 ['morph_analysis', 'words',   NerTagger            Detects named entities:       \n",
       "                    'sentences']                                       person, location and          \n",
       "                                                                       organization names.           \n",
       "\n",
       "timexes             []                            TimexTagger          Detects temporal expressions  \n",
       "                                                                       and normalizes to             \n",
       "                                                                       corresponding dates, times,   \n",
       "                                                                       durations and recurrences.    \n",
       "                                                                       (requires Java)               \n",
       "\n",
       "address_parts       ['words']                     AddressPartTagger    Preprocessing for address     \n",
       "                                                                       detection.                    \n",
       "\n",
       "addresses           ['address_parts']             AddressGrammarTagge  Detects addresses.            \n",
       "                                                  r                                                  \n",
       "\n",
       "maltparser_conll_m  ['sentences',                 ConllMorphTagger     Preprocessing for MaltParser  \n",
       "orph                'morph_analysis']                                  based syntactic analysis.     \n",
       "\n",
       "maltparser_syntax   ['words', 'sentences',        MaltParserTagger     Tags dependency syntactic     \n",
       "                    'maltparser_conll_morph']                          analysis with MaltParser.     \n",
       "                                                                       (requires Java)               \n",
       "\n",
       "verb_chains         ['words', 'sentences',        VerbChainDetector    Tags main verbs and their     \n",
       "                    'morph_analysis', 'clauses']                       extensions (verb chains) in   \n",
       "                                                                       clauses. (experimental)       \n",
       "\n",
       "np_chunks           ['words', 'sentences',        NounPhraseChunker    Tags noun phrase chunks in    \n",
       "                    'morph_analysis',                                  sentences. (experimental)     \n",
       "                    'maltparser_syntax']                                                             \n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.layer_resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaikimisi näitab `LayerResolver`-i tabel kihtide vahelisi sõltuvusi. \n",
    "Tabeli esituskuju saab ümber lülitada nii, et see näitab kihtide atribuute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>LayerResolver</h4>\n",
       "<br>Default layers: <b>morph_analysis, sentences</b>\n",
       "</br><h4>TaggersRegistry</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer</th>\n",
       "      <th>attributes</th>\n",
       "      <th>tagger_name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td>()</td>\n",
       "      <td>TokensTagger</td>\n",
       "      <td>Preprocessing for word segmentation: segments text into tokens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>CompoundTokenTagger</td>\n",
       "      <td>Preprocessing for word segmentation: joins tokens into compound tokens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>WordTagger</td>\n",
       "      <td>Segments text into words.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td>()</td>\n",
       "      <td>SentenceTokenizer</td>\n",
       "      <td>Segments text into sentences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paragraphs</td>\n",
       "      <td>()</td>\n",
       "      <td>ParagraphTokenizer</td>\n",
       "      <td>Segments text into paragraphs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>VabamorfTagger</td>\n",
       "      <td>Tags morphological analysis with Vabamorf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>(clause_type,)</td>\n",
       "      <td>ClauseSegmenter</td>\n",
       "      <td>Segments sentences into clauses. (requires Java)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis_est</td>\n",
       "      <td>(normaliseeritud_sõne, algvorm, lõpp, sõnaliik, vormi_nimetus, kliitik)</td>\n",
       "      <td>VabamorfEstCatConverter</td>\n",
       "      <td>Translates category names of Vabamorf's morphological analyses into Estonian (for educational purposes).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_extended</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, punctuation_type, pronoun_type, letter_case, fin, verb_extension_suffix, subcat)</td>\n",
       "      <td>MorphExtendedTagger</td>\n",
       "      <td>Converts Vabamorf's morphological analyses to syntax preprocessing (CG3) format.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gt_morph_analysis</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>GTMorphConverter</td>\n",
       "      <td>Converts Vabamorf's morphological analyses to giellatekno's (GT) format.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>(nertag,)</td>\n",
       "      <td>NerTagger</td>\n",
       "      <td>Detects named entities: person, location and organization names.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>timexes</td>\n",
       "      <td>(tid, type, value, temporal_function, anchor_time_id, mod, quant, freq, begin_point, end_point, part_of_interval)</td>\n",
       "      <td>TimexTagger</td>\n",
       "      <td>Detects temporal expressions and normalizes to corresponding dates, times, durations and recurrences. (requires Java)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>address_parts</td>\n",
       "      <td>(grammar_symbol, type)</td>\n",
       "      <td>AddressPartTagger</td>\n",
       "      <td>Preprocessing for address detection.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addresses</td>\n",
       "      <td>(grammar_symbol, TÄNAV, MAJA, ASULA, MAAKOND, INDEKS)</td>\n",
       "      <td>AddressGrammarTagger</td>\n",
       "      <td>Detects addresses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maltparser_conll_morph</td>\n",
       "      <td>(id, form, lemma, upostag, xpostag, feats, head, deprel, deps, misc)</td>\n",
       "      <td>ConllMorphTagger</td>\n",
       "      <td>Preprocessing for MaltParser based syntactic analysis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maltparser_syntax</td>\n",
       "      <td>(id, lemma, upostag, xpostag, feats, head, deprel, deps, misc, parent_span, children)</td>\n",
       "      <td>MaltParserTagger</td>\n",
       "      <td>Tags dependency syntactic analysis with MaltParser. (requires Java)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>verb_chains</td>\n",
       "      <td>(pattern, roots, word_ids, mood, polarity, tense, voice, remaining_verbs)</td>\n",
       "      <td>VerbChainDetector</td>\n",
       "      <td>Tags main verbs and their extensions (verb chains) in clauses. (experimental)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>np_chunks</td>\n",
       "      <td>()</td>\n",
       "      <td>NounPhraseChunker</td>\n",
       "      <td>Tags noun phrase chunks in sentences. (experimental)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "LayerResolver(default_layers=['morph_analysis', 'sentences'])\n",
       "TaggersRegistry\n",
       "layer               attributes                    tagger_name          description                   \n",
       "=====               ==========                    ===========          ===========                   \n",
       "\n",
       "tokens              ()                            TokensTagger         Preprocessing for word        \n",
       "                                                                       segmentation: segments text   \n",
       "                                                                       into tokens.                  \n",
       "\n",
       "compound_tokens     ('type', 'normalized')        CompoundTokenTagger  Preprocessing for word        \n",
       "                                                                       segmentation: joins tokens    \n",
       "                                                                       into compound tokens.         \n",
       "\n",
       "words               ('normalized_form',)          WordTagger           Segments text into words.     \n",
       "\n",
       "sentences           ()                            SentenceTokenizer    Segments text into            \n",
       "                                                                       sentences.                    \n",
       "\n",
       "paragraphs          ()                            ParagraphTokenizer   Segments text into            \n",
       "                                                                       paragraphs.                   \n",
       "\n",
       "morph_analysis      ('normalized_text', 'lemma',  VabamorfTagger       Tags morphological analysis   \n",
       "                    'root', 'root_tokens',                             with Vabamorf.                \n",
       "                    'ending', 'clitic', 'form',                                                      \n",
       "                    'partofspeech')                                                                  \n",
       "\n",
       "clauses             ('clause_type',)              ClauseSegmenter      Segments sentences into       \n",
       "                                                                       clauses. (requires Java)      \n",
       "\n",
       "morph_analysis_est  ('normaliseeritud_sõne',      VabamorfEstCatConve  Translates category names of  \n",
       "                    'algvorm', 'lõpp',            rter                 Vabamorf's morphological      \n",
       "                    'sõnaliik', 'vormi_nimetus',                       analyses into Estonian (for   \n",
       "                    'kliitik')                                         educational purposes).        \n",
       "\n",
       "morph_extended      ('normalized_text', 'lemma',  MorphExtendedTagger  Converts Vabamorf's           \n",
       "                    'root', 'root_tokens',                             morphological analyses to     \n",
       "                    'ending', 'clitic', 'form',                        syntax preprocessing (CG3)    \n",
       "                    'partofspeech',                                    format.                       \n",
       "                    'punctuation_type',                                                              \n",
       "                    'pronoun_type',                                                                  \n",
       "                    'letter_case', 'fin',                                                            \n",
       "                    'verb_extension_suffix',                                                         \n",
       "                    'subcat')                                                                        \n",
       "\n",
       "gt_morph_analysis   ('normalized_text', 'lemma',  GTMorphConverter     Converts Vabamorf's           \n",
       "                    'root', 'root_tokens',                             morphological analyses to     \n",
       "                    'ending', 'clitic', 'form',                        giellatekno's (GT) format.    \n",
       "                    'partofspeech')                                                                  \n",
       "\n",
       "ner                 ('nertag',)                   NerTagger            Detects named entities:       \n",
       "                                                                       person, location and          \n",
       "                                                                       organization names.           \n",
       "\n",
       "timexes             ('tid', 'type', 'value',      TimexTagger          Detects temporal expressions  \n",
       "                    'temporal_function',                               and normalizes to             \n",
       "                    'anchor_time_id', 'mod',                           corresponding dates, times,   \n",
       "                    'quant', 'freq',                                   durations and recurrences.    \n",
       "                    'begin_point', 'end_point',                        (requires Java)               \n",
       "                    'part_of_interval')                                                              \n",
       "\n",
       "address_parts       ('grammar_symbol', 'type')    AddressPartTagger    Preprocessing for address     \n",
       "                                                                       detection.                    \n",
       "\n",
       "addresses           ('grammar_symbol', 'TÄNAV',   AddressGrammarTagge  Detects addresses.            \n",
       "                    'MAJA', 'ASULA', 'MAAKOND',   r                                                  \n",
       "                    'INDEKS')                                                                        \n",
       "\n",
       "maltparser_conll_m  ('id', 'form', 'lemma',       ConllMorphTagger     Preprocessing for MaltParser  \n",
       "orph                'upostag', 'xpostag',                              based syntactic analysis.     \n",
       "                    'feats', 'head', 'deprel',                                                       \n",
       "                    'deps', 'misc')                                                                  \n",
       "\n",
       "maltparser_syntax   ('id', 'lemma', 'upostag',    MaltParserTagger     Tags dependency syntactic     \n",
       "                    'xpostag', 'feats', 'head',                        analysis with MaltParser.     \n",
       "                    'deprel', 'deps', 'misc',                          (requires Java)               \n",
       "                    'parent_span', 'children')                                                       \n",
       "\n",
       "verb_chains         ('pattern', 'roots',          VerbChainDetector    Tags main verbs and their     \n",
       "                    'word_ids', 'mood',                                extensions (verb chains) in   \n",
       "                    'polarity', 'tense',                               clauses. (experimental)       \n",
       "                    'voice', 'remaining_verbs')                                                      \n",
       "\n",
       "np_chunks           ()                            NounPhraseChunker    Tags noun phrase chunks in    \n",
       "                                                                       sentences. (experimental)     \n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.layer_resolver.layer_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tagasi kihtide vahelisi sõltuvusi näitavale esituskujule saab, kui kutsuda välja: `text.layer_resolver.layer_dependencies`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaikimisi kasutatavale tööahelale pääseb ligi ka ilma `Text` klassi vahenduseta, kui importida `DEFAULT_RESOLVER`:\n",
    "\n",
    "```python\n",
    "from estnltk.default_resolver import DEFAULT_RESOLVER\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tööahelas olevatele märgendajatele pääseb ligi `LayerResolver`-i meetodi `get_tagger(layer)` abil. \n",
    "See võimaldab nt uurida märgendajate konfiguratsiooni:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags morphological analysis on words. Uses Vabamorf's analyzer and disambiguator.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>VabamorfTagger</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech')</td>\n",
       "      <td>('words', 'sentences', 'compound_tokens')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>guess</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propername</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disambiguate</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phonetic</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slang_lex</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postanalysis_tagger</th>\n",
       "      <td>PostMorphAnalysisTagger(('compound_tokens', 'words', 'morph_analysis')-&gt;morph_analysis)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_postanalysis</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysis_reorderer</th>\n",
       "      <td>MorphAnalysisReorderer(('morph_analysis',)-&gt;morph_analysis)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_reorderer</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textbased_disambiguator</th>\n",
       "      <td>CorpusBasedMorphDisambiguator(['words', 'sentences', 'morph_analysis']*-&gt;morph_analysis*)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predisambiguate</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postdisambiguate</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "VabamorfTagger(input_layers=('words', 'sentences', 'compound_tokens'), output_layer=morph_analysis, output_attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), guess=True, propername=True, disambiguate=True, compound=True, phonetic=False, slang_lex=False, postanalysis_tagger=PostMorphAnalysisTagger(('compound_tokens', 'words', 'morph_analysis')->morph_analysis), use_postanalysis=True, analysis_reorderer=MorphAnalysisReorderer(('morph_analysis',)->morph_analysis), use_reorderer=True, textbased_disambiguator=CorpusBasedMorphDisambiguator(['words', 'sentences', 'morph_analysis']*->morph_analysis*), predisambiguate=False, postdisambiguate=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " text.layer_resolver.get_tagger('morph_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seda, millised kihid luuakse, kui kutsutakse välja `tag_layer` välja ilma parameetriteta, mõjutab `LayerResolver`-i atribuut `default_layers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('morph_analysis', 'sentences')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " text.layer_resolver.default_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atribuudi väärtuse saab ka ümber muuta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ma ei hooli juveelidest. Mulle meeldivad lilled.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis_est</td>\n",
       "      <td>normaliseeritud_sõne, algvorm, lõpp, sõnaliik, vormi_nimetus, kliitik</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ma ei hooli juveelidest. Mulle meeldivad lilled.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Ma ei hooli juveelidest. Mulle meeldivad lilled.')\n",
    "\n",
    "# Muudame vaikekihiks morph_analysis_est\n",
    "text.layer_resolver.default_layers = ['morph_analysis_est']\n",
    "\n",
    "# Märgendame morph_analysis_est (ja kõik selle sõltuvused)\n",
    "text.tag_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tööahelas olevate märgendajate konfiguratsiooni saab vajadusel muuta, sellest allpool detailsemalt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Märgendajate importimine `estnltk.taggers` kaudu. Märgendajate otserakendamine (meetod `tag`)\n",
    "\n",
    "`DEFAULT_RESOLVER` ei sisalda kõiki EstNLTK-s olemasolevaid märgendajaid.\n",
    "Põhjus selles, et osad märgendajad on rakendamiseks spetsiifilistest kontekstides (nt märgenduste võrdlemisel), osad märgendajad nõuavad spetsiifilisi ressursse (nt suuri mudeleid, mis tuleb veebist alla tõmmata) ja osad tegelevad spetsiifiliste tekstianalüüsi probleemidega (nt kuupäevade tuvastamisega meditsiinitekstides).\n",
    "Siiski on enamus märgendajaid kättesaadavad [`estnltk.taggers`](https://github.com/estnltk/estnltk/blob/main/estnltk/estnltk/taggers/__init__.py) kaudu, seega saab neid sealt importida ja rakendada vastavalt vajadusele.\n",
    "\n",
    "```python\n",
    "import estnltk.taggers\n",
    "# Kuva imporditavate märgendajate nimed\n",
    "dir( estnltk.taggers )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Näide. Tahame tekstil rakendada veebiteenusel baseeruvat Stanza süntaksianalüüsi. \n",
    "Loome kõigepealt analüüsitava teksti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Ma ei hooli juveelidest. Mulle meeldivad lilled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edasi impordime `StanzaSyntaxWebTagger`-i ja konfigureerime [juhendi järgi](https://github.com/estnltk/estnltk/blob/main/tutorials/taggers/web_taggers/web_taggers.ipynb) veebiteenuse asukoha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>BatchProcessingWebTagger</h4>\n",
       "Tags dependency syntactic analysis using EstNLTK StanzaSyntaxTagger's webservice.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>StanzaSyntaxWebTagger</td>\n",
       "      <td>stanza_syntax</td>\n",
       "      <td>('id', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel', 'deps', 'misc')</td>\n",
       "      <td>('words', 'sentences', 'morph_extended')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>https://api.tartunlp.ai/estnltk/tagger/stanza_syntax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_layer</th>\n",
       "      <td>words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_layer_max_size</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_enveloping_layer</th>\n",
       "      <td>sentences</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "StanzaSyntaxWebTagger(input_layers=('words', 'sentences', 'morph_extended'), output_layer=stanza_syntax, output_attributes=('id', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel', 'deps', 'misc'), url=https://api.tartunlp.ai/estnltk/tagger/stanza_syntax, batch_layer=words, batch_layer_max_size=125, batch_enveloping_layer=sentences)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import StanzaSyntaxWebTagger\n",
    "stanza_syntax_tagger = StanzaSyntaxWebTagger(url='https://api.tartunlp.ai/estnltk/tagger/stanza_syntax')\n",
    "stanza_syntax_tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enne imporditud märgendaja rakendamist tuleb hoolitseda selle eest, et sisendtekstil oleks olemas kõik vajaminevad sõltuvuskihid ( _input layers_ ), kuna märgendaja ise automaatselt sõltuvuskihte tekstile ei lisa -- nende puudumisel tuleb veateade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ma ei hooli juveelidest. Mulle meeldivad lilled.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_extended</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, punctuation_type, pronoun_type, letter_case, fin, verb_extension_suffix, subcat</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ma ei hooli juveelidest. Mulle meeldivad lilled.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lisame tekstile puuduolevad sõltuvuskihid\n",
    "text.tag_layer(('words', 'sentences', 'morph_extended'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui sõltuvuskihid on lisatud, kutsume välja märgendaja meetodi `tag`, mis tekitabki märgenduskihi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ma ei hooli juveelidest. Mulle meeldivad lilled.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_extended</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, punctuation_type, pronoun_type, letter_case, fin, verb_extension_suffix, subcat</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>stanza_syntax</td>\n",
       "      <td>id, lemma, upostag, xpostag, feats, head, deprel, deps, misc</td>\n",
       "      <td>morph_extended</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ma ei hooli juveelidest. Mulle meeldivad lilled.')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rakendame märgendajat tekstil\n",
    "stanza_syntax_tagger.tag( text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Täiendavad viited:\n",
    "\n",
    "🔗 Sissejuhatus EstNLTK baastööahelasse: https://github.com/estnltk/estnltk/blob/a5a736a64759eead9c868ffeacf5f8dbf14b1f7a/tutorials/basics/introduction_to_nlp_pipeline.ipynb\n",
    "\n",
    "🔗 Detailne info märgendajate kohta: https://github.com/estnltk/estnltk/tree/main/tutorials/nlp_pipeline\n",
    "\n",
    "🔗 Süsteemsed märgendajad ja märgendajate loomine: https://github.com/estnltk/estnltk/tree/main/tutorials/taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<h4><i>Märgendajad (<b><code>Tagger</code></b>) vs ümbermärgendajad</i> (<b><code>Retagger</code></b>)</h4> \n",
    "<br>\n",
    "Osad EstNTLK märgendajad loovad uusi kihte, osad aga kirjutavad ümber (parendavad) olemasolevaid kihte. \n",
    "Kui tegemist on kihti ümberkirjutava märgendajaga (<b><code>Retagger</code></b>), siis tuleb enne selle rakendamist veenduda, et ümberkirjutatav kiht (<code>output_layer</code>) on tekstil juba olemas ning märgendaja rakendamine käib siis meetodi <code>retag( text )</code> kaudu.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<h4><i>Märgenduskihi nime muutmine</i></h4> \n",
    "<br>\n",
    "Kui importida märgendaja <code>estnltk.taggers</code>-i kaudu, siis saab ka muuta loodava märgenduskihi nime. See käib tavaliselt konstruktori argumendi <code>output_layer</code> abil, nt verbiahelate tuvastaja puhul:\n",
    "<pre>\n",
    "from estnltk.taggers import VerbChainDetector\n",
    "verb_chain_tagger = VerbChainDetector(output_layer='my_verb_chains')\n",
    "</pre>\n",
    "Märgenduskihitide nimede muutmine on vajalik tööriistade erinevate konfiguratsioonide testimisel, samuti tööriistade täiustamisel.\n",
    "Nt, kui nimetada märgenduskihid vastavalt tööriista versioonile (a la <code>'verb_chains_v1'</code>, <code>'verb_chains_v2'</code> jne), siis saab neid ka võrrelda omavahel.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Tööahelas olevate märgendajate muutmine (`make_resolver`)\n",
    "\n",
    "EstNLTK baastööahela tekitamine (märgendajate initsialiseerimine ja lisamine ahelasse) käib `make_resolver`-i abil.\n",
    "\n",
    "Kõige lihtsam viis tööahela muutmiseks on luua `make_resolver`-iga baastööahelast koopia ja muuta seda vastavalt oma vajadustele.\n",
    "Näide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.default_resolver import make_resolver\n",
    "\n",
    "my_resolver = make_resolver()  # Loome baastööahela koopia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seejärel saab meetodi `update` abil uuendada tööahela märgendajat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loome uue morf märgendaja, millel on ühestamine ja oletamised välja lülitatud\n",
    "from estnltk.taggers import VabamorfTagger\n",
    "vabamorf_tagger = VabamorfTagger( disambiguate=False, guess=False, propername=False )\n",
    "\n",
    "# Asendame tööahelas oleva morf märgendaja uuega\n",
    "my_resolver.update( vabamorf_tagger )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muudetud tööahela rakendamiseks tuleb meetodi `tag_layer` väljakutsumisel täpsustada, millist `resolver`-it kasutame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "      <th>_ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Metsawahi</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hobusele</td>\n",
       "      <td>hobusele</td>\n",
       "      <td>hobune</td>\n",
       "      <td>hobune</td>\n",
       "      <td>['hobune']</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>om</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>['uus']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laut</td>\n",
       "      <td>laut</td>\n",
       "      <td>laut</td>\n",
       "      <td>laut</td>\n",
       "      <td>['laut']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ehitet</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech', '_ignore'), spans=SL[Span('Metsawahi', [{'normalized_text': None, 'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None, '_ignore': False}]),\n",
       "Span('hobusele', [{'normalized_text': 'hobusele', 'lemma': 'hobune', 'root': 'hobune', 'root_tokens': ['hobune'], 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'S', '_ignore': False}]),\n",
       "Span('om', [{'normalized_text': None, 'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None, '_ignore': False}]),\n",
       "Span('uus', [{'normalized_text': 'uus', 'lemma': 'uus', 'root': 'uus', 'root_tokens': ['uus'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A', '_ignore': False}]),\n",
       "Span('laut', [{'normalized_text': 'laut', 'lemma': 'laut', 'root': 'laut', 'root_tokens': ['laut'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S', '_ignore': False}]),\n",
       "Span('ehitet', [{'normalized_text': None, 'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None, '_ignore': False}]),\n",
       "Span('.', [{'normalized_text': None, 'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None, '_ignore': False}])])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Metsawahi hobusele om uus laut ehitet.')\n",
    "text.tag_layer('morph_analysis', resolver=my_resolver)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eelmises näites: kuna tundmatute sõnade oletamine lülitati morfoloogilisest analüüsist välja (`guess=False`), siis said kõik vana kirjaviisiga sõnad ( _Metsawahi , om , ehitet_ ) tühjad analüüsid (kõik atribuudiväärtused `None`).\n",
    "Seega võib morf analüüsi vastavat konfiguratsiooni kasutades tuvastada sõnavormid, mida tänapäeva eesti kirjakeel ei tunne. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LayerResolver`-i meetodi `update(tagger)` abil saab tööahelasse lisada ka täiesti uusi märgendajaid, aga tingimuseks on, et lisatava märgendaja kõiki sõltuvuskihte ( _input layers_ ) peab tööahel oskama juba teha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<h4><i><code>make_resolver</code> ja morfoloogilise analüüsi parameetrid</i></h4> \n",
    "<br>\n",
    "Kuna EstNTLK lingvistilise analüüsi keskne komponent on morfoloogiline märgendaja, siis on võimalik <code>make_resolver</code>-i abil ka otse muuta morfoloogilise analüüsi parameetreid <code>disambiguate</code>, <code>guess</code>, <code>propername</code> jm.\n",
    "Selle kohta on detailsemalt juttu juhendmaterjalis <a href=\"https://github.com/estnltk/estnltk/blob/a5a736a64759eead9c868ffeacf5f8dbf14b1f7a/tutorials/basics/introduction_to_nlp_pipeline.ipynb\">introduction_to_nlp_pipeline.ipynb</a>.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Hoiatus: <code>make_resolver</code> ja konfliktsed konfiguratsioonid</i></h4> \n",
    "<br>\n",
    "<code>make_resolver</code> ja <code>DEFAULT_RESOLVER</code> pakuvad morfoloogilise analüüsi vaikekonfiguratsiooni, millega toimivad ka teised tööahelas olevad komponendid. \n",
    "Kui aga muuta <code>make_resolver</code>-i abil morfoloogilise analüüsi parameetreid, ei garanteeritud, et säilib tööahela analüüsi kvaliteet ning kõigi komponentide töövõime. \n",
    "Nt kui lülitada ülalkirjeldatud viisil välja ühestamine ja oletamine, siis ei toimi enam nimeüksuste tuvastamine ja süntaktiline analüüs. \n",
    "Seega tasub tööahela konfiguratsiooni muuta alles siis, kui on selge, kuidas see erinevaid tööriistu mõjutab.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui oled kogemata muutnud vaiketööahelat selliselt, et osad komponendid enam ei toimi, siis saad vaiketööahela taastada `make_resolver`-i abil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.default_resolver import make_resolver\n",
    "# Taastame tööahela vaikekonfiguratsiooni\n",
    "Text.layer_resolver = make_resolver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 Märgenduskihi eemaldamine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Märgenduskihi eemaldamiseks on meetod `pop_layer`, mis eemaldab kihi ning tagastab selle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound_tokens', 'sentences', 'tokens', 'words'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eemaldame morfoloogilise märgenduse kihi\n",
    "text.pop_layer('morph_analysis')\n",
    "\n",
    "# Veendume, et kihti enam pole\n",
    "text.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NB!_ Kui `Text` objektil leidub kihte, mis on eemaldatavast kihist sõltuvad, siis eemaldatakse ka need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Märgenduskihist väljavõtete tegemine. Itereerimine üle märgenduste\n",
    "\n",
    "EstNLTK-s on kaks viisi `Text` objektilt märgenduskihi küsimiseks: \n",
    "\n",
    "* indeksi (sõne) järgi:\n",
    "`text['tokens']`\n",
    "* atribuudi järgi:\n",
    "`text.tokens`\n",
    "\n",
    "Tulemuste poolest on mõlemad viisid võrdsed: tagastatakse `Layer` objekt, mis on sisuliselt järjend _märgendustest_.\n",
    "Näide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ma</td>\n",
       "      <td>Ma</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>['mina']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>['ei']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>neg</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hooli</td>\n",
       "      <td>hooli</td>\n",
       "      <td>hoolima</td>\n",
       "      <td>hooli</td>\n",
       "      <td>['hooli']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juveelidest</td>\n",
       "      <td>juveelidest</td>\n",
       "      <td>juveel</td>\n",
       "      <td>juveel</td>\n",
       "      <td>['juveel']</td>\n",
       "      <td>dest</td>\n",
       "      <td></td>\n",
       "      <td>pl el</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mulle</td>\n",
       "      <td>Mulle</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>['mina']</td>\n",
       "      <td>lle</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meeldivad</td>\n",
       "      <td>meeldivad</td>\n",
       "      <td>meeldima</td>\n",
       "      <td>meeldi</td>\n",
       "      <td>['meeldi']</td>\n",
       "      <td>vad</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lilled</td>\n",
       "      <td>lilled</td>\n",
       "      <td>lill</td>\n",
       "      <td>lill</td>\n",
       "      <td>['lill']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Ma', [{'normalized_text': 'Ma', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "Span('ei', [{'normalized_text': 'ei', 'lemma': 'ei', 'root': 'ei', 'root_tokens': ['ei'], 'ending': '0', 'clitic': '', 'form': 'neg', 'partofspeech': 'V'}]),\n",
       "Span('hooli', [{'normalized_text': 'hooli', 'lemma': 'hoolima', 'root': 'hooli', 'root_tokens': ['hooli'], 'ending': '0', 'clitic': '', 'form': 'o', 'partofspeech': 'V'}]),\n",
       "Span('juveelidest', [{'normalized_text': 'juveelidest', 'lemma': 'juveel', 'root': 'juveel', 'root_tokens': ['juveel'], 'ending': 'dest', 'clitic': '', 'form': 'pl el', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Mulle', [{'normalized_text': 'Mulle', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': 'lle', 'clitic': '', 'form': 'sg all', 'partofspeech': 'P'}]),\n",
       "Span('meeldivad', [{'normalized_text': 'meeldivad', 'lemma': 'meeldima', 'root': 'meeldi', 'root_tokens': ['meeldi'], 'ending': 'vad', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "Span('lilled', [{'normalized_text': 'lilled', 'lemma': 'lill', 'root': 'lill', 'root_tokens': ['lill'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loome teksti koos sõnade, lausete ja morfoloogilise märgendusega\n",
    "from estnltk import Text\n",
    "text = Text('Ma ei hooli juveelidest. Mulle meeldivad lilled.')\n",
    "text.tag_layer(['words', 'sentences', 'morph_analysis'])\n",
    "\n",
    "# Küsime morfoloogiliste märgenduste kihi\n",
    "text['morph_analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Märgenduse asukoht ja vastav tekstilõik: `Span` ja `EnvelopingSpan`\n",
    "\n",
    "_Märgendus_ koosneb tavajuhul `Span`-ist, mis määrab märgenduse asukoha tekstis, ning `Annotation` objektidest, mis määravad märgenduse sisu ehk millist infot märgendus kannab. Näide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Ma</span></span></td>\n",
       "      <td>Ma</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>[&#x27;mina&#x27;]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('Ma', [{'normalized_text': 'Ma', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Küsime morfoloogilise märgenduse kihist esimese elemendi\n",
    "text['morph_analysis'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui tegemist on **ümbriskihiga** ( _enveloping layer_ ), on märgendus defineeritud mingi teise märgenduskihi elementide järjendina. Sellisel juhul kirjeldab märgenduse asukohta `EnvelopingSpan`.\n",
    "Näiteks, lausemärgendus on defineeritud nende sõnade kaudu, mida lause sisaldab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>EnvelopingSpan</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Ma</span> <span style=\"text-decoration: underline;\">ei</span> <span style=\"text-decoration: underline;\">hooli</span> <span style=\"text-decoration: underline;\">juveelidest</span><span style=\"text-decoration: underline;\">.</span></span></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "EnvelopingSpan(['Ma', 'ei', 'hooli', 'juveelidest', '.'], [{}])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esimese lause sisu (sõnade järjend)\n",
    "text['sentences'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Märgenduse infosisust ehk `Annotation` objektidest tuleb detailsemalt juttu allpool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iga märgendus on varustatud atribuutidega `start`, `end` ja `text`, mis kirjeldavad selle asukohta algses tekstis ning vastavat sõnet.\n",
    "Atribuut `start` sisaldab märgenduse algusindeksit tekstis, atribuut `end` aga lõppindeksit.\n",
    "Atribuut `text` sisaldab tekstilõiku, mida märgendus katab.\n",
    "Näited:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][0].start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][0].end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ma'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Millisel kujul on atribuudis `text` olev tekstilõik, see sõltub kihi tüübist. \n",
    "Kui tegemist on ümbriskihiga ( _enveloping layer_ ), siis peitub atribuudi all sõnede järjend.\n",
    "Näiteks: lausete kiht ümbritseb sõnade kihti ning seega annab lausete atribuut `text` järjendi sõnade kihi `text` väärtustest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ma', 'ei', 'hooli', 'juveelidest', '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esimese lause \"text\"\n",
    "text['sentences'][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui on vaja saada kätte ümbriskihi elementi sõne kujul, siis selle saab kätte `enclosing_text` abil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ma ei hooli juveelidest.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esimesele lausele vastav sõne\n",
    "text['sentences'][0].enclosing_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sarnaselt lausete kihile on ümbriskihid veel nt kihid `'clauses'`, `'compound_tokens'` ja `'paragraphs'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Hoiatus: <code>enclosing_text</code> ja lünkadega märgendused</i></h4> \n",
    "<br>\n",
    "Atribuut <code>enclosing_text</code> annab sisuliselt välja märgenduse indeksite <code>start</code> ja <code>end</code> vahele jääva sõne.\n",
    "See kehtib isegi siis, kui märgenduses on lüngad, st märgendus ei sisalda kõiki ümbritsetava kihi elemente vahemikus <code>start</code> ja <code>end</code>.\n",
    "Seega tuleb olla ettevaatlik <code>enclosing_text</code> kasutamisega nt märgenduskihi <code>'clauses'</code> puhul: kuna sealsed märgendused võivad sisaldada ka lünkasid, ei anna <code>enclosing_text</code> täpselt edasi märgenduse ulatust.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<h4><i>Märgenduste asukohapõhine võrdlemine</i> (<code>estnltk_core.layer.span_operations</code>) </h4> \n",
    "<br>\n",
    "EstNLTK-s on olemas ka funktsioonid <code>Span</code>-ide süstemaatiliseks asukohapõhiseks võrdlemiseks. Näiteks:\n",
    "<ul> \n",
    " <li> <code>conflict(span_x, span_y)</code> teeb kindlaks, kas <code>span_x</code> ja <code>span_y</code> on positsioonide poolest osaliselt või täielikult ülekattuvad;</li>\n",
    " <li> <code>nested(span_x, span_y)</code> kontrollib, kas emb-kumb märgendustest on teise märgenduse sees;</li>\n",
    " <li> <code>equal(span_x, span_y)</code> kontrollib märgenduste täielikku võrdsust;</li>\n",
    "</ul>\n",
    "    \n",
    "🔗 Võrdlusfunktsioone on veel, kõigi funktsioonide kohta vaata detailsemalt lähtekoodist: <a href=\"https://github.com/estnltk/estnltk/blob/main/estnltk_core/estnltk_core/layer/span_operations.py\">https://github.com/estnltk/estnltk/blob/main/estnltk_core/estnltk_core/layer/span_operations.py</a>\n",
    "    \n",
    "NB! Need funktsioonid võrdlevad märgendusi vaid asukohapõhiselt ning ei arvesta <code>Annotation</code> objektides olevat märgendussisu.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Märgenduse infosisu: `Annotation`\n",
    "\n",
    "Märgenduse infosisu -- nt morfoloogilise analüüsi puhul informatsioon lemma, sõnaliigi ja vormitunnuste kohta -- sisaldub `Annotation` objektis.\n",
    "Sisu kättesaamiseks on `Span` ja `EnvelopingSpan` objektidel atribuut `annotations`, mis annab järjendi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Annotation('Ma', {'normalized_text': 'Ma', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['morph_analysis'][0].annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Annotation` objekt on sarnane _sõnastikuga_ : selles on defineeritud märgenduskihi **atribuudid** ja neile vastavad **väärtused**.\n",
    "Seega on võimalik ka atribuudinime järgi väärtust küsida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mina'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Küsime esimesest märgendusest 'lemma' väärtuse\n",
    "annotation = text['morph_analysis'][0].annotations[0]\n",
    "annotation['lemma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui on aga tarvis korraga paljudest märgendusest atribuudiväärtuseid kätte saada, siis muutub eeltoodud küsimisviis kohmakaks. \n",
    "Seepärast sisaldab EstNLTK ka märksa mugavamaid viise märgendustest väljavõtete tegemiseks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Märgendustest väljavõtete tegemine\n",
    "\n",
    "Nagu tavalisest järjendist, saab ka märgenduskihist võtta välja märgendusi **indeksite vahemiku** abil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mulle</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meeldivad</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lilled</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Mulle', [{'normalized_form': None}]),\n",
       "Span('meeldivad', [{'normalized_form': None}]),\n",
       "Span('lilled', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][5:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saab **välja selekteerida** ainult spetsiifilite indeksitega märgendused, nt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>juveelidest</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lilled</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('juveelidest', [{'normalized_form': None}]),\n",
       "Span('lilled', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][[3,7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`lambda` funktsiooni** abil saab võtta välja kindlatele tingimustele vastavad märgendused.\n",
    "\n",
    "Näiteks, võtame välja ainult sõnad, mille pikkus on 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ma</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Ma', [{'normalized_form': None}]),\n",
       "Span('ei', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][ lambda span: len(span.text) == 2 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeksite järgi `Span`-ide väljavõtmist saab kombineerida spetsiifiliste atribuutide väljavõtmisega. \n",
    "Sellisel juhul pole väljavõtte tulemuseks enam märgenduskiht, vaid `AttributeList` (kui valiti üks atribuut) või `AttributeTupleList` (kui valiti mitu atribuuti). \n",
    "Kui kiht on omakorda veel mitmene, on tulemuseks vastavalt kas `AmbiguousAttributeList` või `AmbiguousAttributeTupleList`.\n",
    "\n",
    "Näiteks võime sellist kombineeritud väljavõtmist rakendada morfoloogilise märgenduse peal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeList (spans)</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeList([['P'], ['V'], ['V'], ['S']], ('partofspeech',))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Võtame välja 4 esimese sõna sõnaliigid\n",
    "text.morph_analysis[0:4, 'partofspeech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeTupleList (spans)</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mina</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ei</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>hoolima</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>juveel</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeTupleList([[['mina', 'P']], [['ei', 'V']], [['hoolima', 'V']], [['juveel', 'S']]], ('lemma', 'partofspeech'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Võtame välja 4 esimese sõna lemmad ja sõnaliigid\n",
    "text.morph_analysis[0:4, ['lemma','partofspeech']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeksitele leidub ka alternatiivne viis märgendusatribuutide kättesaamiseks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeList (spans)</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>meeldima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeList([['mina'], ['meeldima'], ['lill'], ['.']], ('lemma',))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sõnade lemmad atribuudi abil\n",
    "text.morph_analysis[5:].lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kui kiht omab ülemkihti, siis saab selle atribuudid kätte ka ülemkihi kaudu.\n",
    "Näiteks, sõnade kihi kaudu saab kätte lemmad morf märgenduste kihist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeList (spans)</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>meeldima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeList([['mina'], ['meeldima'], ['lill'], ['.']], ('lemma',))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sõnade lemmad atribuudi abil, ülemkihi kaudu\n",
    "text.words[5:].lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<h4><i>Märkus mitmesuse kohta</i></h4> \n",
    "<br>\n",
    "Nimetus <code>AmbiguousAttributeList</code> Notebooki väljundis annab märku, on tegemist väljavõttega mitmesest märgenduskihist.\n",
    "Tuletame meelde, et objektide <code>Span</code> ja <code>EnvelopingSpan</code> atribuudi <code>annotations</code> kaudu antakse meile järjend, mitte üksik väärtus. Seega antakse ka atribuutide väärtused tegelikult järjendina.\n",
    "Näiteks:\n",
    "<pre>\n",
    ">> text.words[5].lemma\n",
    "['mina']\n",
    ">> text.words[5].partofspeech\n",
    "['P']\n",
    "</pre>\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4 Mitmest märgenduskihist väljavõtete tegemine: kombineeritud itereerimine\n",
    "\n",
    "Sageli on vaja kombineerida mitmest kihist pärit infot. \n",
    "Näiteks on siin morfoloogilisest märgendusest väljavõtete tegemine ühe lause piires.\n",
    "Kuna lausete kiht ümbritseb sõnade kihti ning morfoloogilise analüüsi kiht toetub sõnade kihile, siis saamegi itereerida üle lausete ja nendes olevate sõnade ning võtta välja iga sõna morfoloogilised märgendused:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lause: Ma ei hooli juveelidest.\n",
      "  Lemma:  mina \t\tsõnaliik: P\n",
      "  Lemma:  ei \t\tsõnaliik: V\n",
      "  Lemma:  hoolima \t\tsõnaliik: V\n",
      "  Lemma:  juveel \t\tsõnaliik: S\n",
      "  Lemma:  . \t\tsõnaliik: Z\n",
      "\n",
      "Lause: Mulle meeldivad lilled.\n",
      "  Lemma:  mina \t\tsõnaliik: P\n",
      "  Lemma:  meeldima \t\tsõnaliik: V\n",
      "  Lemma:  lill \t\tsõnaliik: S\n",
      "  Lemma:  . \t\tsõnaliik: Z\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in text.sentences:\n",
    "    print('Lause:', sentence.enclosing_text)\n",
    "    for word in sentence:\n",
    "        print( '  Lemma: ', word.morph_analysis.lemma[0], \\\n",
    "               '\\t\\tsõnaliik:', word.morph_analysis.partofspeech[0] )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.5 Kihi märgenduste agregeerimine: `Layer.groupby` ja `Layer.rolling`\n",
    "\n",
    "EstNLTK märgenduskihil on olemas meetodid, mis võimaldavad teha agregeerivaid väljavõtteid: märgendusi grupeerida ning jadastada (moodustada _n_-gramme).\n",
    "\n",
    "Meetod `groupby` võimaldab märgendusi **grupeerida atribuutide või ümbriskihtide järgi**.\n",
    "Näiteks, võime morfoloogilisi märgendusi grupeerida sõnaliikide alusel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = text.morph_analysis.groupby( 'partofspeech' , return_type='spans' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meetodi `count` abil saab kätte sõnaliikide sagedused:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('P',): 2, ('V',): 3, ('S',): 2, ('Z',): 2}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.count "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saab võtta välja kõik mingisse gruppi kuuluvad märgendused. \n",
    "Näiteks, võtame välja kõik verbid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Span('ei', [{'normalized_text': 'ei', 'lemma': 'ei', 'root': 'ei', 'root_tokens': ['ei'], 'ending': '0', 'clitic': '', 'form': 'neg', 'partofspeech': 'V'}]),\n",
       " Span('hooli', [{'normalized_text': 'hooli', 'lemma': 'hoolima', 'root': 'hooli', 'root_tokens': ['hooli'], 'ending': '0', 'clitic': '', 'form': 'o', 'partofspeech': 'V'}]),\n",
       " Span('meeldivad', [{'normalized_text': 'meeldivad', 'lemma': 'meeldima', 'root': 'meeldi', 'root_tokens': ['meeldi'], 'ending': 'vad', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.groups[('V',)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grupeerida on võimalik ka mitme atribuudi järgi, nt grupeerime sõnaliikide ja vormitunnuste järgi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('P', 'sg n'): 1,\n",
       " ('V', 'neg'): 1,\n",
       " ('V', 'o'): 1,\n",
       " ('S', 'pl el'): 1,\n",
       " ('Z', ''): 2,\n",
       " ('P', 'sg all'): 1,\n",
       " ('V', 'vad'): 1,\n",
       " ('S', 'pl n'): 1}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = text.morph_analysis.groupby( ['partofspeech', 'form'] , return_type='spans' )\n",
    "groups.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lisaks on võimalik grupeerida ka ümbriskihtide ( _enveloping layer_ ) alusel.\n",
    "Näiteks, grupeerime morfoloogilised analüüsid lausete järgi ning väljastame iga lause sõnad ja sõnaliigid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ma ei hooli juveelidest. Mulle meeldivad lilled.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ma ei hooli juveelidest. Mulle meeldivad lilled.')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ma', 'ei', 'hooli', 'juveelidest', '.']\n",
      "    Ma \t ['P']\n",
      "    ei \t ['V']\n",
      "    hooli \t ['V']\n",
      "    juveelidest \t ['S']\n",
      "    . \t ['Z']\n",
      "['Mulle', 'meeldivad', 'lilled', '.']\n",
      "    Mulle \t ['P']\n",
      "    meeldivad \t ['V']\n",
      "    lilled \t ['S']\n",
      "    . \t ['Z']\n"
     ]
    }
   ],
   "source": [
    "for sentence_id, sentence_spanlist in text.morph_analysis.groupby( text.sentences ):\n",
    "    print([span.text for span in sentence_spanlist])\n",
    "    for morph_span in sentence_spanlist:\n",
    "        print('   ',morph_span.text,'\\t',morph_span.partofspeech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meetod `rolling` võimaldab **märgendusi järjestikku grupeerida**. \n",
    "Näiteks, võime moodustada morfoloogilise märgenduse pealt trigrammid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ma', 'ei', 'hooli'] => ['mina'] ['ei'] ['hoolima']\n",
      "['ei', 'hooli', 'juveelidest'] => ['ei'] ['hoolima'] ['juveel']\n",
      "['hooli', 'juveelidest', '.'] => ['hoolima'] ['juveel'] ['.']\n",
      "['juveelidest', '.', 'Mulle'] => ['juveel'] ['.'] ['mina']\n",
      "['.', 'Mulle', 'meeldivad'] => ['.'] ['mina'] ['meeldima']\n",
      "['Mulle', 'meeldivad', 'lilled'] => ['mina'] ['meeldima'] ['lill']\n",
      "['meeldivad', 'lilled', '.'] => ['meeldima'] ['lill'] ['.']\n"
     ]
    }
   ],
   "source": [
    "for spans in text.morph_analysis.rolling( window=3 ):\n",
    "    print(spans.text, '=>', spans[0].lemma, spans[1].lemma, spans[2].lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meetodi rakendamisel saab teha veel täpsustusi: saab määratleda ümbriskihi, mille raames n-grammid moodustatakse, ning saab määratleda minimaalse n-grammi pikkuse (mis rakendub piirisituatsioonides, nt teksti alguses ja lõpus)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 Meetodite `groupby` ja `rolling` kasutuse kohta detailsemalt: https://github.com/estnltk/estnltk/blob/main/tutorials/system/layer_operations.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Teksti tükeldamine: `extract_sections` ja `split_by`\n",
    "\n",
    "Funktsiooni `extract_sections` abil on võimalik `Text` objekt **tükeldada indeksite järgi väiksemateks osadeks**.\n",
    "Näide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(text='juveelidest.'), Text(text='Mulle meeldivad')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk_core.layer_operations import extract_sections\n",
    "\n",
    "sections = extract_sections(text, sections=[(12, 24), (25,40)])\n",
    "sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tulemuseks on samuti `Text` objektid ning vaikimisi püütakse säilitada ka kõiki märgenduskihte -- eeldusel, et märgendused mahuvad täielikult eraldatud osade sisse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">juveelidest.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='juveelidest.')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eelmises näites eemaldati tükeldamisel lausete märgendused, kuna kumbki eraldatud osadest ei mahutanud terviklauseid. \n",
    "Parameetri `trim_overlapping=True` kaasaandmisel `extract_sections`-ile jääksid aga laused alles: need lõigatakse lihtsalt lühemaks, vastavalt tükeldamisel etteantud indeksitele."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktsiooni `split_by` abil on võimalik `Text` objekti **tükeldada märgenduskihtide järgi väiksemateks osadeks**.\n",
    "Näiteks, võime teksti jagada lausete järgi väiksemateks `Text` objektideks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(text='Ma ei hooli juveelidest.'), Text(text='Mulle meeldivad lilled.')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk_core.layer_operations import split_by\n",
    "\n",
    "sentence_texts = split_by(text, 'sentences')\n",
    "sentence_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ma ei hooli juveelidest.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ma ei hooli juveelidest.')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erinevalt funktsioonist `extract_sections` jätab `split_by` alles vaid märgenduskihi, mille järgi toimus teksti tükeldamine ning  sellega sõltuvusseoseidpidi ühendatud kihid.\n",
    "Nt, eelmises näites jäi alles `'morph_analysis'` kiht, kuna selle ülemus on `'words'` ning `'sentences'` on omakorda `'words'` kihi ümbriskiht, aga eemaldati kihid `'tokens'` ja `'compound_tokens'`, kuna need pole `'sentences'` kihiga seotud ei ümbriskihi ega ülem/alamkihi seoste kaudu.\n",
    "Vajadusel saab siiski nõuda ka kõigi kihtide allesjätmist, selle kohta vt lähemalt funktsiooni dokumentatsioonist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 `extract_sections` ja `split_by` kasutuse kohta annab detailsemat infot: https://github.com/estnltk/estnltk/blob/main/tutorials/system/layer_operations.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 Tükeldamisele leidub ka pöördoperatsioon, mis võimaldab tükeldatud tekstid tagasi tervikuks liita. Selle kasutamise kohta annab infot samuti [layer_operations.ipynb](https://github.com/estnltk/estnltk/blob/main/tutorials/system/layer_operations.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Viiteid detailsematele abimaterjalidele (ingl k)\n",
    "\n",
    "* Sissejuhatus:\n",
    "    * Vaiketööahel ja lingvistiline analüüs: [introduction_to_nlp_pipeline.ipynb](https://github.com/estnltk/estnltk/blob/main/tutorials/basics/introduction_to_nlp_pipeline.ipynb)\n",
    "    * Andmestruktuurid ja programmeerimisliides: [introduction_to_estnltk_api.ipynb](https://github.com/estnltk/estnltk/blob/main/tutorials/basics/introduction_to_estnltk_api.ipynb)\n",
    "    * Vajalike ressursside / mudelite allalaadimine: [estnltk_resources.ipynb](https://github.com/estnltk/estnltk/blob/main/tutorials/basics/estnltk_resources.ipynb)\n",
    "\n",
    "\n",
    "* Põhikomponendid (lingvistiline analüüs, märgendajad):\n",
    "\n",
    "    * [A_text_segmentation](https://github.com/estnltk/estnltk/tree/main/tutorials/nlp_pipeline/A_text_segmentation) -- sõnestamise tööriistad: teksti jagamine sõnedeks, sõnadeks, lauseteks, osalauseteks ja lõikudeks;\n",
    "\n",
    "    * [B_morphology](https://github.com/estnltk/estnltk/tree/main/tutorials/nlp_pipeline/B_morphology) -- morfoloogia tööriistad: morfoloogiline analüüs (Vabamorf, tekstipõhine ja korpusepõhine ühestaja, kasutajasõnastikupõhine parandaja, GT kujule teisendaja and HFST-l baseerub analüsaator), morfoloogiline süntees, õigekirjakontroll ja silbitaja;\n",
    "\n",
    "    * [C_syntax](https://github.com/estnltk/estnltk/tree/main/tutorials/nlp_pipeline/C_syntax) -- süntaksi tööriistad: eeltöötlus, süntaktilised parserid ja nende mudelid ning tööriistad süntaksi järeltöötluseks ning hindamiseks;\n",
    "\n",
    "    * [D_information_extraction](https://github.com/estnltk/estnltk/tree/main/tutorials/nlp_pipeline/D_information_extraction) -- infoeraldus: ajaväljendite, nimeüksuste ja aadresside tuvastamine;\n",
    "\n",
    "    * [E_embeddings](https://github.com/estnltk/estnltk/tree/main/tutorials/nlp_pipeline/E_embeddings) -- eeltreenitud keelemudelitel ja sõnavektoritel põhinevad tööriistad;\n",
    "\n",
    "    * [X_miscellaneous](https://github.com/estnltk/estnltk/tree/main/tutorials/nlp_pipeline/X_miscellaneous) -- eksperimentaalsed tööriistad: verbiahelate tuvastaja, nimisõnafraaside eraldaja, omadussõnafraaside leidja ja kuupäevade tuvastaja meditsiiniteksitest;\n",
    "    * [web_taggers](https://github.com/estnltk/estnltk/blob/main/tutorials/taggers/web_taggers/web_taggers.ipynb) -- veebipõhised tekstimärgendajad;\n",
    "    * [wordnet](https://github.com/estnltk/estnltk/blob/main/tutorials/wordnet/wordnet.ipynb) -- Eesti wordnet'i liides;\n",
    "    * [collocation_net](https://github.com/estnltk/estnltk/blob/main/tutorials/collocation_net/tutorial.ipynb)\n",
    "\n",
    "\n",
    "* Töö korpustega ( [corpus_processing](https://github.com/estnltk/estnltk/tree/main/tutorials/corpus_processing) ):\n",
    "\n",
    "    * Eelsõnestatud teksti sisselugemine: [restoring_pretokenized_text.ipynb](https://github.com/estnltk/estnltk/blob/main/tutorials/corpus_processing/restoring_pretokenized_text.ipynb) \n",
    "\n",
    "    * Andmete import suurkorpustest (Koondkorpus, etTenTen, ühendkorpus): [importing_text_objects_from_corpora.ipynb](https://github.com/estnltk/estnltk/blob/main/tutorials/corpus_processing/importing_text_objects_from_corpora.ipynb) \n",
    "\n",
    "\n",
    "* Erinevate formaatide lugemine/kirjutamine/teisendamine ( [converters](https://github.com/estnltk/estnltk/tree/main/tutorials/converters) ):\n",
    "\n",
    "    * CONLL formaadist importimine [converters/conll_importer.ipynb](https://github.com/estnltk/estnltk/blob/main/tutorials/converters/conll_importer.ipynb)\n",
    "    * _dict_ importimine/eksportimine [converters/dict_exporter_importer.ipynb](https://github.com/estnltk/estnltk/blob/main/tutorials/converters/dict_exporter_importer.ipynb) \n",
    "    * JSON importimine/eksportimine [converters/json_exporter_importer.ipynb](https://github.com/estnltk/estnltk/blob/main/tutorials/converters/json_exporter_importer.ipynb) \n",
    "    * TCF importimine/eksportimine [converters/TCF_exporter_importer.ipynb](https://github.com/estnltk/estnltk/blob/main/tutorials/converters/TCF_exporter_importer.ipynb) \n",
    "\n",
    "\n",
    "* Märgenduste visualiseerimine:\n",
    "    * https://github.com/estnltk/estnltk/tree/main/tutorials/visualisation\n",
    "\n",
    "\n",
    "* Postgres andmebaasiliidese kasutamine ( [storage](https://github.com/estnltk/estnltk/tree/main/tutorials/storage) ):\n",
    "    * _Text_ objektide salvestamine andmebaasi: [storage/storing_text_objects_in_postgres.ipynb](https://github.com/estnltk/estnltk/blob/main/tutorials/storage/storing_text_objects_in_postgres.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. `Layer` klass ja märgendajate (`Tagger` / `Retagger`) loomine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 `Layer` klass\n",
    "\n",
    "### 2.1.1 Oma märgenduskihi loomine: lihtne näide\n",
    "\n",
    "`Layer` klass sisaldab teksti märgenduskihti ja selle metaandmeid. Kasutaja poolt vaadatuna on tegemist märgenduste järjendiga. _Märgendus_ koosneb asukohamäärangust (`Span` või `EnvelopingSpan`) ning märgendusinfost (`Annotation` objekt(id)).\n",
    "\n",
    "Näide lihtkihi loomisest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>my_words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Tere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maailm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='my_words', attributes=(), spans=SL[Span('Tere', [{}]),\n",
       "Span('maailm', [{}])])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text, Layer\n",
    "\n",
    "text = Text('Tere, maailm!')\n",
    "\n",
    "# Loome uue lihtkihi ja seome selle tekstiga\n",
    "layer = Layer('my_words', text_object=text)\n",
    "\n",
    "# Lisame kihile märgendusi (asukohtade järgi)\n",
    "layer.add_annotation( (0, 4) )\n",
    "layer.add_annotation( (6, 12) )\n",
    "\n",
    "layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näha, saime tulemuseks ainult märgendatud tekstilõigud: mingeid atribuudiväärtustusi meie märgendused ei sisalda.\n",
    "Tehniliselt: kuna me kihi loomisel ei määranud kihile atribuute, siis meetod `add_annotation` tekitas märgendustesse ilma infosisuta `Annotation` objektid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eelmises näites tekitasime ühesuunalise seose `Layer`-i ja `Text`-i vahele: `Layer` teab oma `Text` objekti, aga `Text` veel kihti ei tunne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tere, maailm!</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tere, maailm!')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seega on meil tegemist eraldatud kihiga ( _detached layer_ ).\n",
    "Selleks, et **siduda kiht `Text` objektiga**, tuleb kasutada meetodit `add_layer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tere, maailm!</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>my_words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tere, maailm!')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Riputame kihi teksti külge\n",
    "text.add_layer( layer )\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Kihi metaandmed\n",
    "\n",
    "Sarnaselt `Text` objektile on ka märgenduskihi metaandmed sõnastikuna kättesaadavad ja muudetavad atribuudi `meta` kaudu. Näide:\n",
    "\n",
    "```python\n",
    "# metaandmete omistamine\n",
    "layer.meta['date_created'] = '2021-08-26'\n",
    "layer.meta['avg_word_len'] = 0.0\n",
    "```\n",
    "\n",
    "`meta` atribuudi võtmete alla talletatavad väärtused peaksid kasutama ainult andmetüüpe `str`, `int`, `float` ja `datetime`, kuna muude andmetüüpide puhul ei ole garanteeritud andmete serialiseeritavus / andmebaasi salvestatavus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Kihi loomisel muudetavad parameetrid\n",
    "\n",
    "`Layer` objekti loomisel saab täpsustada järgmised parameetrid:\n",
    "\n",
    " * `name` -- kihi nimi (sõne). Välistatud kihinimed: `text` ning kihinimed, mida kasutavad EstNLTK tööahela märgendajad (vt täpsemalt: _1.2.2. Millised kihte saab tag_layer abil tekitada? DEFAULT\\_RESOLVER_ );\n",
    " \n",
    " \n",
    " * `attributes` -- järjend kihi märgenduste atribuutide nimedega. Need atribuudid saavad olema kõigil kihi `Annotation` objektidel.  Välistatud atribuudinimed: `start`, `end` ja `text`;\n",
    "\n",
    "\n",
    " * `text_object` -- kihiga seotud `Text` objekt. Kui `Text` objekt on sidumata, pole võimalik uurida märgenduste tekstisisu (`text` ja `enclosing_text`);\n",
    " \n",
    " \n",
    " * `parent` -- ülemkihi nimi (sõne). Kui ülemkiht puudub (ning pole tegu ümbriskihiga), lisatakse märgendused otse algtekstile, aga ülemkihi olemasolul saab märgendusi lisada ainult ülemkihi märgendustega samadele asukohtadele;\n",
    " \n",
    " \n",
    " * `enveloping` -- ümbritsetava kihi nimi (sõne). Kui ümbritsetav kiht on määratud, siis tuleb märgenduste lisamisel täpsustada järjend ümbritsetava kihi märgenduste asukohtadest, mida antud kiht katab;\n",
    " \n",
    " \n",
    " * `ambiguous` -- kas kiht on mitmene (tõeväärtus). Kui kiht on mitmene, siis saab ühe asukohaga siduda mitu `Annotation` objekti;\n",
    " \n",
    " \n",
    " * `default_values` -- märgenduse atribuutide väikeväärtused (sõnastik).\n",
    " \n",
    " \n",
    " * `secondary_attributes` -- järjend kihi atribuutidest, mida ei arvestata kihtide/märgenduste võrdlemisel. `secondary_attributes` peab olema `attributes` alamosa.\n",
    " \n",
    " Allpool toome detailsemad näited eri tüüpi kihtide loomisest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Eri tüüpi kihtide loomine (näited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lihtkiht koos atribuutidega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words_with_translations</td>\n",
       "      <td>fin, eng</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>fin</th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Tere</td>\n",
       "      <td>Hei</td>\n",
       "      <td>Hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maailm</td>\n",
       "      <td>maailma</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words_with_translations', attributes=('fin', 'eng'), spans=SL[Span('Tere', [{'fin': 'Hei', 'eng': 'Hello'}]),\n",
       "Span('maailm', [{'fin': 'maailma', 'eng': 'World'}])])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Näidistekst\n",
    "text = Text('Tere, maailm!')\n",
    "\n",
    "# Loome kahe atribuudiga kihi\n",
    "layer = Layer(name='words_with_translations',\n",
    "              text_object=text,\n",
    "              attributes=['fin', 'eng'] )\n",
    "\n",
    "# Lisame kihile märgendusi:\n",
    "# 1) atribuutide määramine parameetritena\n",
    "layer.add_annotation( (0, 4), fin='Hei', eng='Hello' )\n",
    "# 2) atribuutide etteandmine sõnastikuna\n",
    "layer.add_annotation( (6, 12), {'fin':'maailma', 'eng':'World'} )\n",
    "\n",
    "# Seome kihi teksti külge\n",
    "text.add_layer( layer )\n",
    "\n",
    "text.words_with_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>fin</th>\n",
       "      <th>eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Tere</span></span></td>\n",
       "      <td>Hei</td>\n",
       "      <td>Hello</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('Tere', [{'fin': 'Hei', 'eng': 'Hello'}])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lihtkiht koosneb Span-idest, millel mitmesusi pole\n",
    "text.words_with_translations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mitmene kiht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words_with_translations</td>\n",
       "      <td>translated_text, lang</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Tere</td>\n",
       "      <td>Hei</td>\n",
       "      <td>fin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Hello</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maailm</td>\n",
       "      <td>maailma</td>\n",
       "      <td>fin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>World</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words_with_translations', attributes=('translated_text', 'lang'), spans=SL[Span('Tere', [{'translated_text': 'Hei', 'lang': 'fin'}, {'translated_text': 'Hello', 'lang': 'eng'}]),\n",
       "Span('maailm', [{'translated_text': 'maailma', 'lang': 'fin'}, {'translated_text': 'World', 'lang': 'eng'}])])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Näidistekst\n",
    "text = Text('Tere, maailm!')\n",
    "\n",
    "# Loome kahe atribuudiga kihi\n",
    "layer = Layer(name='words_with_translations',\n",
    "              text_object=text,\n",
    "              attributes=['translated_text', 'lang'],\n",
    "              ambiguous=True)\n",
    "\n",
    "# Lisame kihile märgendusi (asukoht + atribuudiväärtustused)\n",
    "# 1) atribuutide määramine parameetritena\n",
    "layer.add_annotation( (0, 4), translated_text='Hei', lang='fin' )\n",
    "layer.add_annotation( (0, 4), translated_text='Hello', lang='eng' )\n",
    "# 2) atribuutide etteandmine sõnastikuna\n",
    "layer.add_annotation( (6, 12), {'translated_text':'maailma', 'lang':'fin'} )\n",
    "layer.add_annotation( (6, 12), {'translated_text':'World', 'lang':'eng'} )\n",
    "\n",
    "# Seome kihi teksti külge\n",
    "text.add_layer( layer )\n",
    "\n",
    "text.words_with_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Tere</span></span></td>\n",
       "      <td>Hei</td>\n",
       "      <td>fin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Hello</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('Tere', [{'translated_text': 'Hei', 'lang': 'fin'}, {'translated_text': 'Hello', 'lang': 'eng'}])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mitmese kihi Span-idel on mitu tõlgendust\n",
    "text.words_with_translations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mitmene alamkiht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words_with_translations</td>\n",
       "      <td>translated_text, lang</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Tere</td>\n",
       "      <td>Hei</td>\n",
       "      <td>fin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Hello</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maailm</td>\n",
       "      <td>maailma</td>\n",
       "      <td>fin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>World</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words_with_translations', attributes=('translated_text', 'lang'), spans=SL[Span('Tere', [{'translated_text': 'Hei', 'lang': 'fin'}, {'translated_text': 'Hello', 'lang': 'eng'}]),\n",
       "Span('maailm', [{'translated_text': 'maailma', 'lang': 'fin'}, {'translated_text': 'World', 'lang': 'eng'}])])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text, Layer\n",
    "\n",
    "# Näidistekst koos sõnade märgenduskihiga\n",
    "text = Text('Tere, maailm!').tag_layer('words')\n",
    "\n",
    "# Loome kahe atribuudiga sõnade kihi alamkihi\n",
    "layer = Layer(name='words_with_translations',\n",
    "              text_object=text,\n",
    "              attributes=['translated_text', 'lang'],\n",
    "              parent='words',\n",
    "              ambiguous=True)\n",
    "\n",
    "for word in text.words:\n",
    "    # Lisame märgenduse, mis baseerub ülemkihi base_span-il (asukohal)\n",
    "    if (word.start, word.end) == (0, 4):  # 'Tere' asukoht\n",
    "        # 1) märgenduse atribuutide määramine parameetritena\n",
    "        layer.add_annotation( word.base_span, translated_text='Hei', lang='fin' )\n",
    "        layer.add_annotation( word.base_span, translated_text='Hello', lang='eng' )\n",
    "    \n",
    "    if (word.start, word.end) == (6, 12):  # 'maailm' asukoht\n",
    "        # 2) märgenduse atribuutide etteandmine sõnastikuna\n",
    "        layer.add_annotation( word.base_span, {'translated_text':'maailma', 'lang':'fin'} )\n",
    "        layer.add_annotation( word.base_span, {'translated_text':'World', 'lang':'eng'} )\n",
    "\n",
    "# Seome kihi teksti külge\n",
    "text.add_layer( layer )\n",
    "\n",
    "text['words_with_translations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Tere</span></span></td>\n",
       "      <td>Hei</td>\n",
       "      <td>fin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Hello</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('Tere', [{'translated_text': 'Hei', 'lang': 'fin'}, {'translated_text': 'Hello', 'lang': 'eng'}])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alamkihi Span\n",
    "text.words_with_translations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Tere</span></span></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('Tere', [{'normalized_form': None}])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alamkihi igal Span-il on olemas ülemus\n",
    "text.words_with_translations[0].parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ümbriskiht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>phrase_translations</td>\n",
       "      <td>translated_text, lang</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Tere', ',', 'maailm', '!']</td>\n",
       "      <td>Hello, World!</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Kuidas', 'läheb', '?']</td>\n",
       "      <td>How are you?</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='phrase_translations', attributes=('translated_text', 'lang'), spans=SL[EnvelopingSpan(['Tere', ',', 'maailm', '!'], [{'translated_text': 'Hello, World!', 'lang': 'eng'}]),\n",
       "EnvelopingSpan(['Kuidas', 'läheb', '?'], [{'translated_text': 'How are you?', 'lang': 'eng'}])])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text, Layer\n",
    "\n",
    "# Näidistekst koos sõnade märgenduskihiga\n",
    "text = Text('Tere, maailm! Kuidas läheb?').tag_layer('words')\n",
    "\n",
    "# Loome kahe atribuudiga sõnade kihti ümbritseva kihi\n",
    "layer = Layer(name='phrase_translations',\n",
    "              text_object=text,\n",
    "              attributes=['translated_text', 'lang'],\n",
    "              enveloping='words')\n",
    "\n",
    "# Lisame esimest 4 sõna katva märgenduse\n",
    "layer.add_annotation( [s.base_span for s in text.words[0:4]], \\\n",
    "                      translated_text='Hello, World!', lang='eng' )\n",
    "\n",
    "# Lisame viimast 3 sõna katva märgenduse\n",
    "layer.add_annotation( [text.words[4].base_span, text.words[5].base_span, text.words[6].base_span], \\\n",
    "                      { 'translated_text': 'How are you?', 'lang': 'eng' } )\n",
    "\n",
    "# Seome kihi teksti külge\n",
    "text.add_layer( layer )\n",
    "\n",
    "text.phrase_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>EnvelopingSpan</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Tere</span><span style=\"text-decoration: underline;\">,</span> <span style=\"text-decoration: underline;\">maailm</span><span style=\"text-decoration: underline;\">!</span></span></td>\n",
       "      <td>Hello, World!</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "EnvelopingSpan(['Tere', ',', 'maailm', '!'], [{'translated_text': 'Hello, World!', 'lang': 'eng'}])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ümbriskiht koosneb EnvelopingSpan-idest\n",
    "text.phrase_translations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 Märgenduskihtide loomise kohta vt veel:\n",
    "    https://github.com/estnltk/estnltk/blob/main/tutorials/system/low_level_layer_operations.ipynb\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Kokkuvõtvalt: kihi märgenduste lisamine, muutmine ja eemaldamine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Layer` võimaldab:\n",
    "\n",
    "  1. lisada märgendusi: \n",
    "     * `layer.add_annotation( base_span )` (ilma atribuutideta kihi korral)\n",
    "     * `layer.add_annotation( base_span, **keyword_attributes )`\n",
    "     * `layer.add_annotation( base_span, attributes_dict )`\n",
    "  2. kustutada märgendusi: \n",
    "     * `layer.remove_span( span: Span )` (objekti järgi)\n",
    "     * `del layer[i]` (indeksi järgi) \n",
    "  3. muuta märgendusi:\n",
    "     * `layer[i].annotations[j][attr_k] = ...` (indeksite järgi) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<h4><i>Disainipõhimõte: märgendusi tekitavad ja muudavad märgendajad</i></h4> \n",
    "<br>\n",
    "EstNLTK järgib disainipõhimõtet, et märgenduskihtide loomine ja muutmine toimub märgendajate sees. \n",
    "See tagab, et loodavad kihid on valiidse struktuuriga, kuna märgendajate sees toimub kihtide järelkontroll.\n",
    "Märgendajate loomise ja kasutamise kohta vt detailsemalt ptk 2.2.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<h4><i>Märgenduste lisamise ja muutmine <code>Span</code> / <code>EnvelopingSpan</code> abil</i></h4> \n",
    "<br>\n",
    "Märgendusi on võimalik muuta ja lisada ka <code>Span</code> ja <code>EnvelopingSpan</code> objektidega opereerides, aga see on veidi keerukam ning uut kihti luues tasub jääda <code>Layer</code>-i poolt pakutava liidese juurde.\n",
    "Kui on aga vaja tekitada kihti muutev <code>Retagger</code>, võib lisateadmine <code>Span</code> ja <code>EnvelopingSpan</code> liidesest olla kasulik. Nimelt, olemasoleva kihi märgendusi saab muuta <code>Span</code> ja <code>EnvelopingSpan</code> kaudu järgmiselt:\n",
    "<ol>\n",
    "    <li>eemalda (kõik) märgendused: <code>span.clear_annotations()</code>;</li>\n",
    "    <li>lisa uus märgendus: <code>span.add_annotation( annotation_dict )</code>;</li>\n",
    "    <li>muuda <code>i</code>-nda märgenduse <code>attr_j</code> väärtust: <code>span.annotations[i][attr_j] = ...</code>;</li>\n",
    "</ol>\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<h4><i>Märgenduste lisamise, muutmise ja eemaldamise reeglid</i></h4> \n",
    "<br>\n",
    "<ul>\n",
    "    <li>Kihil ei tohi olla mitut täpselt ühesuguse asukoha ehk <code>Span-iga</code> (<code>EnvelopingSpan</code>-iga) märgendust (aga osaliselt kattuva asukohaga märgendused on lubatud);</li>\n",
    "    <li>Iga kihil olev <code>Span</code> / <code>EnvelopingSpan</code> peab sisaldama vähemalt üht <code>Annotation</code> objekti (kuigi see võib olla ka tühi, nagu sõnestusmärgenduse puhul);</li>\n",
    "    <li>Mistahes liiki kihile ei saa lisada mitut täpselt samade atribuudiväärtustega <code>Annotation</code>-it -- duplikaatide puhul jäetakse alles vaid üks <code>Annotation</code>;</li>\n",
    "</ul>\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.6 Kihtidevaheliste sõltuvuste muutmine ( `flatten` ja `rebase` )\n",
    "\n",
    "Funktsioon `flatten` nullib kihi sõltuvused ja **teeb kihist mitmese lihtkihi** (ehk siis kihi, mis pole ümbriskiht ega alamkiht):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>flat_sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Tere, maailm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kuidas läheb?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='flat_sentences', attributes=(), spans=SL[Span('Tere, maailm!', [{}]),\n",
       "Span('Kuidas läheb?', [{}])])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk_core.layer_operations import flatten\n",
    "\n",
    "# Lisame lausete märgenduskihi\n",
    "text = Text('Tere, maailm! Kuidas läheb?').tag_layer('sentences')\n",
    "# Tekitame lausete kihist lihtkihi\n",
    "flat_sentences = flatten(text['sentences'], 'flat_sentences')\n",
    "# Lisame tekstile lausete lihtkihi\n",
    "text.add_layer( flat_sentences )\n",
    "text.flat_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kuna algne lausete kiht on sõltuv sõnade kihist, siis sõnade kihi eemaldamisel kaob ka lausete kiht.\n",
    "Lausete kihist tehtud lihtkiht jääb aga alles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tere, maailm! Kuidas läheb?</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>flat_sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tere, maailm! Kuidas läheb?')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.pop_layer( 'words' )\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktsioon `rebase` **tõstab alamkihi sõltuvuse ümber** ühelt ülemkihilt teisele. Näiteks, kiht `'morph_analysis'` sõltub `'words'` kihist ja kiht `'gt_morph_analysis'` omakorda `'morph_analysis'` kihist, seega saame kihi `'gt_morph_analysis'` sõltuvuse tõsta ümber `'words'` kihile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tere, maailm! Kuidas läheb?</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gt_morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tere, maailm! Kuidas läheb?')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk_core.layer_operations import rebase\n",
    "from estnltk.taggers import GTMorphConverter\n",
    "\n",
    "# Lisame tekstile morfoloogilise märgenduse ja osalaused\n",
    "text = Text('Tere, maailm! Kuidas läheb?').tag_layer(['morph_analysis', 'clauses'])\n",
    "# Lisame GT kategooriatega morf märgenduse\n",
    "GTMorphConverter().tag(text)\n",
    "\n",
    "# Teeme 'gt_morph_analysis' sõltuvuse ümber 'words' kihi peale\n",
    "rebase(text, 'gt_morph_analysis', 'words')\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misjärel saab ülemkihi `'morph_analysis'` üldse eemaldada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tere, maailm! Kuidas läheb?</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gt_morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tere, maailm! Kuidas läheb?')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.pop_layer( 'morph_analysis' )\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'gt_morph_analysis'` kiht jäi alles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 Rohkem infot/näiteid `flatten` ja `rebase` kohta leiab siit: https://github.com/estnltk/estnltk/blob/main/tutorials/system/layer_operations.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Märgendajad / Ümbermärgendajad\n",
    "\n",
    "### 2.2.1 `Tagger` (kihi looja)\n",
    "\n",
    "Märgendaja abil luuakse uusi kihte. \n",
    "Märgendaja tegemine samm-haaval:\n",
    "  1. Loo `estnltk.taggers.Tagger` klassi alamklass;\n",
    "  2. Lisa kõik märgendaja konfiguratsiooni parameetrid klassimuutujasse `conf_param` (muutuja tüüp `Sequence[str]`);  \n",
    "        Ainult selles loendis olevaid parameetreid tohib märgendaja alla salvestada. Kui parameetri nime ees on alakriips (`_`), siis loetakse see sisemiseks parameetriks ning märgendaja konfiguratsiooni kuvamisel seda ei näidata;\n",
    "  3. Lisa väljundkihi nimi klassimuutujasse `output_layer`(tüüp `str`);\n",
    "  4. Lisa kõik väljundkihi atribuutide nimed muutujasse `output_attributes`(tüüp `Sequence[str]`);\n",
    "  5. Lisa kõik kihid, mida on vaja väljundkihi loomiseks, muutujasse `input_layers`(tüüp `Sequence[str]`);\n",
    "  6. Loo konstruktor `__init__`, kus pannakse lõplikult paika parameetrite `conf_param`, `output_layer`, `output_attributes`,  `input_layers` ning teiste konfiguratsiooniparameetrite väärtused.\n",
    "       Märgendaja konfiguratsioon peaks olema täielikult määratud konstruktoris, väljaspool konstruktorit selle muutmist toimuda ei tohiks. (Kui kasutajal on vaja muuta konfiguratsiooni, peaks ta tekitada uue märgendaja uue konfiguratsiooniga);\n",
    "  7. Loo meetod `_make_layer_template(self) -> Layer`, mis tekitab tühja eraldatud kihi, kus on kõik kihi atribuudid seadistatud vastavalt märgendaja konfiguratsioonile;\n",
    "  8. Loo meetod `_make_layer(self, raw_text: str, layers: Mapping[str, Layer], status: dict=None) -> Layer`, milles tekitatakse  uus `Layer` objekt (soovitatavalt `_make_layer_template()` abil), täidetakse see andmetega ning tagastatakse;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lihtsustatud näide: loome märgendaja, mis märgendab toiduretseptides koguseid (nt _1 tl_ , _200 g_ , _2 dl_ ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text, Layer\n",
    "from estnltk.taggers import Tagger\n",
    "\n",
    "class QuantityTokensTagger(Tagger):\n",
    "    \"\"\"Tags tokens that make up quantity expressions.\"\"\" \n",
    "    conf_param = ['quantity_lemmas']\n",
    "    \n",
    "    def __init__(self, # output_layer name can be changed:\n",
    "                       output_layer='quantity_tokens',\n",
    "                       # input layer name can be changed:\n",
    "                       input_morph_analysis_layer='morph_analysis',\n",
    "                       # quantity lemmas can be changed:\n",
    "                       quantity_lemmas=['tk', 'tl', 'dl', 'kg', 'g']):\n",
    "        # Set input/output layers\n",
    "        self.input_layers = [input_morph_analysis_layer]\n",
    "        self.output_layer = output_layer\n",
    "        self.output_attributes = ['token_type']\n",
    "        # Set other configuration parameters\n",
    "        self.quantity_lemmas = set(quantity_lemmas)\n",
    "\n",
    "    def _make_layer_template(self):\n",
    "        # Create new detached layer debased on the configuration\n",
    "        return Layer(name=self.output_layer, attributes=self.output_attributes, text_object=None)\n",
    "        \n",
    "    def _make_layer(self, text, layers, status):\n",
    "        # Create new layer based on the configuration\n",
    "        layer = self._make_layer_template()\n",
    "        # Assign the Text object\n",
    "        layer.text_object = text\n",
    "        for span in layers[ self.input_layers[0] ]: # Iterate over 'morph_analysis' (first input layer)\n",
    "            for annotation in span.annotations:\n",
    "                if annotation['lemma'] in self.quantity_lemmas:\n",
    "                    # Mark units\n",
    "                    layer.add_annotation(span.base_span, token_type='UNIT')\n",
    "                    break\n",
    "                if annotation['lemma'].replace('.','',1).isdigit():\n",
    "                    # Mark numbers\n",
    "                    layer.add_annotation(span.base_span, token_type='NUMBER')\n",
    "                    break\n",
    "        # Return created layer\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testime märgendajat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags tokens that make up quantity expressions.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>QuantityTokensTagger</td>\n",
       "      <td>quantity_tokens</td>\n",
       "      <td>('token_type',)</td>\n",
       "      <td>('morph_analysis',)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>quantity_lemmas</th>\n",
       "      <td>{'tk', 'dl', 'g', 'kg', 'tl'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "QuantityTokensTagger(input_layers=('morph_analysis',), output_layer=quantity_tokens, output_attributes=('token_type',), quantity_lemmas={'tk', 'dl', 'g', 'kg', 'tl'})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantities_tagger = QuantityTokensTagger()\n",
    "quantities_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var elements = document.getElementsByClassName(\"overlapping-span\")\n",
       "for (let i = 0; i < elements.length; i++){\n",
       "    elements.item(i).addEventListener(\"click\",function() {show_conflicting_spans(elements.item(i));})}\n",
       "\n",
       "function show_conflicting_spans(span_element) {\n",
       "    let spantable = document.createElement('div')\n",
       "    spantable.classList.add('tables')\n",
       "\n",
       "    // Prepare the contents of the span table\n",
       "    data = span_element.getAttribute(\"span_info\")\n",
       "    data = data.split(\",\")\n",
       "    var spancontent = '<table>'\n",
       "    for (let row of data) {\n",
       "        spancontent+='<tr><td>'\n",
       "        spancontent+=row\n",
       "        spancontent+='</td></tr>'\n",
       "    }\n",
       "    spancontent += '</table>'\n",
       "    spantable.innerHTML = spancontent\n",
       "    span_element.parentElement.appendChild(spantable)\n",
       "\n",
       "    // Increase the size of the cell so the tables would fit\n",
       "    spantable.parentElement.style.height = Math.max(Number(spantable.parentElement.style.height.substring(0,spantable.parentElement.style.height.length-2)),span_element.offsetTop+90)+ 'px'\n",
       "    // Position the table directly below the corresponding text\n",
       "    spantable.style.left = span_element.getBoundingClientRect().left-spantable.parentElement.parentElement.getBoundingClientRect().left + 'px'\n",
       "    spantable.style.top = span_element.getBoundingClientRect().top-spantable.parentElement.parentElement.getBoundingClientRect().top+20+ 'px'\n",
       "\n",
       "    // Remove the table when clicked on again\n",
       "    spantable.addEventListener('click', function () {\n",
       "        let element = this.parentElement\n",
       "        element.removeChild(this)\n",
       "    })\n",
       "}\n",
       "</script><style>\n",
       ".span {\n",
       "    background-color: yellow;\n",
       "}\n",
       "\n",
       ".overlapping-span {\n",
       "    background-color: red;\n",
       "}\n",
       "\n",
       ".spanline {\n",
       "    background-color: blue;\n",
       "    position: relative;\n",
       "    height: 3px;\n",
       "    margin-left: 0px;\n",
       "}\n",
       "\n",
       ".tables {\n",
       "    position: absolute;\n",
       "    width: fit-content;\n",
       "    width: -moz-fit-content;\n",
       "    border: 1px solid black;\n",
       "}\n",
       "\n",
       ".maintext{0} {\n",
       "    position: relative;\n",
       "}\n",
       "\n",
       ".tables tbody tr:nth-child(even) {\n",
       "    background-color: lightgray;\n",
       "}\n",
       "\n",
       ".tables tbody tr:nth-child(odd) {\n",
       "    background-color: beige;\n",
       "}\n",
       "\n",
       ".tables tbody tr:hover {\n",
       "    background-color: ivory;\n",
       "}\n",
       "</style><br><span style=background:yellow; \">200</span> <span style=background:yellow; \">g</span> tumedat 70% šokolaadi (Fairtrade)<br><span style=background:yellow; \">200</span> <span style=background:yellow; \">g</span> võid<br><span style=background:yellow; \">100</span> <span style=background:yellow; \">g</span> hakitud kreeka pähkleid<br><span style=background:yellow; \">0.5</span> <span style=background:yellow; \">tl</span> soola<br><span style=background:yellow; \">0.5</span> <span style=background:yellow; \">tl</span> vanilliekstrakti<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>quantity_tokens</td>\n",
       "      <td>token_type</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>token_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>g</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>g</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>g</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tl</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.5</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tl</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='quantity_tokens', attributes=('token_type',), spans=SL[Span('200', [{'token_type': 'NUMBER'}]),\n",
       "Span('g', [{'token_type': 'UNIT'}]),\n",
       "Span('200', [{'token_type': 'NUMBER'}]),\n",
       "Span('g', [{'token_type': 'UNIT'}]),\n",
       "Span('100', [{'token_type': 'NUMBER'}]),\n",
       "Span('g', [{'token_type': 'UNIT'}]),\n",
       "Span('0.5', [{'token_type': 'NUMBER'}]),\n",
       "Span('tl', [{'token_type': 'UNIT'}]),\n",
       "Span('0.5', [{'token_type': 'NUMBER'}]),\n",
       "Span('tl', [{'token_type': 'UNIT'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loome näidisteksti koos vajaminevate sisendkihtidega\n",
    "text = Text('''\n",
    "200 g tumedat 70% šokolaadi (Fairtrade)\n",
    "200 g võid\n",
    "100 g hakitud kreeka pähkleid\n",
    "0.5 tl soola\n",
    "0.5 tl vanilliekstrakti\n",
    "''')\n",
    "text.tag_layer('morph_analysis')\n",
    "\n",
    "# Rakendame märgendajat\n",
    "quantities_tagger.tag( text )\n",
    "\n",
    "# Visualiseerime tulemused\n",
    "text.quantity_tokens.display()\n",
    "display( text.quantity_tokens )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<h4><i>Rohkem detaile</i></h4> \n",
    "<br>\n",
    "<ul>\n",
    "    <li>Sisuliselt on <code>Tagger</code>-il neli meetodit, mis haldavad kihi loomist:\n",
    "        <ul>\n",
    "            <li><code>tag(text: Text, status: dict)</code> -- luuakse ja lisatakse kiht etteantud <code>Text</code> objektile. Lõppkasutajale mõeldud meetod, mida märgendajate arendajad reeglina muuta / üle kirjutada ei tohiks;</li>\n",
    "            <li><code>make_layer(text: Text, layers: MutableMapping[str, Layer], status: dict)</code> -- luuakse ja tagastatakse loodud kiht ilma seda <code>Text</code> objektiga sidumata. Vajalik Postgres andmebaasiliidesele: meetodi abil saab tekitada eraldatud kihi (<i>detached layer</i>), mis on andmebaasis <code>Text</code> objektist eraldi. Märgendajate arendajad reeglina seda meetodit muuta / üle kirjutada ei tohiks;</li>\n",
    "            <li><code>_make_layer(text: Text, layers: MutableMapping[str, Layer] = None, status: dict = None)</code> -- märgenduskihi loomine ja tagastamine. Märgendajate arendajad peaksid implementeerima selle meetodi;</li>\n",
    "            <li><code>_make_layer_template()</code> -- konfiguratsioonile vastava tühja märgenduskihi loomine ja tagastamine. Reeglina peaks meetod <code>_make_layer()</code> teostama kihi loomist meetodi <code>_make_layer_template()</code> abil, seega tuleb ka see meetod arendajatel implementeerida;</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><i>Kihi loomise staatus</i>: kihi loomise meetoditele saab parameetriks anda sõnastiku <code>status</code>, kuhu märgendaja võib sõnumeid salvestada (nt selle kohta, kas kihi loomine õnnestus);</li>\n",
    "    <li><i>Valideerimine</i>: meetodis <code>make_layer(...)</code> toimub märgendaja sisendi- ja väljundi valideerimine. Enne kihi loomist kontrollitakse, et on olemas kõik vajalikud sisendkihid (<code>input_layers</code>) ning pärast kihi loomist kontrollitakse, et väljundkiht (<code>output_layer</code>) on olemas ning et kõigil märgendustel on väljundatribuudid (<code>output_attributes</code>);</li>\n",
    "    <li><i>Muudetavad kihtide nimed</i>: on soovitatav, et sisend- ja väljundkihtide nimed oleksid märgendajas muudetavad: 1) konstruktori parameetrite abil peaks olema võimalik muuta <code>input_layers</code> ja <code>output_layer</code> väärtuseid; 2) meetodis <code>_make_layer(...)</code> peaks eksplitsiitsete kihinimede asemel kasutada kihinimede muutujaid  <code>input_layers</code> ja <code>output_layer</code>. Kui kihinimed on muudetavad, on võimalik võrrelda märgendaja eri versioonide väljundeid;</li>\n",
    "</ul>\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 Märgendaja loomise kohta vt veel: https://github.com/estnltk/estnltk/blob/main/tutorials/taggers/base_tagger.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 `Retagger` (kihi muutja)\n",
    "\n",
    "Ümbermärgendaja muudab / parandab olemasolevat kihti.\n",
    "Ümbermärgendaja on `Retagger` klassi alamklass, millel on määratud atribuudid:\n",
    "\n",
    "   * `conf_param` -- list legaalsetest parameetrinimedest (sõnede list);\n",
    "   * `output_layer` -- muudetava kihi nimi (sõne);\n",
    "   * `output_attributes` -- list muudetava kihi atribuutide nimedega (sõnede list);\n",
    "   * `input_layers` -- list muutmiseks vajalikest sisendkihtidest (sõnede list); NB! peaks sisaldama ka kihti `output_layer`;\n",
    "\n",
    "ning implementeeritud meetodid:\n",
    "\n",
    "   * `__init__` -- konstruktor, kus pannakse lõplikult paika parameetrite `conf_param`, `output_layer`, `output_attributes`,  `input_layers` ning teiste legaalsete parameetrite väärtused, mis moodustavad konfiguratsiooni;\n",
    "   * `_change_layer(...)` -- meetod, mis muudab (vastavalt märgendaja konfiguratsioonile) kihti `output_layer` ning ei tagasta midagi;\n",
    "\n",
    "`Retagger`-i ülesehitus on suuresti analoogne `Tagger`-i omale. \n",
    "Ka `Retagger`-is haldavad kihi muutmist 3 meetodit: `_change_layer(...)` (kihi muutmise loogika implementatsioon), `change_layer(...)` (andmebaasiliidese jaoks vajalik meetod) ning  `retag(...)` (lõppkasutajale mõeldud meetod).\n",
    "Ent Erinevalt `Tagger`-ist tühja kihi loomise meetodit siin implementeerima ei pea. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lihtsustatud näide ümbermärgendajast: sõnade normaliseerija, mis lisab spetsiifilistele vana kirjakeele sõnadele ( nt _om_ ja _ehitet_ ) normaliseeritud vormid ning märgib iga sõna puhul ära, kas see sai normaliseeritud või mitte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text, Layer\n",
    "from estnltk.taggers import Retagger\n",
    "\n",
    "class DummyWordNormalizer( Retagger ):\n",
    "    \"\"\"A dummy word normalizer that can normalize only some specific words of Old Estonian.\"\"\" \n",
    "    conf_param = ['lexicon']\n",
    "    \n",
    "    def __init__(self, # Name of the layer can be changed:\n",
    "                       output_layer = 'words'):\n",
    "        # Set input/output layers\n",
    "        self.input_layers = [output_layer]\n",
    "        self.output_layer = output_layer\n",
    "        self.output_attributes = ['normalized_form', 'is_normalized']\n",
    "        # Set other configuration parameters\n",
    "        self.lexicon = {'metsawahi':'metsavahi', 'ehitet':'ehitatud', 'om':'on'}\n",
    "    \n",
    "    def _change_layer(self, text, layers, status):\n",
    "        # Get changeble layer\n",
    "        changeble_layer = layers[self.output_layer]\n",
    "        # Add new attribute to the layer\n",
    "        changeble_layer.attributes += (self.output_attributes[-1], )\n",
    "        # Iterate over words and add new normalizations\n",
    "        for span in changeble_layer:\n",
    "            # Get current normalized forms of the word\n",
    "            current_norm_forms = [a['normalized_form'] for a in span.annotations]\n",
    "            if current_norm_forms == [None]:\n",
    "                current_norm_forms = [span.text]\n",
    "            # Try to replace current normalized forms with forms from the lexicon\n",
    "            new_forms = []\n",
    "            change_status = []\n",
    "            for cur_form in current_norm_forms:\n",
    "                if cur_form.lower() in self.lexicon:\n",
    "                    new_forms.append(self.lexicon[cur_form.lower()])\n",
    "                    change_status.append(True)\n",
    "                else:\n",
    "                    new_forms.append(cur_form)\n",
    "                    change_status.append(False)\n",
    "            # Clear existing annotations and add new ones that have 1 extra attribute\n",
    "            span.clear_annotations()\n",
    "            for form_id, new_form in enumerate( new_forms ):\n",
    "                span.add_annotation( {'normalized_form': new_form, \n",
    "                                      'is_normalized' : change_status[form_id] } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testime ümbermärgendajat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>DummyWordNormalizer(Retagger)</h4>\n",
       "A dummy word normalizer that can normalize only some specific words of Old Estonian.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>DummyWordNormalizer</td>\n",
       "      <td>words</td>\n",
       "      <td>('normalized_form', 'is_normalized')</td>\n",
       "      <td>('words',)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lexicon</th>\n",
       "      <td>{'metsawahi': 'metsavahi', 'ehitet': 'ehitatud', 'om': 'on'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DummyWordNormalizer(lexicon={'metsawahi': 'metsavahi', 'ehitet': 'ehitatud', 'om': 'on'})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_normalizer = DummyWordNormalizer()\n",
    "word_normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Metsawahi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hobusele</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>om</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uus</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laut</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ehitet</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Metsawahi', [{'normalized_form': None}]),\n",
       "Span('hobusele', [{'normalized_form': None}]),\n",
       "Span('om', [{'normalized_form': None}]),\n",
       "Span('uus', [{'normalized_form': None}]),\n",
       "Span('laut', [{'normalized_form': None}]),\n",
       "Span('ehitet', [{'normalized_form': None}]),\n",
       "Span('.', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loome näidisteksti koos vajaminevate sisendkihtidega\n",
    "from estnltk import Text\n",
    "text = Text('Metsawahi hobusele om uus laut ehitet.')\n",
    "text.tag_layer('words')\n",
    "# Kuvame vana kihi\n",
    "text.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form, is_normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "      <th>is_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Metsawahi</td>\n",
       "      <td>metsavahi</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hobusele</td>\n",
       "      <td>hobusele</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>om</td>\n",
       "      <td>on</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laut</td>\n",
       "      <td>laut</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ehitet</td>\n",
       "      <td>ehitatud</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form', 'is_normalized'), spans=SL[Span('Metsawahi', [{'normalized_form': 'metsavahi', 'is_normalized': True}]),\n",
       "Span('hobusele', [{'normalized_form': 'hobusele', 'is_normalized': False}]),\n",
       "Span('om', [{'normalized_form': 'on', 'is_normalized': True}]),\n",
       "Span('uus', [{'normalized_form': 'uus', 'is_normalized': False}]),\n",
       "Span('laut', [{'normalized_form': 'laut', 'is_normalized': False}]),\n",
       "Span('ehitet', [{'normalized_form': 'ehitatud', 'is_normalized': True}]),\n",
       "Span('.', [{'normalized_form': '.', 'is_normalized': False}])])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rakendame ümbermärgendajat\n",
    "word_normalizer.retag(text)\n",
    "\n",
    "# Kuvame muudetud kihi\n",
    "text.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 Ümbermärgendaja loomise kohta vt veel: https://github.com/estnltk/estnltk/blob/main/tutorials/taggers/base_tagger.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
