{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue\"> Lisamaterjal: verbiahelate tuvastamine. Andmete serialiseerimine </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See lisamaterjal käsitleb üht uut keeletöötluse teemat ning üht \"tehnilist\" Pythoni teemat.\n",
    "Keeletöötluse teemaks on _verbiahelate tuvastamine_ , mis võimaldab uurida tekstis olevaid väiteid (nt eristada jaatavaid väiteid eitavatest ja kindlaid väiteid võimalikest).\n",
    "Tehniline teema on aga _serialiseerimine_ , mis võimaldab Pythoni mälus olevaid andmeid (sh objekte) otse faili salvestada ning pärast ka taastada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbiahelate tuvastamine\n",
    "\n",
    "Kui lause eesmärgiks on mingi väite väljendamine, siis selle väite _faktilisust_ / _modaalsust_ mõjutab sageli see, milline on väidet väljendav _verbiahel_ . \n",
    "Näiteks, verbiahelaid uurides võib eristada jaatavaid väiteid eitavatest (nt \"Peaminister **astub** homme tagasi\" vs \"Peaminister eile siiski tagasi **ei astunud**\"), kindlaid väiteid võimalikest (nt \"Ta **tuleb** homme\" vs \"Ta **võib tulla** homme\") ning kindlaid tegevusi soovidest / plaanidest / üritamistest jms (nt \"Juku **alustas** kodutööga\" vs \"Juku **kavatseb** kodutööga **alustada**\", '\"Juku **tahab** kodutööd **alustada**\", \"Juku kinnitusel **on võimalik** kodutööd **alustada**\"). \n",
    "Verbiahelate tuvastaja leiabki verbidega seotud ühe- ja mitmesõnalisi üksuseid, millele toetudes saab üles ehitada lause _faktilisuse_ / _modaalsuse_ automaatse analüüsi.\n",
    "\n",
    "Näide verbiahelate tuvastaja importimisest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags main verbs and their extensions (verb chains) in clauses. ( v1.4.1 )\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>VerbChainDetector</td>\n",
       "      <td>verb_chains</td>\n",
       "      <td>('pattern', 'roots', 'word_ids', 'mood', 'polarity', 'tense', 'voice', 'remaining_verbs')</td>\n",
       "      <td>('words', 'sentences', 'morph_analysis', 'clauses')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>add_morph_attr</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>add_analysis_ids_attr</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expand2ndTime</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakOnPunctuation</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>removeSingleAraEi</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "VerbChainDetector(input_layers=('words', 'sentences', 'morph_analysis', 'clauses'), output_layer=verb_chains, output_attributes=('pattern', 'roots', 'word_ids', 'mood', 'polarity', 'tense', 'voice', 'remaining_verbs'), add_morph_attr=False, add_analysis_ids_attr=False, expand2ndTime=False, breakOnPunctuation=False, removeSingleAraEi=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import VerbChainDetector\n",
    "vc_detector = VerbChainDetector()\n",
    "vc_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lihtsaimaks kasutusnäiteks on jaatavate ja eitavate verbiahelate tuvastamine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>verb_chains</td>\n",
       "      <td>pattern, roots, word_ids, mood, polarity, tense, voice, remaining_verbs</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>pattern</th>\n",
       "      <th>roots</th>\n",
       "      <th>word_ids</th>\n",
       "      <th>mood</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tense</th>\n",
       "      <th>voice</th>\n",
       "      <th>remaining_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['alustas']</td>\n",
       "      <td>['verb']</td>\n",
       "      <td>['alusta']</td>\n",
       "      <td>[2]</td>\n",
       "      <td>indic</td>\n",
       "      <td>POS</td>\n",
       "      <td>imperfect</td>\n",
       "      <td>personal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['ei', 'alustanud']</td>\n",
       "      <td>['ei', 'verb']</td>\n",
       "      <td>['ei', 'alusta']</td>\n",
       "      <td>[6, 7]</td>\n",
       "      <td>indic</td>\n",
       "      <td>NEG</td>\n",
       "      <td>imperfect</td>\n",
       "      <td>personal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='verb_chains', attributes=('pattern', 'roots', 'word_ids', 'mood', 'polarity', 'tense', 'voice', 'remaining_verbs'), spans=SL[EnvelopingSpan(['alustas'], [{'pattern': ['verb'], 'roots': ['alusta'], 'word_ids': [2], 'mood': 'indic', 'polarity': 'POS', 'tense': 'imperfect', 'voice': 'personal', 'remaining_verbs': False}]),\n",
       "EnvelopingSpan(['ei', 'alustanud'], [{'pattern': ['ei', 'verb'], 'roots': ['ei', 'alusta'], 'word_ids': [6, 7], 'mood': 'indic', 'polarity': 'NEG', 'tense': 'imperfect', 'voice': 'personal', 'remaining_verbs': False}])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "# Loome teksti\n",
    "text = Text('Kas Juku alustas kodutööga? Minuteada ei alustanud.')\n",
    "# Lisame verbiahelate tuvastamiseks vajalikud sisendkihid\n",
    "text.tag_layer(['words', 'sentences', 'morph_analysis', 'clauses'])\n",
    "\n",
    "# Tuvastame verbiahelad\n",
    "vc_detector.tag( text )\n",
    "\n",
    "# Väljastame verbiahelad (vastavad tekstid)\n",
    "text.verb_chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Ühe- vs mitmesõnalised ahelad._ Nagu eelmisest näitest võib näha, siis jaatav \"verbiahel\" võib koosneda ainult ühest sõnast. Seepärast võib nimi \"verbiahel\" esmapilgul tunduda veidi eksitav (mismoodi on üks verb ahel?!), aga kuna verbiahelate tuvastaja eesmärgiks on süstemaatiliselt leida üles kõik lause / osalause peaverbe¹ hõlmavad konstruktsioonid ja peaverbid ongi sageli ühesõnalised, siis tagastab ka tuvastaja nii mitmesõnalisi kui ka ühesõnalisi tekstiüksuseid;\n",
    "\n",
    " * ¹ _peaverbi_ all mõeldakse siin enamasti finiitverbi ehk pöördelist verbivormi. Aga on ka erandeid, nende kohta vt järgnevat loendit;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konkreetsemalt katab verbiahelate tuvastaja järgmisi konstruktsioone:\n",
    "   * Lause/osalause peaverbid:\n",
    "       * Jaatavad verbid, v.a. _olema_ (nt \"Pidevalt **uurivad** asjade seisu ka hollandlased\");\n",
    "       * Ühe- ja mitmesõnalised jaatavad _olema_ -konstruktsioonid (nt \"Raha **on** alati vähe\", \"**Oleme** sellist kino ennegi **näinud**\");\n",
    "       * Eitusega peaverbid: _ei/ära/pole/ega + verb_ (nt \"Helistasin korraks Carmenile, kuid ta **ei vastanud**\");    \n",
    "   * Peaverbide laiendused:\n",
    "       * _verb + infiniitverb_ ahel, kus _infiniitverbi_ ja eelneva verbi vahel on rektsiooniseos, nt verb _kutsuma_ saab võtta _ma_ -verbidest argumente (\"Kevadpäike **kutsub** mind **suusatama**\") ning _püüdma_ saab võtta _da_ -verbidest argumente (\"Aita **ei püüdnudki** Leenat **mõista**\");\n",
    "       * _verb + nom/adv + infiniitverb_ ahel, kus mitmesõnaline üksus _verb + nimisõna/adverb_ on rektsiooniseoses sellele järgneva infiniitverbiga; näiteks, verb _otsima_ saab moodustada mitmesõnalise üksuse sõnaga _võimalust_ ning see üksus saab võtta omakorda _da_ -verbe argumentideks (\"Seepärast **otsisimegi** **võimalust** kusagilt mõned ilvesed **hankida**\");\n",
    "\n",
    "Kui rektsiooniseoste tuvastamisel ei teki mitmesusi (st ei tuvastata mitut erinevat viisi ühe ahela laiendamiseks), võib verbiahelate tuvastaja algoritm laiendada üht ahelat ka mitu korda ning moodustada üksjagu pika ahela, nt lausest \"Minul oleks pidanud olema õigus ise endale külalisi kutsuda\" leitakse ahel  **oleks** => **pidanud** => **olema** => **õigus** => **kutsuda**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>verb_chains</td>\n",
       "      <td>pattern, roots, word_ids, mood, polarity, tense, voice, remaining_verbs</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>pattern</th>\n",
       "      <th>roots</th>\n",
       "      <th>word_ids</th>\n",
       "      <th>mood</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tense</th>\n",
       "      <th>voice</th>\n",
       "      <th>remaining_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['tahtis', 'alustada']</td>\n",
       "      <td>['verb', 'verb']</td>\n",
       "      <td>['taht', 'alusta']</td>\n",
       "      <td>[1, 5]</td>\n",
       "      <td>indic</td>\n",
       "      <td>POS</td>\n",
       "      <td>imperfect</td>\n",
       "      <td>personal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['ei', 'saanud']</td>\n",
       "      <td>['ei', 'verb']</td>\n",
       "      <td>['ei', 'saa']</td>\n",
       "      <td>[8, 9]</td>\n",
       "      <td>indic</td>\n",
       "      <td>NEG</td>\n",
       "      <td>imperfect</td>\n",
       "      <td>personal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['on', 'võimalik', 'alustada']</td>\n",
       "      <td>['ole', 'nom/adv', 'verb']</td>\n",
       "      <td>['ole', 'võimalik', 'alusta']</td>\n",
       "      <td>[13, 15, 17]</td>\n",
       "      <td>indic</td>\n",
       "      <td>POS</td>\n",
       "      <td>present</td>\n",
       "      <td>personal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='verb_chains', attributes=('pattern', 'roots', 'word_ids', 'mood', 'polarity', 'tense', 'voice', 'remaining_verbs'), spans=SL[EnvelopingSpan(['tahtis', 'alustada'], [{'pattern': ['verb', 'verb'], 'roots': ['taht', 'alusta'], 'word_ids': [1, 5], 'mood': 'indic', 'polarity': 'POS', 'tense': 'imperfect', 'voice': 'personal', 'remaining_verbs': False}]),\n",
       "EnvelopingSpan(['ei', 'saanud'], [{'pattern': ['ei', 'verb'], 'roots': ['ei', 'saa'], 'word_ids': [8, 9], 'mood': 'indic', 'polarity': 'NEG', 'tense': 'imperfect', 'voice': 'personal', 'remaining_verbs': False}]),\n",
       "EnvelopingSpan(['on', 'võimalik', 'alustada'], [{'pattern': ['ole', 'nom/adv', 'verb'], 'roots': ['ole', 'võimalik', 'alusta'], 'word_ids': [13, 15, 17], 'mood': 'indic', 'polarity': 'POS', 'tense': 'present', 'voice': 'personal', 'remaining_verbs': False}])])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loome teksti ja lisame verbiahelate tuvastamiseks vajalikud kihid\n",
    "text = Text('Juku tahtis kodutööd juba ammu alustada, aga ei saanud. Juku kinnitusel on siiski võimalik kodutööd alustada.')\n",
    "text.tag_layer(['words', 'sentences', 'morph_analysis', 'clauses'])\n",
    "\n",
    "# Tuvastame verbiahelad\n",
    "vc_detector.tag( text )\n",
    "\n",
    "# Väljastame verbiahelad (vastavad tekstid)\n",
    "text.verb_chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Millist infot annavad edasi tuvastatud verbiahelate atribuudid?\n",
    "\n",
    "* `text` -- verbiahela fraas. Kuna verbiahelate kiht on ümbriskiht sõnade kihi ümber, siis on siin sõnade järjend.\n",
    "* `pattern` -- järjend ahela sõnade üldistusega; ahelat üldistav muster. Iga sõna kohta on toodud välja, kas sõna on: 'verb' (tegusõna, v.a 'olema' verbid), 'nom/adv' (käändsõna või adverb), 'ole' ('olema'-verb), 'pole' ('olema'-verbi eitus: pole & polnud jne), '&' (sidesõna: ja/ning/ega/või) või siis 'ega', 'ei' või 'ära';\n",
    "* `roots` -- järjend ahela sõnade algvormidega (morf analüüsi `'root'` atribuudid);\n",
    "* `word_ids` -- järjend ahela moodustavate sõnade indeksitega tekstis;\n",
    "* `mood` -- ahela finiitverbi kõneviis. Võimalikud väärtused: `'indic'` (kindel kv), `'imper'` (käskiv ja möönev), `'condit'` (tingiv), `'quotat'` (kaudne),  või `'??'` (määramata);\n",
    "* `polarity` -- kas verbiahel on jaatav (`'POS'`) või eitav (`'NEG'`)? Võimalik ka väärtus `'??'` (määramata);\n",
    "* `tense` -- ahela finiitverbi/konstruktsiooni grammatiline aeg. Võimalikud väärtused sõltuvad kõneviisist. Kindlas kõneviisis: `'present'`, `'imperfect'`, `'perfect'`, `'pluperfect'`, käskivas kõneviisis:  `'present'` ning tingivas ja kaudses: `'present'` ja `'past'`. Lisaks võib jääda ka määramata (`'??'`);\n",
    "* `voice` -- ahela finiitverbi tegumood. Võimalikud väärtused: `'personal'`, `'impersonal'`, `'??'`;\n",
    "* `remaining_verbs` -- kahendmuutuja, mis näitab, kas osalausesse jäi veel nö lahtisi verbe, mis potentsiaalselt võiksid kuuluda ahelasse. Väärtus `True` annab märku sellest, et ahel võib olla mitte-täielikult eraldatud (st mitmesuse või puuduva rektsiooniinfo tõttu ei osanud algoritm kõiki verbe ahelasse panna / terviklikku ahelat moodustada);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sõnade järjekord ahelas. Tähenduse mõjutajad ja sisuverbid.** Atribuudi `roots` all olevad algvormid ei ole organiseeritud mitte nende lauses esinemise järjekorras, vaid järjekorras, mis peegeldab sõnadevahelisi seoseid: \n",
    "iga järgnev sõna ahelas on eelmise sõna süntaktiline alluv.\n",
    "Sellise järjestamise tulemusena on ahela eesotsas _tähendust mõjutavad verbid_ , nt eituse abiverb või modaalverb, ning ahela lõpus _sisuverb_ ehk siis verb, mis annab edasi väite põhisisu.\n",
    "Näited:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AttributeTupleList (spans)</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>roots</th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>['kutsuda', 'ei', 'proovitudki']</td>\n",
       "      <td>['ei', 'proovi', 'kutsu']</td>\n",
       "      <td>['ei', 'verb', 'verb']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>['Plaanis', 'on', 'hängida']</td>\n",
       "      <td>['ole', 'plaan', 'hängi']</td>\n",
       "      <td>['ole', 'nom/adv', 'verb']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AttributeTupleList([[['kutsuda', 'ei', 'proovitudki'], ['ei', 'proovi', 'kutsu'], ['ei', 'verb', 'verb']], [['Plaanis', 'on', 'hängida'], ['ole', 'plaan', 'hängi'], ['ole', 'nom/adv', 'verb']]], ('text', 'roots', 'pattern'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Text('Ja teda kutsuda ei proovitudki? Plaanis on lihtsalt hängida seal.')\n",
    "text.tag_layer(['words', 'sentences', 'morph_analysis', 'clauses'])\n",
    "\n",
    "# Tuvastame verbiahelad\n",
    "vc_detector.tag( text )\n",
    "\n",
    "# Väljastame verbiahelad\n",
    "text.verb_chains[['text', 'roots', 'pattern']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näha, siis atribuut `text` annab edasi sõnade tekstis olevat järjestust (sama kehtib ka atribuutide `start` ja `end` kohta), samas kui järjendites `roots` ja `pattern` on järjestus vastavalt sõnade vahelistele seostele. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rohkem infot verbiahelate tuvastaja kohta leiab [EstNLTK abimaterjalist](https://github.com/estnltk/estnltk/blob/main/tutorials/nlp_pipeline/X_miscellaneous/01_verb_chain_detector.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialiseerimine ( _Pickle_ )\n",
    "\n",
    "Tekstilised formaadid nagu XML ja JSON on inimesele suhteliselt hästi loetavad, kuid nende lugemine/kirjutamine tähendab arvuti jaoks enamasti lisatööd: andmeid tuleb teisendada mälus oleva kuju ja tekstilise kuju vahel. \n",
    "Kui lood ise uue Pythoni klassi, siis ei saa selle objekte kohe JSON / XML kujul salvestada, vaid pead looma ka konverteri, mis teisendab objekte vastavatesse andmekujudesse (ja ka tagasi).\n",
    "\n",
    "Pythoni andmestruktuuride ja objektide otse-salvestamiseks leidub ka alternatiivne ja kiirem viis, mida nimetatakse _serialiseerimiseks_. \n",
    "Sisuliselt tähendab serialiseerimine, et salvestamisel teisendatakse mälus olevad andmed binaarsele kujule ning failist laadimisel muudetakse need tagasi Pythoni mälus olevateks andmeteks.\n",
    "Kuna andmete formaati sealjuures ei muudeta, on protsess enamasti suhteliselt kiire.\n",
    "Samuti ei pea ise tegelema konverteri kirjutamisega: enamikku andmestruktuure, funktsioone, klasse kui ka klasside isendeid / objekte on võimalik serialiseerida ilma, et peaks neid kuidagi teisendama.\n",
    "\n",
    "Pythonis vastutab serialiseerimise eest teek [_pickle_](https://docs.python.org/3.9/library/pickle.html). Nagu teiste andmeformaatidegi puhul, on ka serialiseerimise tulemused platvormist sõltumatud ehk serialiseerimise abil tekitatud fail peaks olema suvalisel (Pythoniga) masinal loetav. Binaarse kuju miinuseks on aga kahjuks see, et failis olevad andmed pole enam inimsilmale loetavad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Näitena serialiseerime _rows_ muutuja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [{'a':5, 'b':3}, {'c':4, 'd':1 }]\n",
    "\n",
    "import pickle\n",
    "with open('serialized_ppl.pkl','wb') as fout:\n",
    "    pickle.dump(rows, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paneme tähele, et fail tuleb avada nii lugemiseks kui kirjutamiseks _binary mode_'is (`'wb'` ja `'rb'`).\n",
    "\n",
    "Võite iseseisvalt uurida, milline on tekitatud faili `'serialized_ppl.pkl'` sisu. (Eriti loetav see pole.)\n",
    "\n",
    "Funktsiooni `pickle.load` abil saame serialiseeritud sisu jälle Pythonisse tagasi lugeda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'a': 5, 'b': 3}, {'c': 4, 'd': 1}]\n"
     ]
    }
   ],
   "source": [
    "with open('serialized_ppl.pkl','rb') as fin:\n",
    "    new_rows = pickle.load(fin)\n",
    "    print(new_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaikimisi saab _pickle_ hakkama paljude standardteekide klasside / objektide serialiseerimisega ning ka endakirjutatud teekidega, mis kasutavad standardteegi objekte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EstNLTK `Text` objektide serialiseerimisest\n",
    "\n",
    "Ka EstNLTK `Text` objektide salvestamiseks/laadimiseks on serialiseerimine üsna kiire viis. Proovime seda ühe näite varal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loome serialiseeritava teksti\n",
    "from estnltk import Text\n",
    "text = Text('Küll homme armastab see, kes ei armastanud eile.')\n",
    "# Lisame märgendused\n",
    "text = text.tag_layer(['clauses'])\n",
    "# Tuvastame verbiahelad\n",
    "vc_detector.tag( text )\n",
    "\n",
    "import pickle\n",
    "with open('test_serialized_text.pkl','wb') as fout:\n",
    "     pickle.dump(text, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laeme teksti sisse ja uurime, kas märgendused säilisid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Küll homme armastab see, kes ei armastanud eile.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>verb_chains</td>\n",
       "      <td>pattern, roots, word_ids, mood, polarity, tense, voice, remaining_verbs</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Küll homme armastab see, kes ei armastanud eile.')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>clause_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Küll', 'homme', 'armastab', 'see', ',']</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['kes', 'ei', 'armastanud', 'eile', '.']</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='clauses', attributes=('clause_type',), spans=SL[EnvelopingSpan(['Küll', 'homme', 'armastab', 'see', ','], [{'clause_type': 'regular'}]),\n",
       "EnvelopingSpan(['kes', 'ei', 'armastanud', 'eile', '.'], [{'clause_type': 'regular'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>verb_chains</td>\n",
       "      <td>pattern, roots, word_ids, mood, polarity, tense, voice, remaining_verbs</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>pattern</th>\n",
       "      <th>roots</th>\n",
       "      <th>word_ids</th>\n",
       "      <th>mood</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tense</th>\n",
       "      <th>voice</th>\n",
       "      <th>remaining_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['armastab']</td>\n",
       "      <td>['verb']</td>\n",
       "      <td>['armasta']</td>\n",
       "      <td>[2]</td>\n",
       "      <td>indic</td>\n",
       "      <td>POS</td>\n",
       "      <td>present</td>\n",
       "      <td>personal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['ei', 'armastanud']</td>\n",
       "      <td>['ei', 'verb']</td>\n",
       "      <td>['ei', 'armasta']</td>\n",
       "      <td>[6, 7]</td>\n",
       "      <td>indic</td>\n",
       "      <td>NEG</td>\n",
       "      <td>imperfect</td>\n",
       "      <td>personal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='verb_chains', attributes=('pattern', 'roots', 'word_ids', 'mood', 'polarity', 'tense', 'voice', 'remaining_verbs'), spans=SL[EnvelopingSpan(['armastab'], [{'pattern': ['verb'], 'roots': ['armasta'], 'word_ids': [2], 'mood': 'indic', 'polarity': 'POS', 'tense': 'present', 'voice': 'personal', 'remaining_verbs': False}]),\n",
       "EnvelopingSpan(['ei', 'armastanud'], [{'pattern': ['ei', 'verb'], 'roots': ['ei', 'armasta'], 'word_ids': [6, 7], 'mood': 'indic', 'polarity': 'NEG', 'tense': 'imperfect', 'voice': 'personal', 'remaining_verbs': False}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('test_serialized_text.pkl','rb') as fin:\n",
    "    loaded_text = pickle.load(fin)\n",
    "\n",
    "display(loaded_text)\n",
    "display(loaded_text.clauses)\n",
    "display(loaded_text.verb_chains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mis läheb serialiseerimisel `Text`-iga kaasa? Analoogselt `Text`-ide salvestamisega JSON formaadis pannakse kaasa algne tekst, teksti meta-andmed ja märgenduskihid. Välja jääb info selle kohta, milliste märgendajatega kihid tekitati ning millised olid märgendajate konfiguratsioonid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
