{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue\"> Lisamaterjal: Twitteri veebiteenuste kasutamine Pythonis </h1>\n",
    "\n",
    "Kui soovid Twitter'ist andmeid korjata ja analüüsida, ei ole tingimata vaja ehitada veebiämblikku: Twitter pakub välja veebiteenused, mille kaudu saab (programmaatiliselt) otsida ja koguda päevakajalisi säutse, uurida kasutajate säutsuvooge ja omavahelist suhtlust ning teha palju muudki.\n",
    "\n",
    "Käesolevas lisamaterjalis uurimegi samm-sammult, kuidas saab Pythoni abil Twitteri säutse otsida ja alla laadida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esimesed sammud\n",
    "\n",
    "### I. Twitter'i konto loomine ja seadistamine\n",
    "\n",
    "Selleks, et Twitter-is päringuid teha, peab olema Twitteri kasutajakonto. Konto saab luua aadressil: https://twitter.com/signup\n",
    "\n",
    "Kui konto on olemas, siis tuleb sellega siduda mobiilinumber. Seejärel saadetakse lühisõnumiga kinnituskood, mille pead Twitter'i veebilehel sisestama. \n",
    "Alles siis, kui kontoga on mobiilinumber seotud, saad ligipääsu Twitteri veebiteenustele, st saad hakata Pythonis veebiteenustele päringuid tegema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Ligipääs veebiteenustele: _app_'i loomine ja võtmed\n",
    "\n",
    "Kui oled oma kasutajaga Twitter-isse sisse loginud, mine lehele https://developer.twitter.com/en/portal/dashboard ja loo uus projekt / rakendus.\n",
    "\n",
    "Kui rakenduse loomine on õnnestunud, peaksid kätte saama ligipääsuvõtmed, mille kaudu hakkad veebiteenustega suhtlema. \n",
    "Selleks peaksid pärast rakenduse loomist valima _\"Key and Access Tokens\"_ kopeerima sealt _\"Consumer Key\"_ ja _\"Consumer Secret\"_ väärtused. \n",
    "Allpool peaks veel olema paneel _\"Your Access Token\"_ ning kui oled värske veebiteenuse kasutaja, peaksid selle uuesti looma (nupp nimega _\"create access token\"_ vms). \n",
    "Kui isiklik ligipääsuvõti loodud, kopeeri ka sealt väärtused _\"Access Token\"_ ja _\"Access Token Secret\"_;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. _Python Twitter Tools_'i paigaldamine\n",
    "\n",
    "Twitteri veebiteenusega suhtlemiseks on loodud üksjagu palju Pythoni teeke, nimekirja neist leiate nt [siit](https://developer.twitter.com/en/docs/twitter-api/tools-and-libraries). Käesolevas praktikumis proovime esmalt teeki [_Python Twitter Tools_](https://github.com/sixohsix/twitter). Teegi installimiseks tipi conda käsureale:\n",
    "\n",
    "    pip install twitter    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Näidispäring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esimese sammuna tuleb täita ligipääsuvõtmete muutujad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kasutajakonto ja rakendusega seotud ligipääsuvõtmed\n",
    "# (TODO: täita oma võtmete väärtustega)\n",
    "ACCESS_TOKEN    = ''\n",
    "ACCESS_SECRET   = ''\n",
    "CONSUMER_KEY    = ''\n",
    "CONSUMER_SECRET = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seejärel loome ühenduse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twitter import Twitter, OAuth\n",
    "\n",
    "# Loome veebiteenusega ühenduse (\"logime sisse\")\n",
    "t = Twitter(\n",
    "    auth=OAuth(ACCESS_TOKEN, ACCESS_SECRET, CONSUMER_KEY, CONSUMER_SECRET))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nüüd ongi võimalik teha päringuid. \n",
    "\n",
    "Otsime kõige värskemaid eestikeelseid säutse, mis sisaldavad sõna `Tartu`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = t.search.tweets(q=\"Tartu\", lang=\"et\", result_type='recent', count=15)\n",
    "print( \"Leiti\", len(results['statuses']),\"säutsu.\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suhtlus veebiteenusega toimub JSON formaadis andmeid vahetades, seega on tagastatav tulemus samuti mitmetasemeline sõnastik-andmestruktuur. Võid selle sisu uurida `pprint` abil. Leitud säutsud on saadaval võtme `'statuses'` all järjendina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Trükime välja esimese leitud säutsu andmed\n",
    "pprint( results['statuses'][0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enamik eeltoodud andmetest on tehnilist laadi ning ei pruugi olla väga huvitavad. Seega tasub teha üks tsükkel üle leitud säutsude ning noppida välja huvipakkuvaimad andmed. Näiteks nii:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nopime välja huvipakkuvad andmed\n",
    "for twnr, tweet_obj in enumerate(results['statuses']):\n",
    "    # säutsu andmed\n",
    "    time     = tweet_obj.get('created_at', '---')\n",
    "    language = tweet_obj.get('lang', '---')\n",
    "    text     = tweet_obj.get('text', '---')\n",
    "    # säutsuja andmed\n",
    "    user_name       = tweet_obj['user'].get('name', '---')\n",
    "    user_screenname = tweet_obj['user'].get('screen_name', '---')\n",
    "    user_location   = tweet_obj['user'].get('location', '---')\n",
    "    user_timezone   = tweet_obj['user'].get('time_zone', '---')\n",
    "    # väljastame\n",
    "    print(str(twnr+1)+'. \"'+text+'\"')\n",
    "    print('   user_screenname:',user_screenname)\n",
    "    print('   user_name:      ',user_name)\n",
    "    print('   time:           ',time)\n",
    "    print('   time_zone:      ',user_timezone)\n",
    "    print('   language:       ',language)\n",
    "    print('   user location:  ',user_location)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keerulisemad päringud\n",
    "\n",
    "### Suurem hulk vastuseid ja päringutulemustes navigeerimine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eelmises näites piirati tagastatavate säutsude arv 15-le. Tagastatavate säutsude arvu (parameeter `count`) võib tõsta maksimaalselt kuni 100-ni ning kui leitakse sellest rohkem säutse, tuleb kõigi tulemuste kättesaamiseks hakata päringutulemustes navigeerima. \n",
    "Leitud säutsud on ajaliselt sorteeritud (kõige värskemad kõige ees) ning parameetriga `max_id` saab määrata, millisest (mineviku)säutsust alates tuleb valida 15 või 100 (ehk siis `count`) eelmist säutsu. \n",
    "Seega suure hulga tulemuste korral saab võtta viimase säutsu `id` ja luua selle põhjal uue `max_id` (`max_id = id - 1`) ning kasutada seda otsingul.\n",
    "\n",
    "Järgmisel otsingul kasutatava `max_id` väärtus on tegelikult olemas ka päringu metaandmetes. Seega, kui päringule oli rohkem vasteid kui tagastati, siis ilmub metaandmetesse võti `next_results`, mille väärtuseks on järgmise päringu url koos `max_id`-iga. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otsime mõne globaalselt tuntud nime järgi, et saada palju vasteid\n",
    "results = t.search.tweets(q=\"Putin\", lang=\"et\", result_type='recent', count=100) \n",
    "print( \"Leiti\", len(results['statuses']),\"säutsu.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Uurime päringu metaandmeid: kas vasteid on veel?\n",
    "pprint(results['search_metadata'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vasteid oli veel.\n",
    "\n",
    "Seega võime teha programmi, mis sooritab järgemööda päringuid ja kogub säutsud kokku üle kõigi andmete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Näide: päringutulemuste läbiketramine\n",
    "import re\n",
    "\n",
    "query = \"Putin\"\n",
    "all_results = []\n",
    "max_count = 100\n",
    "results = t.search.tweets(q=query, lang=\"et\", result_type='recent', count=max_count) \n",
    "while True:\n",
    "    # Algväärtustame max_id (esialgu me ei tea, kas tulemusi on veel või mitte)\n",
    "    max_id = None\n",
    "    print( \"Leiti\", len(results['statuses']),\"säutsu.\" )\n",
    "    if results['statuses']:\n",
    "        # Salvestame leitud säutsud\n",
    "        all_results.extend( results['statuses'] )\n",
    "        # Leiame max_id\n",
    "        next_results_url = results['search_metadata'].get('next_results')\n",
    "        if next_results_url:\n",
    "            max_id_str = re.findall('max_id=(\\d+)&', next_results_url)\n",
    "            max_id = int(max_id_str[0])\n",
    "    # Kui max_id on leitud, teeme uue päringu\n",
    "    if max_id:\n",
    "        results = t.search.tweets(q=query, lang=\"et\", max_id=max_id, result_type='recent', count=max_count)\n",
    "    else:\n",
    "        # Kui max_id on leidmata, lõpetame\n",
    "        break\n",
    "print( \"Kokku leiti päringule '\"+query+\"' vasteks\",len(all_results),\"säutsu.\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeletuvastus\n",
    "\n",
    "Kui leitud päringutulemusi detailsemalt uurida, siis tuleb esile ka üks keelespetsiifiliste päringute tegemise kitsaskoht. Nimelt on paljud säutsudest küll märgitud eestikeelseteks, ent tegelikult on nende sisu eesti keelest üsna kaugel (tegemist on kas mõne sugulaskeele või eesti keelega sarnaseid häälikutejadasid sisaldava säutsuga)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uurime viimast 10-t säutsu\n",
    "for i in range(10):\n",
    "    tweet_obj = all_results[-i]\n",
    "    # väljastame\n",
    "    print(str(i+1)+'. \"'+tweet_obj.get('text', '---')+'\"')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Üks võimalus probleemist ülesaamiseks (st eestikeelsete säutsude väljasõelumiseks) on rakendada tekstil morfoloogilist analüsaatorit ja uurida, kui suur osakaal sõnadest on tundmatud. Säutsud, kus enamik sõnu jääb morf analüsaatorile tundmatuks, võib suure tõenäosusega lugeda mitte-eestikeelseteks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teine võimalus on lasta säutsud automaatsest keeletuvastusest läbi. Pythoni teek [LangID](https://github.com/saffsd/langid.py) sobib täitsa hästi sellesse rolli. Teegi installimiseks käsureale:\n",
    "\n",
    "    pip install langid  \n",
    "    \n",
    "Edasi rakendame keeletuvastust eestikeelsete säutsude väljanoppimiseks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impordime keeletuvastuse teegi\n",
    "import langid\n",
    "\n",
    "all_results_et = []\n",
    "for tweet_obj in all_results:\n",
    "    text = tweet_obj.get('text', '---')\n",
    "    # Tuvastame säutsu keele\n",
    "    lang = langid.classify(text)[0]\n",
    "    if lang == 'et':\n",
    "        # Nopime välja vaid eestikeelsed säutsud\n",
    "        all_results_et.append( tweet_obj )\n",
    "\n",
    "print( \"Automaatne keeletuvastus leidis \",len(all_results_et),\" eestikeelset säutsu.\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heidame tulemustele pilgu peale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uurime viimast 10-t säutsu\n",
    "for i in range(10):\n",
    "    tweet_obj = all_results_et[-i]\n",
    "    # väljastame\n",
    "    print(str(i+1)+'. \"'+tweet_obj.get('text', '---')+'\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagu näha, ei ole ka seekord tulemused päris perfektsed, aga prahti paistab siiski oluliselt vähem. Tulemusi saaks ehk veelgi täpsemaks kui uurida ka [keeletuvastuse tõenäosuseid](https://github.com/saffsd/langid.py#probability-normalization) ning võtta välja vaid kõige suurema tõenäosusmäärangu saanud säutsud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Search_ liidese parameetrid ja piirangud otsimisel\n",
    "\n",
    "Eelpool kasutasime otsinguliidest _Search_ (`t.search.tweets`). _Search_ võimaldab leida kõige värskemaid säutse (parameeter `result_type='recent'`), kõige populaarsemaid (`result_type='popular'`) ning segamini nii värskeid kui populaarseid (`result_type='mixed'`, vaikimisi). \n",
    "\n",
    "Kui otsid eestikeelseid säutse (`lang='et'`) ja kasutad eestikeelseid võtmesõnu, ei pruugi aga populaarsete päringule vastuseid leida, kuna eestikeelsed säutsud ei ulatu eriti globaalsel populaarsusskaalal konkureerima. \n",
    "Samuti on piiratud värskeimate säutsude otsimine: veebiliides tagastab vaid [viimase 7 päeva säutse](https://developer.twitter.com/en/docs/tweets/search/overview/standard).\n",
    "\n",
    "Lisaks saab parameetritega täpsustada nt säutsuja asukoha (koordinaadid) ja kuupäeva (kitsendatud 1 nädala piires). Võimalike päringuparameetrite kohta vaata täpsemalt [lehelt](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets#parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (!) Oluline: Päringulimiidid\n",
    "\n",
    "Veebiteenustele päringuid tehes tuleb jälgida, et ei ületaks Twitteri poolt seatud päringulimiite. Päringulimiitide ületamisel (või veel hullem -- serveri üleuputamisel päringutega) võidakse tühistada ligipääs veebiteenustele ja kasutajakonto. \n",
    "\n",
    "Vaikimisi rakenduvaid päringulimiite on kirjeldatud [sellel veebilehel](https://developer.twitter.com/en/docs/basics/rate-limits). Oma päringulimiitide seisu saate jooksvalt kontrollida meetodi `rate_limit_status()` abil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_limits = t.application.rate_limit_status()\n",
    "\n",
    "# Mitu otsipäringut saab veel teha?\n",
    "rate_limits['resources']['search']['/search/tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_limits = t.application.rate_limit_status()\n",
    "\n",
    "# Mitu korda saab veel rakenduse-päringuid teha (nt küsida päringulimiite)?\n",
    "rate_limits['resources']['application']['/application/rate_limit_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muutuja `reset` näitab, kuna toimub järgmine päringulimiitide _algväärtustamine_. Algväärtustamisel viiakse tehtud päringute arvud jälle nulli.\n",
    "\n",
    "Ajamäärang on antud sekundites ning `datetime` abil saab selle inimloetavaks muuta, nt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "reset_time = rate_limits['resources']['application']['/application/rate_limit_status']['reset']\n",
    "human_readable_time = datetime.fromtimestamp( reset_time ).strftime('%Y-%m-%d %H:%M:%S')\n",
    "human_readable_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Säutsude kogumine _TweetCat_'i abil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probleemid, millega puutume kokku eestikeelsete säutsude otsimisel (probleemne keeletuvastus, populaarsete säutsude vähesus, ainult viimase 7 päeva säutsude tagastamine), on esile tulnud ka teiste väikeste keelte jaoks Twitter-i korpuste kogumisel. Ja nende ületamiseks on välja pakutud ka lahendusi. Üheks selliseks lahenduseks on tööriist [_TweetCat_](https://github.com/clarinsi/tweetcat), mis võimaldab säutsude otsimisel / korjamisel rakendada kasutaja-põhist otsingut. \n",
    "\n",
    "_TweetCat_-le tuleb anda ette suhteliselt väike arv võtmesõnu (20-40), mis on antud keeles sagedased ning spetsiifilised (st tõenäoliselt pole sagedased mõnes teises keeles). Nende abil leitakse kõigepealt selles keeles kirjutavad Twitter'i kasutajad. Sellele järgneb iteratiivne päringu laiendamine, mille käigus kogutakse juba leitud kasutajate ajajoontelt (ingl _timeline_) säutsud kokku ning seejärel laiendatakse uuritavate kasutajate ringi võttes luubi alla nende sõbrad ja järgijad (eeldades, et nad tõenäoliselt säutsuvad samas keeles).\n",
    "\n",
    "Kasutajapõhise otsingu eeliseks on, et kasutaja ajajoonelt säutsude korjamisel ei ole \"viimase 7 päeva limiiti\" -- ühelt kasutajalt saab ka vanemaid säutse. Samuti kannab _TweetCat_ hoolt selle eest, et sõelale jääks võimalikult vähe vales keeles säutse: säutsude korjamisel rakendatakse `langid` keeletuvastust. \n",
    "\n",
    "_TweetCat_'i tööpõhimõtteid kirjeldab detailsemalt [see teadusartikkel](https://pdfs.semanticscholar.org/3037/ee591a314481f99902027438eee4c741aa3e.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _TweetCat'i_ installimine ja seadistamine\n",
    "\n",
    "_TweetCat_ on kahjuks selline programm, mis nõuab vana Pythoni versiooni -- Python 2.7-t. Samas ei tähenda see, et peaksid selle kasutamiseks täielikult ümber lülituma vanale Pythonile. Virtuaalkeskkondade võlu ongi selles, et võid luua vana Pythoni versiooniga keskkonna _TweetCat_-i abil andmete korjamiseks, ning andmete töötlemisel saad jälle rakendada harjumuspärast uut Pythoni versiooni. Detailsemalt:\n",
    "\n",
    " 1. Loo `conda` abil uus virtuaalkeskkond, mis sisaldab Python 2.7.*-t (nt versiooni 2.7.13)   \n",
    "    ( meeldetuletuseks keskkondade loomise kohta vt 1. praksi juhendit ) \n",
    "    \n",
    " 2. Installi teegid `langid` ( `pip install langid` ) ja `tweepy` ( `pip install tweepy` ) \n",
    "\n",
    " 3. Lae oma arvutisse respositooriumist https://github.com/clarinsi/tweetcat _TweetCat_'i projekt \n",
    " \n",
    " 4. Paki projekt lahti ning ava kaust `1-harvest` \n",
    "\n",
    " 5. Ava konfiguratsioonifail ( `hbs.py` ) ja määra:\n",
    " \n",
    "     5.1. Ligipääsuvõtmete väärtused ( `CONSUMER_KEY`, `CONSUMER_SECRET`, `ACCESS_TOKEN`, `ACCESS_TOKEN_SECRET` )   \n",
    "     5.2. Kasutatav režiim ( `MODE='LANG'` -- keele järgi otsimine )   \n",
    "     5.3. Huvipakkuvate keelte koodid ( `LANGID_LANG=['et']` -- kui otsida ainult eestikeelseid säutse )  \n",
    "     5.4. (Vajadusel) võtmesõnade faili nimi muutujas `SEEDS` (kui on oma fail juba olemas)\n",
    "     \n",
    " 6. Ava võtmesõnade fail (`'seeds.hbs'` või muutujas `SEEDS` kirjasolev fail) ja lisa sinna võtmesõnad:\n",
    " \n",
    "     * Iga võtmesõna eraldi real  \n",
    "     * Võtmesõnade arv: 20-..., võiksid olla keskmisest sagedasemad sisusõnad, mis uuritava keele-spetsiifilised\n",
    "\n",
    "     \n",
    "### Säutsude kogumine\n",
    "\n",
    "Kui _TweetCat_ on juba seadistatud, siis säutsude kogumiseks:\n",
    "\n",
    " 1. Mine Python 2.7.* virtuaalkeskkonnas kataloogi `1-harvest`\n",
    " \n",
    " 2. Käivita säutsude koguja käsurealt (andes talle ette konfiguratsioonifaili nime): \n",
    " \n",
    "         python harvesting.py hbs\n",
    " \n",
    " 3. Luuakse konfiguratsioonifaili-nimeline kaust ( `hbs` ) ning hakatakse sinna salvestama kogutud säutse kokkupakitud kujul (tekivad `.gz` laiendiga failid);\n",
    " \n",
    " 4. Protsessi katkestamiseks tuleb avada konfiguratsioonifaili-nimeline `.busy` fail ( `hbs.busy` ) ja kirjutada sealne väärtus üle sõnaga `stop`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kogutud säutsude analüüs\n",
    "\n",
    "Kogutud säutsud on kokkupakitud kujul, `.gz` laiendiga failidena. Mooduli `gzip` abil saate need failid avada ning JSON kujul andmed mällu lugeda, funktsioon `json.loads` aitab aga JSON-i teisendada Pythoni sõnastikuks:\n",
    "\n",
    "        import gzip\n",
    "        import json\n",
    "\n",
    "        fname = '2017-11-13_837713401296076800.gz'\n",
    "\n",
    "        with gzip.open(fname, 'rb') as f:\n",
    "            content = f.read()\n",
    "            # NB! Fail on binaarkujul ja tuleb \n",
    "            # dekodeerida\n",
    "            content = content.decode('utf8')\n",
    "            tweets = json.loads( content )\n",
    "            \n",
    "_Säutsude temaatilisus_. _TweetCat_ kannab küll hoolt selle eest, et säutsud oleksid suure tõenäosusega õiges keeles, aga säutsude temaatilisust ei garanteeri. Seega, kui eesmärgiks on koguda mingil kindlal teemal säutse, peaksid korjatud andmekogu omakorda filtreerima ja kindlal teemal (kindlate märksõnadega) säutsud välja selekteerima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Säutsude kogumine reaalajas\n",
    "\n",
    "Kui on tulemas mingi sündmus, millele tõenäoliselt on Twitter'is laialdasem kajastus, siis võib panna püsti ka programmi, mis kuulab Twitter'i säutsuvoogu ning kogub sealt reaalajas huvipakkuvaid säutse. Samuti tasub katsetada säutsude kogumist reaalajas siis, kui eesmärgiks on saada süstemaatiline ülevaade eestikeelsest säutsuruumist mingil ajaperioodil, nt ühe nädala või kuu vältel.\n",
    "\n",
    "Säutsude reaalajas korjamiseks pakub Twitter välja eraldi veebiteenuse, nn [säutsuvoo filtreerimise API](https://developer.twitter.com/en/docs/twitter-api/v1/tweets/filter-realtime/overview).\n",
    "Programm, mis on huvitatud säutsude korjamisest reaalajas, võtab esmalt veebiteenusega ühendust ning täpsustab filtreerimise kriteeriumid (nt millistelt kasutajatelt säutse korjatakse, milliseid võtmesõnu säutsud peavad sisaldama, mis keeles peavad säutsud olema jms).\n",
    "Kui kriteeriumid on paigas, jääb programm ootele ning Twitteri veebiteenus hakkab talle kriteeriumitele vastavaid säutse saatma -- programmi ülesandeks jääb vaid otsustada, mida nendega peale hakata (millised salvestada, millised jätta kõrvale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kasutame säutsude reaalajas korjamiseks Pythoni teegi [_tweepy_](https://github.com/tweepy/tweepy) vahendeid. Installimiseks kõigepealt conda käsureale:\n",
    "\n",
    "    pip install tweepy\n",
    "    \n",
    "Kui `tweepy` on olemas, tuleb meil järgmisena luua nn säutsuvoo klass (`Stream` või `StreamingClient`), mis suhtleb Twitteri säutsuvoo veebiteenustega ning otsustab, mida talle saadetud säutsudega teha ning kuidas talitada erijuhtudel (veateated, limiidihoiatused jms). \n",
    "Järgnevas näites teeme `Stream` klassi, mis kuulab Twitteri säutsuvoogu (API v1 kaudu), tuvastab eestikeelsed säutsud, prindib välja 5 tuvastatud säutsu, misjärel lõpetab töö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tweepy\n",
    "import langid\n",
    "\n",
    "class PrintingStream(tweepy.Stream):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # Initsialiseerime ülemklassi (Stream)\n",
    "        super(PrintingStream, self).__init__(*args, **kwargs)\n",
    "        # Loendame leitud eestikeelseid säutse\n",
    "        self.et_tweets = 0\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        # Saadeti uus säuts: kontrollime kõigepealt säutsu keelt\n",
    "        lang = langid.classify(status.text)[0]\n",
    "        if lang == 'et':\n",
    "            # Kui paistab olevat eestikeelne,\n",
    "            # väljastame loomisaja, kasutajanime ja säutsu teksti\n",
    "            print(status.created_at,'|', status.user.screen_name,'|', status.text)\n",
    "            self.et_tweets += 1\n",
    "        # Kui 5 eestikeelset säutsu on väljastatud, lõpetame töö\n",
    "        if self.et_tweets >= 5:\n",
    "            print('Lõpetan töö ...')\n",
    "            self.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Säutsuvoog ise ei täpsusta, millistele kriteeriumitele vastavaid säutse tuleb koguda. Meetodi `filter()` abil saame öelda, milliseid säutse me tahame  üles korjata.\n",
    "\n",
    "Järgnevas näites avame kõigepealt kasutajavõtmete abil uue säutsuvoo (`PrintingStream`) ning rakendame sellel säutsude filtreerimist ja tuvastamist. \n",
    "Otsime säutse, mis sisaldavad kõige sagedasemaid eesti keele sõnu (_on, ja, ei, ..._) ning mille keeleks on samuti määratud eesti keel (`'et'`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = PrintingStream(\n",
    "    CONSUMER_KEY, CONSUMER_SECRET,\n",
    "    ACCESS_TOKEN, ACCESS_SECRET\n",
    ").filter(track=['on', 'ja', 'ei', 'et', 'kui'], languages=[\"et\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eestikeelsete säutsude leidmine muutuks veel täpsemaks tõenäoliselt siis, kui valida hoolikamalt võtmesõnad, mille järgi säutse otsida. \n",
    "Ehk siis: tuleks leida sõnad, mis on sagedased küll eesti keeles, aga pigem mittesagedased teistes (Twitter'i) keeltes. \n",
    "Seda saaks teha katse-eksituse meetodil: võtta sõnu eesti sõnade sagedusloendist (nt [siit](http://www.cl.ut.ee/ressursid/sagedused1/failid/sonavorm_kahanevas.txt)) ning uurida, kui sageli annab üks või teine sõna eestikeelseid säutse ning kui sageli jääb sõelale valetuvastusi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_Täiendavad parameetrid_. Lisaks võtmesõnade ja keel(t)e määramisele saab säutsuvoo filtreerimisel veel täpsustada kasutajad, kellelt säutse kogutakse, ning säutsujate geograafilised asukohad (pikkus- ja laiuskraadide järgi). Nende ja teiste päringuparameetrite kohta vt täpsemalt siit: https://developer.twitter.com/en/docs/tweets/filter-realtime/api-reference/post-statuses-filter.html\n",
    "\n",
    "  * Vt ka inglisekeelset juhendmaterjali _Tweepy_-iga säutsuvoo filtreerimise kohta: https://docs.tweepy.org/en/stable/streaming.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reaalajas säutsudekogumise limiidid (API v1)\n",
    "\n",
    "Nagu säutsude otsimisel, nii on ka säutsude reaalajas kogumisel omad limiidid. Esiteks, üks Twitter'i kasutaja võib korraga tekitada ainult ühe säutsuvoo filtreerija (`Stream`), mitut filtreerijat samaaegselt kasutada ei ole lubatud.\n",
    "\n",
    "Teiseks, piiratud on ka filtreerimise kriteeriumite hulgad: korraga tohib filtreerida säutse mitte rohkem kui 400 võtmesõna järgi, 5000 kasutaja järgi ja/või 25 geograafilise asukohapiirangu järgi (v.a tasulise konto korral, mille kohta vt lähemalt [siit](https://developer.twitter.com/en/docs/tweets/filter-realtime/overview)). \n",
    "\n",
    "Kolmas oluline piirang puudutab reaalajas filtreerimise tulemusi: veebiteenus tagastab vaid kuni 1% kõigist antud ajahetkel tehtud säutsudest. \n",
    "Kui kriteeriumid on liiga avarad ning nendele vastab rohkem kui 1% kõigist säutsudest, siis jäetakse osad säutsud tagastamata (ja nende asemel saadetakse hoiatus, et limiit on ületatud). \n",
    "Eestikeelsete säutsude puhul ei tohiks see küll olla probleem -- valdav osa säutsudest tehakse teistes keeltes ning kõik eestikeelsed säutsud peaksid mistahes ajahetkel 1% limiidi alla ära mahtuma (vähemalt kõik saksakeelsed säutsud on mahtunud 1% limiidi alla, väidab [see teadustöö](http://www.lrec-conf.org/proceedings/lrec2014/pdf/1146_Paper.pdf) -- suure tõenäosusega mahuvad siis ka eestikeelsed). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Säutsude reaalajas filtreerimine -- kas kasutada või mitte?_\n",
    "\n",
    "Võrreldes mineviku-säutsude otsimisega või TweetCat'i abil kogumisega pakub säutsude reaalajas kogumine kõige süstemaatilisemat viisi säutsude korjamiseks: kui filtreerimiskriteeriumid on hästi valitud, siis võib kätte saada *praktiliselt kõik mingil ajaperioodil tehtud eestikeelsed säutsud*. \n",
    "\n",
    "Mündi teine külg on aga see, et nii saab koguda vaid tuleviku-säutse ning reaalajas kogumine on ka üksjagu keerulisem kui mineviku-säutsude otsimine või TweetCat'iga kogumine. \n",
    "\n",
    " * Kui filtreerimise näites kogusime säutse reaalajas paarikümne sekundi jooksul, siis sellise programmi jooksutamine nädalate või isegi kuude kaupa nõuab kõigepealt stabiilse netiühendusega ja pikaajalist töötamist võimaldavat keskkonda. Tõenäoliselt oleks seda kõige parem teha mitte isiklikus sülearvutis, vaid kusagil serveris -- laadida programm üles ja \"panna tiksuma\";\n",
    " * Kui eesmärgiks on saada kätte kõik eestikeelsed säutsud, siis heade filtreerimiskriteeriumite valimine nõuab tõenäoliselt üksjagu katsetamist -- milliseid võtmesõnu valida, kuidas kombineerida võtmesõnade järgi filtreerimist kasutajate ja asukohtade järgi filtreerimisega, kuidas veenduda / testida, et 95% ja rohkem eestikeelsetest säutsudest leitakse üles jne. Natuke saab siin eeskuju võtta [sellest uurimustööst](http://www.lrec-conf.org/proceedings/lrec2014/pdf/1146_Paper.pdf), kus lahendati sama ülesannet saksakeelsete säutsude puhul;\n",
    " * Kuna programm pannakse käima pikaks ajaks, on tarvis ka läbi mõelda (ja implementeerida) piirisituatsioonid (_a la_ mida teha erinevate hoiatuste korral, mida server võib saata, ning kuidas (automaatselt) taastada katkenud ühendus);\n",
    "\n",
    "Kokkuvõttes: säutsude reaalajas kogumise liides on võimas tööriist, aga selle kasutamaõppimine ja kasutamine nõuavad üksjagu  tööd ja aega."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
